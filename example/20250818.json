{
    "huggingface_papers": [
        {
            "Title": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual   Mathematical Reasoning",
            "HF_Link": "https://hf-mirror.com/papers/2508.10433",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10433",
            "Summary": "Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities across various tasks, but still struggle with complex mathematical reasoning. Existing research primarily focuses on dataset construction and method optimization, often overlooking two critical aspects: comprehensive knowledge-driven design and model-centric data space modeling. In this paper, we introduce We-Math 2.0, a unified system that integrates a structured mathematical knowledge system, model-centric data space modeling, and a reinforcement learning (RL)-based training paradigm to comprehensively enhance the mathematical reasoning abilities of MLLMs. The key contributions of We-Math 2.0 are fourfold: (1) MathBook Knowledge System: We construct a five-level hierarchical system encompassing 491 knowledge points and 1,819 fundamental principles. (2) MathBook-Standard & Pro: We develop MathBook-Standard, a dataset that ensures broad conceptual coverage and flexibility through dual expansion. Additionally, we define a three-dimensional difficulty space and generate 7 progressive variants per problem to build MathBook-Pro, a challenging dataset for robust training. (3) MathBook-RL: We propose a two-stage RL framework comprising: (i) Cold-Start Fine-tuning, which aligns the model with knowledge-oriented chain-of-thought reasoning; and (ii) Progressive Alignment RL, leveraging average-reward learning and dynamic data scheduling to achieve progressive alignment across difficulty levels. (4) MathBookEval: We introduce a comprehensive benchmark covering all 491 knowledge points with diverse reasoning step distributions. Experimental results show that MathBook-RL performs competitively with existing baselines on four widely-used benchmarks and achieves strong results on MathBookEval, suggesting promising generalization in mathematical reasoning.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10433v1"
        },
        {
            "Title": "NextStep-1: Toward Autoregressive Image Generation with Continuous   Tokens at Scale",
            "HF_Link": "https://hf-mirror.com/papers/2508.10711",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10711",
            "Summary": "Prevailing autoregressive (AR) models for text-to-image generation either rely on heavy, computationally-intensive diffusion models to process continuous image tokens, or employ vector quantization (VQ) to obtain discrete tokens with quantization loss. In this paper, we push the autoregressive paradigm forward with NextStep-1, a 14B autoregressive model paired with a 157M flow matching head, training on discrete text tokens and continuous image tokens with next-token prediction objectives. NextStep-1 achieves state-of-the-art performance for autoregressive models in text-to-image generation tasks, exhibiting strong capabilities in high-fidelity image synthesis. Furthermore, our method shows strong performance in image editing, highlighting the power and versatility of our unified approach. To facilitate open research, we will release our code and models to the community.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10711v1"
        },
        {
            "Title": "ToonComposer: Streamlining Cartoon Production with Generative   Post-Keyframing",
            "HF_Link": "https://hf-mirror.com/papers/2508.10881",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10881",
            "Summary": "Traditional cartoon and anime production involves keyframing, inbetweening, and colorization stages, which require intensive manual effort. Despite recent advances in AI, existing methods often handle these stages separately, leading to error accumulation and artifacts. For instance, inbetweening approaches struggle with large motions, while colorization methods require dense per-frame sketches. To address this, we introduce ToonComposer, a generative model that unifies inbetweening and colorization into a single post-keyframing stage. ToonComposer employs a sparse sketch injection mechanism to provide precise control using keyframe sketches. Additionally, it uses a cartoon adaptation method with the spatial low-rank adapter to tailor a modern video foundation model to the cartoon domain while keeping its temporal prior intact. Requiring as few as a single sketch and a colored reference frame, ToonComposer excels with sparse inputs, while also supporting multiple sketches at any temporal location for more precise motion control. This dual capability reduces manual workload and improves flexibility, empowering artists in real-world scenarios. To evaluate our model, we further created PKBench, a benchmark featuring human-drawn sketches that simulate real-world use cases. Our evaluation demonstrates that ToonComposer outperforms existing methods in visual quality, motion consistency, and production efficiency, offering a superior and more flexible solution for AI-assisted cartoon production.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10881v1"
        },
        {
            "Title": "PRELUDE: A Benchmark Designed to Require Global Comprehension and   Reasoning over Long Contexts",
            "HF_Link": "https://hf-mirror.com/papers/2508.09848",
            "Arxiv_Link": "https://arxiv.org/abs/2508.09848",
            "Summary": "We introduce PRELUDE, a benchmark for evaluating long-context understanding through the task of determining whether a character's prequel story is consistent with the canonical narrative of the original book. Our task poses a stronger demand for global comprehension and deep reasoning than existing benchmarks -- as the prequels are not part of the original story, assessing their plausibility typically requires searching and integrating information that is only indirectly related. Empirically, 88% of instances require evidence from multiple parts of the narrative. Experimental results highlight the challenge of our task: in-context learning, RAG and in-domain training with state-of-the-art LLMs, and commercial DeepResearch services, lag behind humans by >15%. A further human study reveals that models often produce correct answers with flawed reasoning, leading to an over 30% gap in reasoning accuracy compared to humans. These findings underscore the substantial room for improvement in long-context understanding and reasoning.",
            "PDF_Link": "http://arxiv.org/pdf/2508.09848v2"
        },
        {
            "Title": "UI-Venus Technical Report: Building High-performance UI Agents with RFT",
            "HF_Link": "https://hf-mirror.com/papers/2508.10833",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10833",
            "Summary": "We present UI-Venus, a native UI agent that takes only screenshots as input based on a multimodal large language model. UI-Venus achieves SOTA performance on both UI grounding and navigation tasks using only several hundred thousand high-quality training samples through reinforcement finetune (RFT) based on Qwen2.5-VL. Specifically, the 7B and 72B variants of UI-Venus obtain 94.1% / 50.8% and 95.3% / 61.9% on the standard grounding benchmarks, i.e., Screenspot-V2 / Pro, surpassing the previous SOTA baselines including open-source GTA1 and closed-source UI-TARS-1.5. To show UI-Venus's summary and planing ability, we also evaluate it on the AndroidWorld, an online UI navigation arena, on which our 7B and 72B variants achieve 49.1% and 65.9% success rate, also beating existing models. To achieve this, we introduce carefully designed reward functions for both UI grounding and navigation tasks and corresponding efficient data cleaning strategies. To further boost navigation performance, we propose Self-Evolving Trajectory History Alignment & Sparse Action Enhancement that refine historical reasoning traces and balances the distribution of sparse but critical actions, leading to more coherent planning and better generalization in complex UI tasks. Our contributions include the publish of SOTA open-source UI agents, comprehensive data cleaning protocols and a novel self-evolving framework for improving navigation performance, which encourage further research and development in the community. Code is available at https://github.com/inclusionAI/UI-Venus.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10833v2"
        },
        {
            "Title": "Puppeteer: Rig and Animate Your 3D Models",
            "HF_Link": "https://hf-mirror.com/papers/2508.10898",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10898",
            "Summary": "Modern interactive applications increasingly demand dynamic 3D content, yet the transformation of static 3D models into animated assets constitutes a significant bottleneck in content creation pipelines. While recent advances in generative AI have revolutionized static 3D model creation, rigging and animation continue to depend heavily on expert intervention. We present Puppeteer, a comprehensive framework that addresses both automatic rigging and animation for diverse 3D objects. Our system first predicts plausible skeletal structures via an auto-regressive transformer that introduces a joint-based tokenization strategy for compact representation and a hierarchical ordering methodology with stochastic perturbation that enhances bidirectional learning capabilities. It then infers skinning weights via an attention-based architecture incorporating topology-aware joint attention that explicitly encodes inter-joint relationships based on skeletal graph distances. Finally, we complement these rigging advances with a differentiable optimization-based animation pipeline that generates stable, high-fidelity animations while being computationally more efficient than existing approaches. Extensive evaluations across multiple benchmarks demonstrate that our method significantly outperforms state-of-the-art techniques in both skeletal prediction accuracy and skinning quality. The system robustly processes diverse 3D content, ranging from professionally designed game assets to AI-generated shapes, producing temporally coherent animations that eliminate the jittering issues common in existing methods.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10898v1"
        },
        {
            "Title": "STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer",
            "HF_Link": "https://hf-mirror.com/papers/2508.10893",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10893",
            "Summary": "We present STream3R, a novel approach to 3D reconstruction that reformulates pointmap prediction as a decoder-only Transformer problem. Existing state-of-the-art methods for multi-view reconstruction either depend on expensive global optimization or rely on simplistic memory mechanisms that scale poorly with sequence length. In contrast, STream3R introduces an streaming framework that processes image sequences efficiently using causal attention, inspired by advances in modern language modeling. By learning geometric priors from large-scale 3D datasets, STream3R generalizes well to diverse and challenging scenarios, including dynamic scenes where traditional methods often fail. Extensive experiments show that our method consistently outperforms prior work across both static and dynamic scene benchmarks. Moreover, STream3R is inherently compatible with LLM-style training infrastructure, enabling efficient large-scale pretraining and fine-tuning for various downstream 3D tasks. Our results underscore the potential of causal Transformer models for online 3D perception, paving the way for real-time 3D understanding in streaming environments. More details can be found in our project page: https://nirvanalan.github.io/projects/stream3r.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10893v1"
        },
        {
            "Title": "A Survey on Diffusion Language Models",
            "HF_Link": "https://hf-mirror.com/papers/2508.10875",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10875",
            "Summary": "Diffusion Language Models (DLMs) are rapidly emerging as a powerful and promising alternative to the dominant autoregressive (AR) paradigm. By generating tokens in parallel through an iterative denoising process, DLMs possess inherent advantages in reducing inference latency and capturing bidirectional context, thereby enabling fine-grained control over the generation process. While achieving a several-fold speed-up, recent advancements have allowed DLMs to show performance comparable to their autoregressive counterparts, making them a compelling choice for various natural language processing tasks. In this survey, we provide a holistic overview of the current DLM landscape. We trace its evolution and relationship with other paradigms, such as autoregressive and masked language models, and cover both foundational principles and state-of-the-art models. Our work offers an up-to-date, comprehensive taxonomy and an in-depth analysis of current techniques, from pre-training strategies to advanced post-training methods. Another contribution of this survey is a thorough review of DLM inference strategies and optimizations, including improvements in decoding parallelism, caching mechanisms, and generation quality. We also highlight the latest approaches to multimodal extensions of DLMs and delineate their applications across various practical scenarios. Furthermore, our discussion addresses the limitations and challenges of DLMs, including efficiency, long-sequence handling, and infrastructure requirements, while outlining future research directions to sustain progress in this rapidly evolving field. Project GitHub is available at https://github.com/VILA-Lab/Awesome-DLMs.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10875v1"
        },
        {
            "Title": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of   Large Reasoning Models",
            "HF_Link": "https://hf-mirror.com/papers/2508.10751",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10751",
            "Summary": "Reinforcement learning with verifiable rewards (RLVR), which typically adopts Pass@1 as the reward, has faced the issues in balancing exploration and exploitation, causing policies to prefer conservative actions, converging to a local optimum. Identifying an appropriate reward metric is therefore crucial. Regarding the prior work, although Pass@k has been used in evaluation, its connection to LLM exploration ability in RLVR remains largely overlooked. To investigate this, we first use Pass@k as the reward to train the policy model (i.e., $\\textbf{Pass@k Training}$), and observe the improvement on its exploration ability. Next, we derive an analytical solution for the advantage of Pass@k Training, leading to an efficient and effective process. Building on this, our analysis reveals that exploration and exploitation are not inherently conflicting objectives, while they can mutually enhance each other. Moreover, Pass@k Training with analytical derivation essentially involves directly designing the advantage function. Inspired by this, we preliminarily explore the advantage design for RLVR, showing promising results and highlighting a potential future direction.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10751v1"
        },
        {
            "Title": "HumanSense: From Multimodal Perception to Empathetic Context-Aware   Responses through Reasoning MLLMs",
            "HF_Link": "https://hf-mirror.com/papers/2508.10576",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10576",
            "Summary": "While Multimodal Large Language Models (MLLMs) show immense promise for achieving truly human-like interactions, progress is hindered by the lack of fine-grained evaluation frameworks for human-centered scenarios, encompassing both the understanding of complex human intentions and the provision of empathetic, context-aware responses. Here we introduce HumanSense, a comprehensive benchmark designed to evaluate the human-centered perception and interaction capabilities of MLLMs, with a particular focus on deep understanding of extended multimodal contexts and the formulation of rational feedback. Our evaluation reveals that leading MLLMs still have considerable room for improvement, particularly for advanced interaction-oriented tasks. Supplementing visual input with audio and text information yields substantial improvements, and Omni-modal models show advantages on these tasks. Furthermore, we argue that appropriate feedback stems from a contextual analysis of the interlocutor's needs and emotions, with reasoning ability serving as the key to unlocking it. Accordingly, we employ a multi-stage, modality-progressive reinforcement learning to enhance the reasoning abilities of an Omni model, achieving substantial gains on evaluation results. Additionally, we observe that successful reasoning processes exhibit highly consistent thought patterns. By designing corresponding prompts, we also enhance the performance of non-reasoning models in a training-free manner. Project page: \\textcolor{brightpink}https://digital-avatar.github.io/ai/HumanSense/",
            "PDF_Link": "http://arxiv.org/pdf/2508.10576v1"
        },
        {
            "Title": "Processing and acquisition traces in visual encoders: What does CLIP   know about your camera?",
            "HF_Link": "https://hf-mirror.com/papers/2508.10637",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10637",
            "Summary": "Prior work has analyzed the robustness of visual encoders to image transformations and corruptions, particularly in cases where such alterations are not seen during training. When this occurs, they introduce a form of distribution shift at test time, often leading to performance degradation. The primary focus has been on severe corruptions that, when applied aggressively, distort useful signals necessary for accurate semantic predictions.   We take a different perspective by analyzing parameters of the image acquisition process and transformations that may be subtle or even imperceptible to the human eye. We find that such parameters are systematically encoded in the learned visual representations and can be easily recovered. More strikingly, their presence can have a profound impact, either positively or negatively, on semantic predictions. This effect depends on whether there is a strong correlation or anti-correlation between semantic labels and these acquisition-based or processing-based labels. Our code and data are available at: https://github.com/ryan-caesar-ramos/visual-encoder-traces",
            "PDF_Link": "http://arxiv.org/pdf/2508.10637v1"
        },
        {
            "Title": "From Black Box to Transparency: Enhancing Automated Interpreting   Assessment with Explainable AI in College Classrooms",
            "HF_Link": "https://hf-mirror.com/papers/2508.10860",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10860",
            "Summary": "Recent advancements in machine learning have spurred growing interests in automated interpreting quality assessment. Nevertheless, existing research suffers from insufficient examination of language use quality, unsatisfactory modeling effectiveness due to data scarcity and imbalance, and a lack of efforts to explain model predictions. To address these gaps, we propose a multi-dimensional modeling framework that integrates feature engineering, data augmentation, and explainable machine learning. This approach prioritizes explainability over ``black box'' predictions by utilizing only construct-relevant, transparent features and conducting Shapley Value (SHAP) analysis. Our results demonstrate strong predictive performance on a novel English-Chinese consecutive interpreting dataset, identifying BLEURT and CometKiwi scores to be the strongest predictive features for fidelity, pause-related features for fluency, and Chinese-specific phraseological diversity metrics for language use. Overall, by placing particular emphasis on explainability, we present a scalable, reliable, and transparent alternative to traditional human evaluation, facilitating the provision of detailed diagnostic feedback for learners and supporting self-regulated learning advantages not afforded by automated scores in isolation.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10860v1"
        },
        {
            "Title": "When Explainability Meets Privacy: An Investigation at the Intersection   of Post-hoc Explainability and Differential Privacy in the Context of Natural   Language Processing",
            "HF_Link": "https://hf-mirror.com/papers/2508.10482",
            "Arxiv_Link": "https://arxiv.org/abs/2508.10482",
            "Summary": "In the study of trustworthy Natural Language Processing (NLP), a number of important research fields have emerged, including that of explainability and privacy. While research interest in both explainable and privacy-preserving NLP has increased considerably in recent years, there remains a lack of investigation at the intersection of the two. This leaves a considerable gap in understanding of whether achieving both explainability and privacy is possible, or whether the two are at odds with each other. In this work, we conduct an empirical investigation into the privacy-explainability trade-off in the context of NLP, guided by the popular overarching methods of Differential Privacy (DP) and Post-hoc Explainability. Our findings include a view into the intricate relationship between privacy and explainability, which is formed by a number of factors, including the nature of the downstream task and choice of the text privatization and explainability method. In this, we highlight the potential for privacy and explainability to co-exist, and we summarize our findings in a collection of practical recommendations for future work at this important intersection.",
            "PDF_Link": "http://arxiv.org/pdf/2508.10482v2"
        }
    ],
    "gh_trendings": [
        {
            "url": "https://github.com/coleam00/Archon",
            "language": "Python",
            "description": "Beta release of Archon OS - the knowledge and task management backbone for AI coding assistants.",
            "readme_summary": "<p align=\"center\">\n  <img src=\"./archon-ui-main/public/archon-main-graphic.png\" alt=\"Archon Main Graphic\" width=\"853\" height=\"422\">\n</p>\n\n<p align=\"center\">\n  <em>Power up your AI coding assistants with your own custom knowledge base and task management as an MCP server</em>\n</p>\n\n<p align=\"center\">\n  <a href=\"#quick-start\">Quick Start</a> â€¢\n  <a href=\"#whats-included\">What's Included</a> â€¢\n  <a href=\"#architecture\">Architecture</a>\n</p>\n\n---\n\n## ğŸ¯ What is Archon?\n\n> Archon is currently in beta! Expect things to not work 100%, and please feel free to share any feedback and contribute with fixes/new features! Thank you to everyone for all the excitement we have for Archon already, as well as the bug reports, PRs, and discussions. It's a lot for our small team to get through but we're committed to addressing everything and making Archon into the best tool it possibly can be!\n\nArchon is the **command center** for AI coding assistants. For you, it's a sleek interface to manage knowledge, context, and tasks for your projects. For the AI coding assistant(s), it's a **Model Context Protocol (MCP) server** to collaborate on and leverage the same knowledge, context, and tasks. Connect Claude Code, Kiro, Cursor, Windsurf, etc. to give your AI agents access to:\n\n- **Your documentation** (crawled websites, uploaded PDFs/docs)\n- **Smart search capabilities** with advanced RAG strategies  \n- **Task management** integrated with your knowledge base\n- **Real-time updates** as you add new content and collaborate with your coding assistant on tasks\n- **Much more** coming soon to build Archon into an integrated environment for all context engineering\n\nThis new vision for Archon replaces the old one (the agenteer). Archon used to be the AI agent that builds other agents, and now you can use Archon to do that and more.\n\n> It doesn't matter what you're building or if it's a new/existing codebase - Archon's knowledge and task management capabilities will improve the output of **any** AI driven coding.\n\n## ğŸ”— Important Links\n\n- **[GitHub Discussions](https://github.com/coleam00/Archon/discussions)** - Join the conversation and share ideas about Archon\n- **[Contributing Guide](CONTRIBUTING.md)** - How to get involved and contribute to Archon\n- **[Introduction Video](https://youtu.be/8pRc_s2VQIo)** - Getting Started Guide and Vision for Archon\n- **[Dynamous AI Mastery](https://dynamous.ai)** - The birthplace of Archon - come join a vibrant community of other early AI adopters all helping each other transform their careers and businesses!\n\n## Quick Start\n\n### Prerequisites\n- [Docker Desktop](https://www.docker.com/products/docker-desktop/)\n- [Supabase](https://supabase.com/) account (free tier or local Supabase both work)\n- [OpenAI API key](https://platform.openai.com/api-keys) (Gemini and Ollama are supported too!)\n\n### Setup Instructions\n\n1. **Clone Repository**:\n   ```bash\n   git clone https://github.com/coleam00/archon.git\n   cd archon\n   ```\n\n2. **Environment Configuration**:\n   ```bash\n   cp .env.example .env\n   # Edit .env and add your Supabase credentials:\n   # SUPABASE_URL=https://your-project.supabase.co\n   # SUPABASE_SERVICE_KEY=your-service-key-here\n   ```\n\n   NOTE: Supabase introduced a new type of service key but use the legacy one (the longer one).\n\n   OPTIONAL: If you want to enable the reranking RAG strategy, uncomment lines 20-22 in `python\\requirements.server.txt`. This will significantly increase the size of the Archon Server container which is why it's off by default.\n\n3. **Database Setup**: In your [Supabase project](https://supabase.com/dashboard) SQL Editor, copy, paste, and execute the contents of `migration/complete_setup.sql`\n\n4. **Start Services**:\n   ```bash\n   docker-compose up --build -d\n   ```\n   \n   This starts the core microservices:\n   - **Server**: Core API and business logic (Port: 8181)\n   - **MCP Server**: Protocol interface for AI clients (Port: 8051)\n   - **Agents (coming soon!)**: AI operations and streaming (Port: 8052)\n   - **UI**: Web interface (Port: 3737)\n\n   Ports are configurable in your .env as well!\n\n5. **Configure API Keys**:\n   - Open http://localhost:3737\n   - Go to **Settings** â†’ Select your LLM/embedding provider and set the API key (OpenAI is default)\n   - Test by uploading a document or crawling a website\n\n## ğŸ”„ Database Reset (Start Fresh if Needed)\n\nIf you need to completely reset your database and start fresh:\n\n<details>\n<summary>âš ï¸ <strong>Reset Database - This will delete ALL data for Archon!</strong></summary>\n\n1. **Run Reset Script**: In your Supabase SQL Editor, run the contents of `migration/RESET_DB.sql`\n   \n   âš ï¸ WARNING: This will delete all Archon specific tables and data! Nothing else will be touched in your DB though.\n\n2. **Rebuild Database**: After reset, run `migration/complete_setup.sql` to create all the tables again.\n\n3. **Restart Services**:\n   ```bash\n   docker-compose up -d\n   ```\n\n4. **Reconfigure**: \n   - Select your LLM/embedding provider and set the API key again\n   - Re-upload any documents or re-crawl websites\n\nThe reset script safely removes all tables, functions, triggers, and policies with proper dependency handling.\n\n</details>\n\n## âš¡ Quick Test\n\nOnce everything is running:\n\n1. **Test Web Crawling**: Go to http://localhost:3737 â†’ Knowledge Base â†’ \"Crawl Website\" â†’ Enter a doc URL (such as https://ai.pydantic.dev/llms-full.txt)\n2. **Test Document Upload**: Knowledge Base â†’ Upload a PDF\n3. **Test Projects**: Projects â†’ Create a new project and add tasks\n4. **Integrate with your AI coding assistant**: MCP Dashboard â†’ Copy connection config for your AI coding assistant\n\n## ğŸ“š Documentation\n\n### Core Services\n\n| Service | Container Name | Default URL | Purpose |\n|---------|---------------|-------------|---------|\n| **Web Interface** | archon-ui | http://localhost:3737 | Main dashboard and controls |\n| **API Service** | archon-server | http://localhost:8181 | Web crawling, document processing |\n| **MCP Server** | archon-mcp | http://localhost:8051 | Model Context Protocol interface |\n| **Agents Service** | archon-agents | http://localhost:8052 | AI/ML operations, reranking |\n\n## What's Included\n\n### ğŸ§  Knowledge Management\n- **Smart Web Crawling**: Automatically detects and crawls entire documentation sites, sitemaps, and individual pages\n- **Document Processing**: Upload and process PDFs, Word docs, markdown files, and text documents with intelligent chunking\n- **Code Example Extraction**: Automatically identifies and indexes code examples from documentation for enhanced search\n- **Vector Search**: Advanced semantic search with contextual embeddings for precise knowledge retrieval\n- **Source Management**: Organize knowledge by source, type, and tags for easy filtering\n\n### ğŸ¤– AI Integration  \n- **Model Context Protocol (MCP)**: Connect any MCP-compatible client (Claude Code, Cursor, even non-AI coding assistants like Claude Desktop)\n- **10 MCP Tools**: Comprehensive yet simple set of tools for RAG queries, task management, and project operations\n- **Multi-LLM Support**: Works with OpenAI, Ollama, and Google Gemini models\n- **RAG Strategies**: Hybrid search, contextual embeddings, and result reranking for optimal AI responses\n- **Real-time Streaming**: Live responses from AI agents with progress tracking\n\n### ğŸ“‹ Project & Task Management\n- **Hierarchical Projects**: Organize work with projects, features, and tasks in a structured workflow\n- **AI-Assisted Creation**: Generate project requirements and tasks using integrated AI agents  \n- **Document Management**: Version-controlled documents with collaborative editing capabilities\n- **Progress Tracking**: Real-time updates and status management across all project activities\n\n### ğŸ”„ Real-time Collaboration\n- **WebSocket Updates**: Live progress tracking for crawling, processing, and AI operations\n- **Multi-user Support**: Collaborative knowledge building and project management\n- **Background Processing**: Asynchronous operations that don't block the user interface\n- **Health Monitoring**: Built-in service health checks and automatic reconnection\n\n## Architecture\n\n### Microservices Structure\n\nArchon uses true microservices architecture with clear separation of concerns:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Frontend UI   â”‚    â”‚  Server (API)   â”‚    â”‚   MCP Server    â”‚    â”‚ Agents Service  â”‚\nâ”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚\nâ”‚  React + Vite   â”‚â—„â”€â”€â–ºâ”‚    FastAPI +    â”‚â—„â”€â”€â–ºâ”‚    Lightweight  â”‚â—„â”€â”€â–ºâ”‚   PydanticAI    â”‚\nâ”‚  Port 3737      â”‚    â”‚    SocketIO     â”‚    â”‚    HTTP Wrapper â”‚    â”‚   Port 8052     â”‚\nâ”‚                 â”‚    â”‚    Port 8181    â”‚    â”‚    Port 8051    â”‚    â”‚                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚                        â”‚                        â”‚                        â”‚\n         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                  â”‚                        â”‚\n                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚\n                         â”‚    Database     â”‚               â”‚\n                         â”‚                 â”‚               â”‚\n                         â”‚    Supabase     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                         â”‚    PostgreSQL   â”‚\n                         â”‚    PGVector     â”‚\n                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Service Responsibilities\n\n| Service | Location | Purpose | Key Features |\n|---------|----------|---------|--------------|\n| **Frontend** | `archon-ui-main/` | Web interface and dashboard | React, TypeScript, TailwindCSS, Socket.IO client |\n| **Server** | `python/src/server/` | Core business logic and APIs | FastAPI, service layer, Socket.IO broadcasts, all ML/AI operations |\n| **MCP Server** | `python/src/mcp/` | MCP protocol interface | Lightweight HTTP wrapper, 10 MCP tools, session management |\n| **Agents** | `python/src/agents/` | PydanticAI agent hosting | Document and RAG agents, streaming responses |\n\n### Communication Patterns\n\n- **HTTP-based**: All inter-service communication uses HTTP APIs\n- **Socket.IO**: Real-time updates from Server to Frontend  \n- **MCP Protocol**: AI clients connect to MCP Server via SSE or stdio\n- **No Direct Imports**: Services are truly independent with no shared code dependencies\n\n### Key Architectural Benefits\n\n- **Lightweight Containers**: Each service contains only required dependencies\n- **Independent Scaling**: Services can be scaled independently based on load\n- **Development Flexibility**: Teams can work on different services without conflicts\n- **Technology Diversity**: Each service uses the best tools for its specific purpose\n\n## ğŸ”§ Configuring Custom Ports & Hostname\n\nBy default, Archon services run on the following ports:\n- **Archon-UI**: 3737\n- **Archon-Server**: 8181  \n- **Archon-MCP**: 8051\n- **Archon-Agents**: 8052\n- **Archon-Docs**: 3838 (optional)\n\n### Changing Ports\n\nTo use custom ports, add these variables to your `.env` file:\n\n```bash\n# Service Ports Configuration\nARCHON_UI_PORT=3737\nARCHON_SERVER_PORT=8181\nARCHON_MCP_PORT=8051\nARCHON_AGENTS_PORT=8052\nARCHON_DOCS_PORT=3838\n```\n\nExample: Running on different ports:\n```bash\nARCHON_SERVER_PORT=8282\nARCHON_MCP_PORT=8151\n```\n\n### Configuring Hostname\n\nBy default, Archon uses `localhost` as the hostname. You can configure a custom hostname or IP address by setting the `HOST` variable in your `.env` file:\n\n```bash\n# Hostname Configuration\nHOST=localhost  # Default\n\n# Examples of custom hostnames:\nHOST=192.168.1.100     # Use specific IP address\nHOST=archon.local      # Use custom domain\nHOST=myserver.com      # Use public domain\n```\n\nThis is useful when:\n- Running Archon on a different machine and accessing it remotely\n- Using a custom domain name for your installation\n- Deploying in a network environment where `localhost` isn't accessible\n\nAfter changing hostname or ports:\n1. Restart Docker containers: `docker-compose down && docker-compose up -d`\n2. Access the UI at: `http://${HOST}:${ARCHON_UI_PORT}`\n3. Update your AI client configuration with the new hostname and MCP port\n\n## ğŸ”§ Development\n\nFor development with hot reload:\n\n```bash\n# Backend services (with auto-reload)\ndocker-compose up archon-server archon-mcp archon-agents --build\n\n# Frontend (with hot reload) \ncd archon-ui-main && npm run dev\n\n# Documentation (with hot reload)\ncd docs && npm start\n```\n\n**Note**: The backend services are configured with `--reload` flag in their uvicorn commands and have source code mounted as volumes for automatic hot reloading when you make changes.\n\n## ğŸ“„ License\n\nArchon Community License (ACL) v1.2 - see [LICENSE](LICENSE) file for details.\n\n**TL;DR**: Archon is free, open, and hackable. Run it, fork it, share it - just don't sell it as-a-service without permission.\n"
        },
        {
            "url": "https://github.com/emcie-co/parlant",
            "language": "Python",
            "description": "LLM agents built for control. Designed for real-world use. Deployed in minutes.",
            "readme_summary": "<div align=\"center\">\n\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentLight.png?raw=true\">\n  <img alt=\"Parlant - AI Agent Framework\" src=\"https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentDark.png?raw=true\" width=400 />\n</picture>\n\n<h3>Finally, LLM agents that actually follow instructions</h3>\n\n<p>\n  <a href=\"https://www.parlant.io/\" target=\"_blank\">ğŸŒ Website</a> â€¢\n  <a href=\"https://www.parlant.io/docs/quickstart/installation\" target=\"_blank\">âš¡ Quick Start</a> â€¢\n  <a href=\"https://discord.gg/duxWqxKk6J\" target=\"_blank\">ğŸ’¬ Discord</a> â€¢\n  <a href=\"https://www.parlant.io/docs/quickstart/examples\" target=\"_blank\">ğŸ“– Examples</a>\n</p>\n\n<p>\n  <a href=\"https://pypi.org/project/parlant/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/parlant?color=blue\"></a>\n  <img alt=\"Python 3.10+\" src=\"https://img.shields.io/badge/python-3.10+-blue\">\n  <a href=\"https://opensource.org/licenses/Apache-2.0\"><img alt=\"License\" src=\"https://img.shields.io/badge/license-Apache%202.0-green\"></a>\n  <a href=\"https://discord.gg/duxWqxKk6J\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1312378700993663007?color=7289da&logo=discord&logoColor=white\"></a>\n  <img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/emcie-co/parlant?style=social\">\n</p>\n\n<a href=\"https://trendshift.io/repositories/12768\" target=\"_blank\">\n  <img src=\"https://trendshift.io/api/badge/repositories/12768\" alt=\"Trending on TrendShift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/>\n</a>\n\n</div>\n\n## ğŸ¯ The Problem Every AI Developer Faces\n\nYou build an AI agent. It works great in testing. Then real users start talking to it and...\n\n- âŒ It ignores your carefully crafted system prompts\n- âŒ It hallucinates responses in critical moments\n- âŒ It can't handle edge cases consistently\n- âŒ Each conversation feels like a roll of the dice\n\n**Sound familiar?** You're not alone. This is the #1 pain point for developers building production AI agents.\n\n## âš¡ The Solution: Teach Principles, Not Scripts\n\nParlant flips the script on AI agent development. Instead of hoping your LLM will follow instructions, **Parlant guarantees it**.\n\n```python\n# Traditional approach: Cross your fingers ğŸ¤\nsystem_prompt = \"You are a helpful assistant. Please follow these 47 rules...\"\n\n# Parlant approach: Guaranteed compliance âœ…\nawait agent.create_guideline(\n    condition=\"Customer asks about refunds\",\n    action=\"Check order status first to see if eligible\",\n    tools=[check_order_status],\n)\n```\n\n<div align=\"center\">\n\n## ğŸš€ Get Your Agent Running in 60 Seconds\n\n</div>\n\n```bash\npip install parlant\n```\n\n```python\nimport parlant.sdk as p\n\n@p.tool\nasync def get_weather(context: p.ToolContext, city: str) -> p.ToolResult:\n    # Your weather API logic here\n    return p.ToolResult(f\"Sunny, 72Â°F in {city}\")\n\nasync def main():\n    async with p.Server() as server:\n        agent = await server.create_agent(\n            name=\"WeatherBot\",\n            description=\"Helpful weather assistant\"\n        )\n\n        # Define behavior with natural language\n        await agent.create_guideline(\n            condition=\"User asks about weather\",\n            action=\"Get current weather and provide a friendly response with suggestions\",\n            tools=[get_weather]\n        )\n\n        # ğŸ‰ Test playground ready at http://localhost:8800\n        # Integrate the official React widget into your app,\n        # or follow the tutorial to build your own frontend!\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())\n```\n\n**That's it!** Your agent is running with guaranteed rule-following behavior.\n\n## ğŸ¬ See It In Action\n\n<img alt=\"Parlant Demo\" src=\"https://github.com/emcie-co/parlant/blob/develop/docs/demo.gif?raw=true\" width=\"100%\" />\n\n## ğŸ”¥ Why Developers Are Switching to Parlant\n\n<table width=\"100%\">\n<tr>\n  <td width=\"50%\">\n\n### ğŸ—ï¸ **Traditional AI Frameworks**\n\n  </td>\n  <td width=\"50%\">\n\n### âš¡ **Parlant**\n\n  </td>\n</tr>\n<tr>\n<td width=\"50%\">\n\n- Write complex system prompts\n- Hope the LLM follows them\n- Debug unpredictable behaviors\n- Scale by prompt engineering\n- Cross fingers for reliability\n\n</td>\n<td width=\"50%\">\n\n- Define rules in natural language\n- **Guaranteed** rule compliance\n- Predictable, consistent behavior\n- Scale by adding guidelines\n- Production-ready from day one\n\n</td>\n</tr>\n</table>\n\n## ğŸ¯ Perfect For Your Use Case\n\n<div align=\"center\">\n\n|  **Financial Services**  |     **Healthcare**      |       **E-commerce**        |       **Legal Tech**       |\n| :----------------------: | :---------------------: | :-------------------------: | :------------------------: |\n| Compliance-first design  |   HIPAA-ready agents    |  Customer service at scale  |   Precise legal guidance   |\n| Built-in risk management | Patient data protection | Order processing automation | Document review assistance |\n\n</div>\n\n## ğŸ› ï¸ Enterprise-Grade Features\n\n- **ğŸ§­ Conversational Journeys** - Lead the customer step-by-step to a goal\n- **ğŸ¯ Dynamic Guideline Matching** - Context-aware rule application\n- **ğŸ”§ Reliable Tool Integration** - APIs, databases, external services\n- **ğŸ“Š Conversation Analytics** - Deep insights into agent behavior\n- **ğŸ”„ Iterative Refinement** - Continuously improve agent responses\n- **ğŸ›¡ï¸ Built-in Guardrails** - Prevent hallucination and off-topic responses\n- **ğŸ“± React Widget** - [Drop-in chat UI for any web app](https://github.com/emcie-co/parlant-chat-react)\n- **ğŸ” Full Explainability** - Understand every decision your agent makes\n\n## ğŸ“ˆ Join 5,000+ Developers Building Better AI\n\n<div align=\"center\">\n\n**Companies using Parlant in production:**\n\n_Financial institutions â€¢ Healthcare providers â€¢ Legal firms â€¢ E-commerce platforms_\n\n[![Star History Chart](https://api.star-history.com/svg?repos=emcie-co/parlant&type=Date)](https://star-history.com/#emcie-co/parlant&Date)\n\n</div>\n\n## ğŸƒâ€â™‚ï¸ Quick Start Paths\n\n<table border=\"0\">\n<tr>\n<td><strong>ğŸ¯ I want to test it myself</strong></td>\n<td><a href=\"https://www.parlant.io/docs/quickstart/installation\">â†’ 5-minute quickstart</a></td>\n</tr>\n<tr>\n<td><strong>ğŸ› ï¸ I want to see an example</strong></td>\n<td><a href=\"https://www.parlant.io/docs/quickstart/examples\">â†’ Healthcare agent example</a></td>\n</tr>\n<tr>\n<td><strong>ğŸš€ I want to get involved</strong></td>\n<td><a href=\"https://discord.gg/duxWqxKk6J\">â†’ Join our Discord community</a></td>\n</tr>\n</table>\n\n## ğŸŒŸ What Developers Are Saying\n\n> _\"By far the most elegant conversational AI framework that I've come across! Developing with Parlant is pure joy.\"_ **â€” Vishal Ahuja, Senior Lead, Customer-Facing Conversational AI @ JPMorgan Chase**\n\n## ğŸ¤ Community & Support\n\n- ğŸ’¬ **[Discord Community](https://discord.gg/duxWqxKk6J)** - Get help from the team and community\n- ğŸ“– **[Documentation](https://parlant.io/docs/quickstart/installation)** - Comprehensive guides and examples\n- ğŸ› **[GitHub Issues](https://github.com/emcie-co/parlant/issues)** - Bug reports and feature requests\n- ğŸ“§ **[Direct Support](https://parlant.io/contact)** - Direct line to our engineering team\n\n## ğŸ“„ License\n\nApache 2.0 - Use it anywhere, including commercial projects.\n\n---\n\n<div align=\"center\">\n\n**Ready to build AI agents that actually work?**\n\nâ­ **Star this repo** â€¢ ğŸš€ **[Try Parlant now](https://parlant.io/)** â€¢ ğŸ’¬ **[Join Discord](https://discord.gg/duxWqxKk6J)**\n\n_Built with â¤ï¸ by the team at [Emcie](https://emcie.co)_\n\n</div>\n"
        },
        {
            "url": "https://github.com/DataExpert-io/data-engineer-handbook",
            "language": "Jupyter Notebook",
            "description": "This is a repo with links to everything you'd ever want to learn about data engineering",
            "readme_summary": "# The Data Engineering Handbook\n<a href=\"https://trendshift.io/repositories/8755\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/8755\" alt=\"DataExpert-io%2Fdata-engineer-handbook | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\nThis repo has all the resources you need to become an amazing data engineer!\n\n## Getting started\n\nIf you are new to data engineering, start by following this [2024 breaking into data engineering roadmap](https://blog.dataengineer.io/p/the-2024-breaking-into-data-engineering)\n\nIf you are here for the [6-week free YouTube boot camp](https://youtu.be/myhe0LXpCeo) you can check out\n- [introduction](bootcamp/introduction.md)\n- [software needed](bootcamp/software.md)\n\n\nFor more applied learning:\n- Check out the [projects](projects.md) section for more hands-on examples!\n- Check out the [interviews](interviews.md) section for more advice on how to pass data engineering interviews!\n- Check out the [books](books.md) section for a list of high quality data engineering books\n- Check out the [communities](communities.md) section for a list of high quality data engineering communities to join\n- Check out the [newsletter](newsletters.md) section to learn via email \n\n\n## Resources\n\n### Great [list of over 25 books](books.md)\n\nTop 3 must read books are:\n- [Fundamentals of Data Engineering](https://www.amazon.com/Fundamentals-Data-Engineering-Robust-Systems/dp/1098108302/)\n- [Designing Data-Intensive Applications](https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321/)\n- [Designing Machine Learning Systems](https://www.amazon.com/Designing-Machine-Learning-Systems-Production-Ready/dp/1098107969)\n\n### Great [list of over 10 communities to join](communities.md):\n\nTop must-join communities for DE:\n- [DataExpert.io Community Discord](https://discord.gg/JGumAXncAK)\n- [Data Talks Club Slack](https://datatalks.club/slack)\n- [Data Engineer Things Community](https://www.dataengineerthings.org/)\n\nTop must-join communities for ML:\n- [AdalFlow Discord](https://discord.com/invite/ezzszrRZvT)\n- [Chip Huyen MLOps Discord](https://discord.gg/dzh728c5t3)\n\n### Companies:\n\n- Orchestration  \n  - [Mage](https://www.mage.ai)\n  - [Astronomer](https://www.astronomer.io)\n  - [Prefect](https://www.prefect.io)\n  - [Dagster](https://www.dagster.io)\n  - [Airflow](https://airflow.apache.org/)\n  - [Kestra](https://kestra.io/) \n  - [Shipyard](https://www.shipyardapp.com/)\n  - [Hamilton](https://github.com/dagworks-inc/hamilton)\n- Data Lake / Cloud\n  - [Tabular](https://www.tabular.io)\n  - [Microsoft](https://www.microsoft.com)\n  - [Databricks](https://www.databricks.com/company/about-us)\n  - [Onehouse](https://www.onehouse.ai)\n  - [Delta Lake](https://delta.io/)\n  - [Ilum](https://ilum.cloud/)\n  - [DuckLake](https://ducklake.select/)\n  - [Apache Iceberg](https://iceberg.apache.org/)\n  - [Apache Polaris](https://polaris.apache.org/)\n  - [Lakekeeper](https://lakekeeper.io/)\n- Data Warehouse\n  - [Snowflake](https://www.snowflake.com/en/)\n  - [Firebolt](https://www.firebolt.io/)\n  - [Databend](https://www.databend.com/)\n- Data Quality\n  - [dbt](https://www.getdbt.com/)\n  - [Metaplane](https://www.metaplane.dev/)\n  - [Gable](https://www.gable.ai)\n  - [Great Expectations](https://www.greatexpectations.io)\n  - [Streamdal](https://streamdal.com)\n  - [Coalesce](https://coalesce.io/)\n  - [Soda](https://www.soda.io/)\n  - [DQOps](https://dqops.com/)\n  - [HEDDA.IO](https://hedda.io)\n  - [Dingo](https://github.com/MigoXLab/dingo)\n- Education Companies\n  - [DataExpert.io](https://www.dataexpert.io)\n  - [LearnDataEngineering.com](https://www.learndataengineering.com)\n  - [AlgoExpert](https://www.algoexpert.io)\n  - [ByteByteGo](https://www.bytebytego.com)\n- Analytics / Visualization\n  - [Preset](https://www.preset.io)\n  - [Starburst](https://www.starburst.io)\n  - [Metabase](https://www.metabase.com/)\n  - [Looker Studio](https://lookerstudio.google.com/overview)\n  - [Tableau](https://www.tableau.com/)\n  - [Power BI](https://powerbi.microsoft.com/)\n  - [Hex](https://hex.ai/)\n  - [Apache Superset](https://superset.apache.org/)\n  - [Evidence](https://evidence.dev)\n  - [Redash](https://redash.io/)\n  - [Lightdash](https://lightdash.com/)\n- Data Integration\n  - [Cube](https://cube.dev)\n  - [Fivetran](https://www.fivetran.com)\n  - [Airbyte](https://airbyte.io)\n  - [dlt](https://dlthub.com/)\n  - [Sling](https://slingdata.io/)\n  - [Meltano](https://meltano.com/)\n  - [Estuary](https://estuary.dev/)\n- Semantic Layers\n  - [Cube](https://cube.dev)\n  - [dbt Semantic Layer](https://www.getdbt.com/product/semantic-layer) \n- Modern OLAP\n  - [Apache Druid](https://druid.apache.org/)\n  - [ClickHouse](https://clickhouse.com/)\n  - [Apache Pinot](https://pinot.apache.org/)\n  - [Apache Kylin](https://kylin.apache.org/)\n  - [DuckDB](https://duckdb.org/)\n  - [QuestDB](https://questdb.io/)\n  - [StarRocks](https://www.starrocks.io/)\n- LLM application library\n  - [AdalFlow](https://github.com/SylphAI-Inc/AdalFlow)\n  - [LangChain](https://github.com/langchain-ai/langchain)\n  - [LlamaIndex](https://github.com/run-llama/llama_index)\n- Real-Time Data\n  - [Aggregations.io](https://aggregations.io)\n  - [Responsive](https://www.responsive.dev/)\n  - [RisingWave](https://risingwave.com/)\n  - [Striim](https://www.striim.com/)\n- Data Lineage\n  - [OpenLineage](https://openlineage.io/)\n\n\n### Data Engineering blogs of companies:\n\n- [Netflix](https://netflixtechblog.com/tagged/big-data)\n- [Uber](https://www.uber.com/blog/houston/data/?uclick_id=b2f43229-f3f4-4bae-bd5d-10a05db2f70c)\n- [Databricks](https://www.databricks.com/blog/category/engineering/data-engineering)\n- [Airbnb](https://medium.com/airbnb-engineering/data/home)\n- [Amazon AWS Blog](https://aws.amazon.com/blogs/big-data/)\n- [Microsoft Data Architecture Blogs](https://techcommunity.microsoft.com/t5/data-architecture-blog/bg-p/DataArchitectureBlog)\n- [Microsoft Fabric Blog](https://blog.fabric.microsoft.com/)\n- [Oracle](https://blogs.oracle.com/datawarehousing/)\n- [Meta](https://engineering.fb.com/category/data-infrastructure/)\n- [Onehouse](https://www.onehouse.ai/blog)\n- [Estuary Blog](https://estuary.dev/blog/)\n\n### Data Engineering Whitepapers:\n\n- [A Five-Layered Business Intelligence Architecture](https://ibimapublishing.com/articles/CIBIMA/2011/695619/695619.pdf)\n- [Lakehouse:A New Generation of Open Platforms that Unify Data Warehousing and Advanced Analytics](https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf)\n- [Big Data Quality: A Data Quality Profiling Model](https://link.springer.com/chapter/10.1007/978-3-030-23381-5_5)\n- [The Data Lakehouse: Data Warehousing and More](https://arxiv.org/abs/2310.08697)\n- [Spark: Cluster Computing with Working Sets](https://dl.acm.org/doi/10.5555/1863103.1863113)\n- [The Google File System](https://research.google/pubs/the-google-file-system/)\n- [Building a Universal Data Lakehouse](https://www.onehouse.ai/whitepaper/onehouse-universal-data-lakehouse-whitepaper)\n- [XTable in Action: Seamless Interoperability in Data Lakes](https://arxiv.org/abs/2401.09621)\n- [MapReduce: Simplified Data Processing on Large Clusters](https://research.google/pubs/mapreduce-simplified-data-processing-on-large-clusters/)\n- [Tidy Data](https://vita.had.co.nz/papers/tidy-data.pdf)\n- [Data Engineering Whitepapers](https://www.ssp.sh/brain/data-engineering-whitepapers/)\n\n### Social Media Accounts\n\nHere's the mostly comprehensive list of data engineering creators: \n**(You have to have at least 5k followers somewhere to be added!)**\n\n\n#### YouTube \n| Name                        | YouTube Channel                                                                                         | Follower Count |\n|----------------------------|---------------------------------------------------------------------------------------------------------|---------------:|\n| ByteByteGo                 | [ByteByteGo](https://www.youtube.com/c/ByteByteGo)                                             | 1,000,000+     |\n| Zach Wilson                | [Data with Zach](https://www.youtube.com/@eczachly_)                                          | 150,000+       |\n| Shashank Mishra            | [E-learning Bridge](https://www.youtube.com/@shashank_mishra)                                   | 100,000+       |\n| Seattle Data Guy           | [Seattle Data Guy](https://www.youtube.com/c/SeattleDataGuy)                                  | 100,000+       |\n| TrendyTech                 | [TrendyTech](https://www.youtube.com/c/TrendytechInsights)                                   | 100,000+       |\n| Darshil Parmar             | [Darshil Parmar](https://www.youtube.com/@DarshilParmar)                                       | 100,000+       |\n| Andreas Kretz              | [Andreas Kretz](https://www.youtube.com/c/andreaskayy)                                          | 100,000+       |\n| The Ravit Show             | [The Ravit Show](https://youtube.com/@theravitshow)                                           | 100,000+       |\n| Guy in a Cube              | [Guy in a Cube](https://www.youtube.com/@GuyInACube)                                            | 100,000+       |\n| Adam Marczak               | [Adam Marczak](https://www.youtube.com/@AdamMarczakYT)                                         | 100,000+       |\n| nullQueries                | [nullQueries](https://www.youtube.com/@nullQueries)                                             | 100,000+       |\n| TECHTFQ by Thoufiq         | [TECHTFQ by Thoufiq](https://www.youtube.com/@techTFQ)                                         | 100,000+       |\n| SQLBI                       | [SQLBI](https://www.youtube.com/@SQLBI)                                                     | 100,000+       |\n| Alex Freberg               | [Alex The Analyst](https://www.youtube.com/@AlexTheAnalyst)                                     | 100,000+       |\n| Ankur Ranjan               | [Big Data Show](https://www.youtube.com/@TheBigDataShow)                                        | 100,000+       |\n| Prashanth Kumar Pandey     | [ScholarNest](https://www.youtube.com/@ScholarNest)                                              | 77,000+        |\n| ITVersity                  | [ITVersity](https://www.youtube.com/@itversity)                                                  | 67,000+        |\n| Soumil Shah                | [Soumil Shah](https://www.youtube.com/@SoumilShah)                                               | 50,000         |\n| Ansh Lamba                 | [Ansh Lamba](https://www.youtube.com/@AnshLambaJSR)                                              | 18,000+        |\n| Azure Lib                  | [Azure Lib](https://www.youtube.com/@azurelib-academy)                                        | 10,000+        |\n| Advancing Analytics        | [Advancing Analytics](https://www.youtube.com/@AdvancingAnalytics)                               | 10,000+        |\n| Kahan Data Solutions       | [Kahan Data Solutions](https://www.youtube.com/@KahanDataSolutions)                               | 10,000+        |\n| Ankit Bansal               | [Ankit Bansal](https://youtube.com/@ankitbansal6)                                               | 10,000+        |\n| Mr. K Talks Tech           | [Mr. K Talks Tech](https://www.youtube.com/channel/UCzdOan4AmF65PmLLks8Lmww)                      | 10,000+        |\n| Samuel Focht               | [Python Basics](https://www.youtube.com/@PythonBasics)                                           | 10,000+        |\n| Mehdi Ouazza              | [Mehdio DataTV](https://www.youtube.com/@mehdio)                                                    | 3,000+         |\n| Alex Merced                | [Alex Merced Data](https://www.youtube.com/@alexmerceddata_)                                            | N/A           |\n| John Kutay                 | [John Kutay](https://www.youtube.com/@striiminc) | N/A           |\n| Emil Kaminski              | [Databricks For Professionals](https://www.youtube.com/@DatabricksPro)                           | 5,000+          |\n\n\n#### LinkedIn\n\n| Name                      | LinkedIn Profile                                                                                         | Follower Count |\n|--------------------------|----------------------------------------------------------------------------------------------------------|---------------:|\n| Zach Wilson              | [Zach Wilson](https://www.linkedin.com/in/eczachly)                                                     | 400,000+       |\n| Chip Huyen               | [Chip Huyen](https://www.linkedin.com/in/chiphuyen/)                                    | 250,000+       |\n| Shashank Mishra          | [Shashank Mishra](https://www.linkedin.com/in/shashank219/)                                     | 100,000+       |\n| Seattle Data Guy         | [Ben Rogojan](https://www.linkedin.com/in/benjaminrogojan)                                        | 100,000+       |\n| TrendyTech               | [Sumit Mittal](https://www.linkedin.com/in/bigdatabysumit/)                                   | 100,000+       |\n| Darshil Parmar           | [Darshil Parmar](https://www.linkedin.com/in/darshil-parmar/)                                   | 100,000+       |\n| Andreas Kretz            | [Andreas Kretz](https://www.linkedin.com/in/andreas-kretz)                                     | 100,000+       |\n| ByteByteGo (Alex Xu)     | [Alex Xu](https://www.linkedin.com/in/alexxubyte)                                             | 100,000+       |\n| Azure Lib (Deepak Goyal) | [Deepak Goyal](https://www.linkedin.com/in/deepak-goyal-93805a17/)                              | 100,000+       |\n| Alex Freberg             | [Alex Freberg](https://www.linkedin.com/in/alex-freberg/)                                     | 100,000+       |\n| SQLBI (Marco Russo)      | [Marco Russo](https://www.linkedin.com/in/sqlbi)                                                  | 50,000+        |\n| Ankit Bansal             | [Ankit Bansal](https://www.linkedin.com/in/ankitbansal6/)                                        | 50,000+        |\n| Marc Lamberti            | [Marc Lamberti](https://www.linkedin.com/in/marclamberti)                                       | 50,000+        |\n| Ankur Ranjan             | [Ankur Ranjan](https://www.linkedin.com/in/thebigdatashow/)                                       | 48,000+        |\n| ITVersity (Durga Gadiraju)| [Durga Gadiraju](https://www.linkedin.com/in/durga0gadiraju/)                                   | 48,000+        |\n| Prashanth Kumar Pandey   | [Prashanth Kumar Pandey](https://www.linkedin.com/in/prashant-kumar-pandey/)                       | 37,000+        |\n| Alex Merced              | [Alex Merced](https://www.linkedin.com/in/alexmerced)                                           | 30,000+        |\n| Ijaz Ali                 | [Ijaz Ali](https://www.linkedin.com/in/ijaz-ali-6aaa87122/)                                       | 24,000+        |\n| Mehdi Ouazza             | [Mehdi Ouazza](https://www.linkedin.com/in/mehd-io/)                                        | 20,000+        |\n| Ananth Packkildurai      | [Ananth Packkildurai](https://www.linkedin.com/in/ananthdurai/)                                    | 18,000+        |\n| Ansh Lamba               | [Ansh Lamba](https://www.linkedin.com/in/ansh-lamba-793681184/)                                    | 13,000+        |\n| Manojkumar Vadivel       | [Manojkumar Vadivel](https://www.linkedin.com/in/manojvsj/)                                        | 12,000+        |\n| Advancing Analytics      | [Simon Whiteley](https://www.linkedin.com/in/simon-whiteley-uk/)                                  | 10,000+        |\n| Li Yin                   | [Li Yin](https://www.linkedin.com/in/li-yin-ai/)                                                  | 10,000+        |\n| Jaco van Gelder          | [Jaco van Gelder](https://www.linkedin.com/in/jwvangelder/)                                       | 10,000+        |\n| Joseph Machado           | [Joseph Machado](https://www.linkedin.com/in/josephmachado1991/)                                  | 10,000+        |\n| Eric Roby                | [Eric Roby](https://www.linkedin.com/in/codingwithroby/)                                           | 10,000+        |\n| Simon SpÃ¤ti              | [Simon SpÃ¤ti](https://www.linkedin.com/in/sspaeti/)                                            | 10,000+        |\n| Constantin Lungu         | [Constantin Lungu](https://www.linkedin.com/in/constantin-lungu-668b8756)                         | 10,000+        |\n| Lakshmi Sontenam         | [Lakshmi Sontenam](https://www.linkedin.com/in/shivaga9esh)                                      | 9,500+         |\n| Dani PÃ¡lma               | [Daniel PÃ¡lma](https://www.linkedin.com/in/danthelion/)                                          | 9,000+         |\n| Soumil Shah              | [Soumil Shah](https://www.linkedin.com/in/shah-soumil/)                                          | 8,000+         |\n| Arnaud Milleker          | [Arnaud Milleker](https://www.linkedin.com/in/arnaudmilleker/)                                    | 7,000+         |\n| Dimitri Visnadi          | [Dimitri Visnadi](https://www.linkedin.com/in/visnadi/)                                    | 7,000+         |\n| Lenny                    | [Lenny A](https://www.linkedin.com/in/lennyardiles/)                                         | 6,000+         |\n| Dipankar Mazumdar        | [Dipankar Mazumdar](https://www.linkedin.com/in/dipankar-mazumdar/)                                 | 5,000+         |\n| Daniel Ciocirlan         | [Daniel Ciocirlan](https://www.linkedin.com/in/danielciocirlan)                                    | 5,000+         |\n| Hugo Lu                  | [Hugo Lu](https://www.linkedin.com/in/hugo-lu-confirmed/)                                           | 5,000+         |\n| Tobias Macey             | [Tobias Macey](https://www.linkedin.com/in/tmacey)                                                 | 5,000+         |\n| Marcos Ortiz             | [Marcos Ortiz](https://www.linkedin.com/in/mlortiz)                                             | 5,000+         |\n| Julien Hurault           | [Julien Hurault](https://www.linkedin.com/in/julienhuraultanalytics/)                               | 5,000+         |\n| John Kutay               | [John Kutay](https://www.linkedin.com/in/johnkutay/)                                               | 5,000+         |\n| Hassaan Akbar            | [Hassaan Akbar](https://www.linkedin.com/in/ehassaan)                                              | 5,000+         |\n| Subhankar                | [Subhankar](https://www.linkedin.com/in/subhankarumass/)                                            | 5,000+         |\n| Nitin                    | [Nitin](https://www.linkedin.com/in/tomernitin29/)                                                        | N/A           |\n| Hassaan                    | [Hassaan](https://www.linkedin.com/in/shassaan/)                                                        | 5000+           |\n| Javier de la Torre             | [Javier](www.linkedin.com/in/javier-de-la-torre-medina)                                                        | 5000+           |\n\n\n#### X/Twitter\n\n| Name              | X/Twitter Profile                                                 | Follower Count |\n|-------------------|------------------------------------------------------------------|---------------:|\n| ByteByteGo        | [alexxubyte](https://twitter.com/alexxubyte/)            | 100,000+       |\n| Dan Kornas        | [@dankornas](https://www.twitter.com/dankornas)           | 66,000+        |\n| Zach Wilson       | [EcZachly](https://www.twitter.com/EcZachly)          | 30,000+        |\n| Seattle Data Guy  | [SeattleDataGuy](https://www.twitter.com/SeattleDataGuy)   | 10,000+        |\n| SQLBI             | [marcorus](https://x.com/marcorus)                       | 10,000+        |\n| Joseph Machado    | [startdataeng](https://twitter.com/startdataeng)         | 5,000+         |\n| Alex Merced       | [@amdatalakehouse](https://www.twitter.com/amdatalakehouse)      | N/A           |\n| John Kutay        | [@JohnKutay](https://x.com/JohnKutay)                            | N/A           |\n| Mehdi Ouazza      | [mehd_io](https://x.com/mehd_io)                                 | N/A           |\n\n\n#### Instagram\n\n| Name           | Instagram Profile                                                                   | Follower Count |\n|----------------|--------------------------------------------------------------------------------------|---------------:|\n| Sundas Khalid  | [sundaskhalidd](https://www.instagram.com/sundaskhalidd)                              | 300,000+       |\n| Zach Wilson    | [eczachly](https://www.instagram.com/eczachly)                             | 150,000+       |\n| Andreas Kretz  | [learndataengineering](https://www.instagram.com/learndataengineering)          | 5,000+         |\n| Alex Merced    | [@alexmercedcoder](https://www.instagram.com/alexmercedcoder)                       | N/A           |\n\n#### TikTok\n\n| Name            | TikTok Profile                                                                   | Follower Count |\n|-----------------|----------------------------------------------------------------------------------|---------------:|\n| Zach Wilson     | [@eczachly](https://www.tiktok.com/@eczachly)                            | 70,000+        |\n| Alex Freberg    | [@alex_the_analyst](https://www.tiktok.com/@alex_the_analyst)             | 10,000+        |\n| Mehdi Ouazza    | [@mehdio_datatv](https://www.tiktok.com/@mehdio_datatv)                          | N/A           |\n\n\n### Great Podcasts\n\n- [The Data Engineering Show](https://www.dataengineeringshow.com/)\n- [Data Engineering Podcast](https://www.dataengineeringpodcast.com/)\n- [DataTopics](https://www.datatopics.io/)\n- [The Data Engineering Side Of Data](https://podcasts.apple.com/us/podcast/the-engineering-side-of-data/id1566999533)\n- [DataWare](https://www.ascend.io/dataaware-podcast/)\n- [The Data Coffee Break Podcast](https://www.deezer.com/us/show/5293247)\n- [The Datastack show](https://datastackshow.com/)\n- [Intricity101 Data Sharks Podcast](https://www.intricity.com/learningcenter/podcast)\n- [Drill to Detail with Mark Rittman](https://www.rittmananalytics.com/drilltodetail/)\n- [Analytics Power Hour](https://analyticshour.io/)\n- [Catalog & cocktails](https://listen.casted.us/public/127/Catalog-%26-Cocktails-2fcf8728)\n- [Datatalks](https://datatalks.club/podcast.html)\n- [Data Brew by Databricks](https://www.databricks.com/discover/data-brew)\n- [The Data Cloud Podcast by Snowflake](https://rise-of-the-data-cloud.simplecast.com/)\n- [What's New in Data](https://www.striim.com/podcast/)\n- [Open||Source||Data by Datastax](https://www.datastax.com/resources/podcast/open-source-data)\n- [Streaming Audio by confluent](https://developer.confluent.io/podcast/)\n- [The Data Scientist Show](https://podcasts.apple.com/us/podcast/the-data-scientist-show/id1584430381)\n- [MLOps.community](https://podcast.mlops.community/)\n- [Monday Morning Data Chat](https://open.spotify.com/show/3Km3lBNzJpc1nOTJUtbtMh)\n- [The Data Chief](https://www.thoughtspot.com/data-chief/podcast)\n\n### Great [list of 20+ newsletters](newsletters.md)\n\nTop must follow newsletters for data engineering:\n- [DataEngineer.io Newsletter](https://blog.dataengineer.io)\n- [Joe Reis](https://joereis.substack.com)\n- [Start Data Engineering](https://www.startdataengineering.com)\n- [Data Engineering Weekly](https://www.dataengineeringweekly.com)\n- [Data Engineer Things](https://dataengineerthings.substack.com/)\n\n### Glossaries:\n- [Data Engineering Vault](https://www.ssp.sh/brain/data-engineering/)\n- [Airbyte Data Glossary](https://glossary.airbyte.com/)\n- [Data Engineering Wiki by Reddit](https://dataengineering.wiki/Index)\n- [Seconda Glossary](https://www.secoda.co/glossary/)\n- [Glossary Databricks](https://www.databricks.com/glossary)\n- [Airtable Glossary](https://airtable.com/shrGh8BqZbkfkbrfk/tbluZ3ayLHC3CKsDb)\n- [Data Engineering Glossary by Dagster](https://dagster.io/glossary)\n\n\n### Design Patterns\n\n- [Cumulative Table Design](https://www.github.com/DataExpert-io/cumulative-table-design)\n- [Microbatch Deduplication](https://www.github.com/EcZachly/microbatch-hourly-deduped-tutorial)\n- [The Little Book of Pipelines](https://www.github.com/EcZachly/little-book-of-pipelines)\n- [Data Developer Platform](https://datadeveloperplatform.org/architecture/)\n\n### Courses / Academies\n\n- [DataExpert.io course](https://www.dataexpert.io) use code **HANDBOOK10** for a discount!\n- [LearnDataEngineering.com](https://www.learndataengineering.com)\n- [Technical Freelancer Academy](https://www.technicalfreelanceracademy.com/) Use code **zwtech** for a discount!\n- [IBM Data Engineering for Everyone](https://www.edx.org/learn/data-engineering/ibm-data-engineering-basics-for-everyone)\n- [Qwiklabs](https://www.qwiklabs.com/)\n- [DataCamp](https://www.datacamp.com/)\n- [Udemy Courses from Shruti Mantri](https://www.udemy.com/user/shruti-mantri-5/)\n- [Rock the JVM](https://rockthejvm.com/) teaches Spark (in Scala), Flink and others\n- [Data Engineering Zoomcamp by DataTalksClub](https://datatalks.club/)\n- [Efficient Data Processing in Spark](https://josephmachado.podia.com/efficient-data-processing-in-spark)\n- [Scaler](https://www.scaler.com/)\n- [DataTeams - Data Engingeer hiring platform](https://www.datateams.ai/)\n- [Udemy Courses from Daniel Blanco](https://danielblanco.dev/links)\n\n### Certifications Courses\n\n- [Google Cloud Certified - Professional Data Engineer](https://cloud.google.com/certification/data-engineer)\n- [Databricks - Certified Associate Developer for Apache Spark](https://www.databricks.com/learn/certification/apache-spark-developer-associate)\n- [Databricks - Data Engineer Associate](https://www.databricks.com/learn/certification/data-engineer-associate)\n- [Databricks - Data Engineer Professional](https://www.databricks.com/learn/certification/data-engineer-professional)\n- [Microsoft DP-203: Data Engineering on Microsoft Azure](https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-203/?tab=tab-learning-paths)\n- [Microsoft DP-600: Fabric Analytics Engineer Associate](https://learn.microsoft.com/credentials/certifications/fabric-analytics-engineer-associate/)\n- [Microsoft DP-700: Fabric Data Engineer Associate](https://learn.microsoft.com/en-us/credentials/certifications/fabric-data-engineer-associate/?practice-assessment-type=certification)\n- [AWS Certified Data Engineer - Associate](https://aws.amazon.com/certification/certified-data-engineer-associate/)\n"
        },
        {
            "url": "https://github.com/rasbt/LLMs-from-scratch",
            "language": "Jupyter Notebook",
            "description": "Implement a ChatGPT-like LLM in PyTorch from scratch, step by step",
            "readme_summary": "# Build a Large Language Model (From Scratch)\n\nThis repository contains the code for developing, pretraining, and finetuning a GPT-like LLM and is the official code repository for the book [Build a Large Language Model (From Scratch)](https://amzn.to/4fqvn0D).\n\n<br>\n<br>\n\n<a href=\"https://amzn.to/4fqvn0D\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover.jpg?123\" width=\"250px\"></a>\n\n<br>\n\nIn [*Build a Large Language Model (From Scratch)*](http://mng.bz/orYv), you'll learn and understand how large language models (LLMs) work from the inside out by coding them from the ground up, step by step. In this book, I'll guide you through creating your own LLM, explaining each stage with clear text, diagrams, and examples.\n\nThe method described in this book for training and developing your own small-but-functional model for educational purposes mirrors the approach used in creating large-scale foundational models such as those behind ChatGPT. In addition, this book includes code for loading the weights of larger pretrained models for finetuning.\n\n- Link to the official [source code repository](https://github.com/rasbt/LLMs-from-scratch)\n- [Link to the book at Manning (the publisher's website)](http://mng.bz/orYv)\n- [Link to the book page on Amazon.com](https://www.amazon.com/gp/product/1633437167)\n- ISBN 9781633437166\n\n<a href=\"http://mng.bz/orYv#reviews\"><img src=\"https://sebastianraschka.com//images/LLMs-from-scratch-images/other/reviews.png\" width=\"220px\"></a>\n\n\n<br>\n<br>\n\nTo download a copy of this repository, click on the [Download ZIP](https://github.com/rasbt/LLMs-from-scratch/archive/refs/heads/main.zip) button or execute the following command in your terminal:\n\n```bash\ngit clone --depth 1 https://github.com/rasbt/LLMs-from-scratch.git\n```\n\n<br>\n\n(If you downloaded the code bundle from the Manning website, please consider visiting the official code repository on GitHub at [https://github.com/rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch) for the latest updates.)\n\n<br>\n<br>\n\n\n# Table of Contents\n\nPlease note that this `README.md` file is a Markdown (`.md`) file. If you have downloaded this code bundle from the Manning website and are viewing it on your local computer, I recommend using a Markdown editor or previewer for proper viewing. If you haven't installed a Markdown editor yet, [Ghostwriter](https://ghostwriter.kde.org) is a good free option.\n\nYou can alternatively view this and other files on GitHub at [https://github.com/rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch) in your browser, which renders Markdown automatically.\n\n<br>\n<br>\n\n\n> **Tip:**\n> If you're seeking guidance on installing Python and Python packages and setting up your code environment, I suggest reading the [README.md](setup/README.md) file located in the [setup](setup) directory.\n\n<br>\n<br>\n\n[![Code tests Linux](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml/badge.svg)](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml)\n[![Code tests Windows](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml/badge.svg)](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml)\n[![Code tests macOS](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml/badge.svg)](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml)\n\n\n\n\n<br>\n\n| Chapter Title                                              | Main Code (for Quick Access)                                                                                                    | All Code + Supplementary      |\n|------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------|-------------------------------|\n| [Setup recommendations](setup)                             | -                                                                                                                               | -                             |\n| Ch 1: Understanding Large Language Models                  | No code                                                                                                                         | -                             |\n| Ch 2: Working with Text Data                               | - [ch02.ipynb](ch02/01_main-chapter-code/ch02.ipynb)<br/>- [dataloader.ipynb](ch02/01_main-chapter-code/dataloader.ipynb) (summary)<br/>- [exercise-solutions.ipynb](ch02/01_main-chapter-code/exercise-solutions.ipynb)               | [./ch02](./ch02)            |\n| Ch 3: Coding Attention Mechanisms                          | - [ch03.ipynb](ch03/01_main-chapter-code/ch03.ipynb)<br/>- [multihead-attention.ipynb](ch03/01_main-chapter-code/multihead-attention.ipynb) (summary) <br/>- [exercise-solutions.ipynb](ch03/01_main-chapter-code/exercise-solutions.ipynb)| [./ch03](./ch03)             |\n| Ch 4: Implementing a GPT Model from Scratch                | - [ch04.ipynb](ch04/01_main-chapter-code/ch04.ipynb)<br/>- [gpt.py](ch04/01_main-chapter-code/gpt.py) (summary)<br/>- [exercise-solutions.ipynb](ch04/01_main-chapter-code/exercise-solutions.ipynb) | [./ch04](./ch04)           |\n| Ch 5: Pretraining on Unlabeled Data                        | - [ch05.ipynb](ch05/01_main-chapter-code/ch05.ipynb)<br/>- [gpt_train.py](ch05/01_main-chapter-code/gpt_train.py) (summary) <br/>- [gpt_generate.py](ch05/01_main-chapter-code/gpt_generate.py) (summary) <br/>- [exercise-solutions.ipynb](ch05/01_main-chapter-code/exercise-solutions.ipynb) | [./ch05](./ch05)              |\n| Ch 6: Finetuning for Text Classification                   | - [ch06.ipynb](ch06/01_main-chapter-code/ch06.ipynb)  <br/>- [gpt_class_finetune.py](ch06/01_main-chapter-code/gpt_class_finetune.py)  <br/>- [exercise-solutions.ipynb](ch06/01_main-chapter-code/exercise-solutions.ipynb) | [./ch06](./ch06)              |\n| Ch 7: Finetuning to Follow Instructions                    | - [ch07.ipynb](ch07/01_main-chapter-code/ch07.ipynb)<br/>- [gpt_instruction_finetuning.py](ch07/01_main-chapter-code/gpt_instruction_finetuning.py) (summary)<br/>- [ollama_evaluate.py](ch07/01_main-chapter-code/ollama_evaluate.py) (summary)<br/>- [exercise-solutions.ipynb](ch07/01_main-chapter-code/exercise-solutions.ipynb) | [./ch07](./ch07)  |\n| Appendix A: Introduction to PyTorch                        | - [code-part1.ipynb](appendix-A/01_main-chapter-code/code-part1.ipynb)<br/>- [code-part2.ipynb](appendix-A/01_main-chapter-code/code-part2.ipynb)<br/>- [DDP-script.py](appendix-A/01_main-chapter-code/DDP-script.py)<br/>- [exercise-solutions.ipynb](appendix-A/01_main-chapter-code/exercise-solutions.ipynb) | [./appendix-A](./appendix-A) |\n| Appendix B: References and Further Reading                 | No code                                                                                                                         | -                             |\n| Appendix C: Exercise Solutions                             | No code                                                                                                                         | -                             |\n| Appendix D: Adding Bells and Whistles to the Training Loop | - [appendix-D.ipynb](appendix-D/01_main-chapter-code/appendix-D.ipynb)                                                          | [./appendix-D](./appendix-D)  |\n| Appendix E: Parameter-efficient Finetuning with LoRA       | - [appendix-E.ipynb](appendix-E/01_main-chapter-code/appendix-E.ipynb)                                                          | [./appendix-E](./appendix-E) |\n\n<br>\n&nbsp;\n\nThe mental model below summarizes the contents covered in this book.\n\n<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/mental-model.jpg\" width=\"650px\">\n\n\n<br>\n&nbsp;\n\n## Prerequisites\n\nThe most important prerequisite is a strong foundation in Python programming.\nWith this knowledge, you will be well prepared to explore the fascinating world of LLMs\nand understand the concepts and code examples presented in this book.\n\nIf you have some experience with deep neural networks, you may find certain concepts more familiar, as LLMs are built upon these architectures.\n\nThis book uses PyTorch to implement the code from scratch without using any external LLM libraries. While proficiency in PyTorch is not a prerequisite, familiarity with PyTorch basics is certainly useful. If you are new to PyTorch, Appendix A provides a concise introduction to PyTorch. Alternatively, you may find my book, [PyTorch in One Hour: From Tensors to Training Neural Networks on Multiple GPUs](https://sebastianraschka.com/teaching/pytorch-1h/), helpful for learning about the essentials.\n\n\n\n<br>\n&nbsp;\n\n## Hardware Requirements\n\nThe code in the main chapters of this book is designed to run on conventional laptops within a reasonable timeframe and does not require specialized hardware. This approach ensures that a wide audience can engage with the material. Additionally, the code automatically utilizes GPUs if they are available. (Please see the [setup](https://github.com/rasbt/LLMs-from-scratch/blob/main/setup/README.md) doc for additional recommendations.)\n\n\n&nbsp;\n## Video Course\n\n[A 17-hour and 15-minute companion video course](https://www.manning.com/livevideo/master-and-build-large-language-models) where I code through each chapter of the book. The course is organized into chapters and sections that mirror the book's structure so that it can be used as a standalone alternative to the book or complementary code-along resource.\n\n<a href=\"https://www.manning.com/livevideo/master-and-build-large-language-models\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/video-screenshot.webp?123\" width=\"350px\"></a>\n\n\n\n&nbsp;\n## Exercises\n\nEach chapter of the book includes several exercises. The solutions are summarized in Appendix C, and the corresponding code notebooks are available in the main chapter folders of this repository (for example,  [./ch02/01_main-chapter-code/exercise-solutions.ipynb](./ch02/01_main-chapter-code/exercise-solutions.ipynb).\n\nIn addition to the code exercises, you can download a free 170-page PDF titled  [Test Yourself On Build a Large Language Model (From Scratch)](https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch) from the Manning website. It contains approximately 30 quiz questions and solutions per chapter to help you test your understanding.\n\n<a href=\"https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/test-yourself-cover.jpg?123\" width=\"150px\"></a>\n\n\n\n&nbsp;\n## Bonus Material\n\nSeveral folders contain optional materials as a bonus for interested readers:\n\n- **Setup**\n  - [Python Setup Tips](setup/01_optional-python-setup-preferences)\n  - [Installing Python Packages and Libraries Used In This Book](setup/02_installing-python-libraries)\n  - [Docker Environment Setup Guide](setup/03_optional-docker-environment)\n- **Chapter 2: Working with text data**\n  - [Byte Pair Encoding (BPE) Tokenizer From Scratch](ch02/05_bpe-from-scratch/bpe-from-scratch.ipynb)\n  - [Comparing Various Byte Pair Encoding (BPE) Implementations](ch02/02_bonus_bytepair-encoder)\n  - [Understanding the Difference Between Embedding Layers and Linear Layers](ch02/03_bonus_embedding-vs-matmul)\n  - [Dataloader Intuition with Simple Numbers](ch02/04_bonus_dataloader-intuition)\n- **Chapter 3: Coding attention mechanisms**\n  - [Comparing Efficient Multi-Head Attention Implementations](ch03/02_bonus_efficient-multihead-attention/mha-implementations.ipynb)\n  - [Understanding PyTorch Buffers](ch03/03_understanding-buffers/understanding-buffers.ipynb)\n- **Chapter 4: Implementing a GPT model from scratch**\n  - [FLOPS Analysis](ch04/02_performance-analysis/flops-analysis.ipynb)\n  - [KV Cache](ch04/03_kv-cache)\n- **Chapter 5: Pretraining on unlabeled data:**\n  - [Alternative Weight Loading Methods](ch05/02_alternative_weight_loading/)\n  - [Pretraining GPT on the Project Gutenberg Dataset](ch05/03_bonus_pretraining_on_gutenberg)\n  - [Adding Bells and Whistles to the Training Loop](ch05/04_learning_rate_schedulers)\n  - [Optimizing Hyperparameters for Pretraining](ch05/05_bonus_hparam_tuning)\n  - [Building a User Interface to Interact With the Pretrained LLM](ch05/06_user_interface)\n  - [Converting GPT to Llama](ch05/07_gpt_to_llama)\n  - [Llama 3.2 From Scratch](ch05/07_gpt_to_llama/standalone-llama32.ipynb)\n  - [Qwen3 Dense and Mixture-of-Experts (MoE) From Scratch](ch05/11_qwen3/)\n  - [Gemma 3 From Scratch](ch05/12_gemma3/)\n  - [Memory-efficient Model Weight Loading](ch05/08_memory_efficient_weight_loading/memory-efficient-state-dict.ipynb)\n  - [Extending the Tiktoken BPE Tokenizer with New Tokens](ch05/09_extending-tokenizers/extend-tiktoken.ipynb)\n  - [PyTorch Performance Tips for Faster LLM Training](ch05/10_llm-training-speed)\n- **Chapter 6: Finetuning for classification**\n  - [Additional experiments finetuning different layers and using larger models](ch06/02_bonus_additional-experiments)\n  - [Finetuning different models on 50k IMDB movie review dataset](ch06/03_bonus_imdb-classification)\n  - [Building a User Interface to Interact With the GPT-based Spam Classifier](ch06/04_user_interface)\n- **Chapter 7: Finetuning to follow instructions**\n  - [Dataset Utilities for Finding Near Duplicates and Creating Passive Voice Entries](ch07/02_dataset-utilities)\n  - [Evaluating Instruction Responses Using the OpenAI API and Ollama](ch07/03_model-evaluation)\n  - [Generating a Dataset for Instruction Finetuning](ch07/05_dataset-generation/llama3-ollama.ipynb)\n  - [Improving a Dataset for Instruction Finetuning](ch07/05_dataset-generation/reflection-gpt4.ipynb)\n  - [Generating a Preference Dataset with Llama 3.1 70B and Ollama](ch07/04_preference-tuning-with-dpo/create-preference-data-ollama.ipynb)\n  - [Direct Preference Optimization (DPO) for LLM Alignment](ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb)\n  - [Building a User Interface to Interact With the Instruction Finetuned GPT Model](ch07/06_user_interface)\n\n<br>\n&nbsp;\n\n## Questions, Feedback, and Contributing to This Repository\n\n\nI welcome all sorts of feedback, best shared via the [Manning Forum](https://livebook.manning.com/forum?product=raschka&page=1) or [GitHub Discussions](https://github.com/rasbt/LLMs-from-scratch/discussions). Likewise, if you have any questions or just want to bounce ideas off others, please don't hesitate to post these in the forum as well.\n\nPlease note that since this repository contains the code corresponding to a print book, I currently cannot accept contributions that would extend the contents of the main chapter code, as it would introduce deviations from the physical book. Keeping it consistent helps ensure a smooth experience for everyone.\n\n\n&nbsp;\n## Citation\n\nIf you find this book or code useful for your research, please consider citing it.\n\nChicago-style citation:\n\n> Raschka, Sebastian. *Build A Large Language Model (From Scratch)*. Manning, 2024. ISBN: 978-1633437166.\n\nBibTeX entry:\n\n```\n@book{build-llms-from-scratch-book,\n  author       = {Sebastian Raschka},\n  title        = {Build A Large Language Model (From Scratch)},\n  publisher    = {Manning},\n  year         = {2024},\n  isbn         = {978-1633437166},\n  url          = {https://www.manning.com/books/build-a-large-language-model-from-scratch},\n  github       = {https://github.com/rasbt/LLMs-from-scratch}\n}\n```\n"
        },
        {
            "url": "https://github.com/enescingoz/awesome-n8n-templates",
            "language": "Unknown",
            "description": "Supercharge your workflow automation with this curated collection of n8n templates! Instantly connect your favorite apps-like Gmail, Telegram, Google Drive, Slack, and more-with ready-to-use, AI-powered automations. Save time, boost productivity, and unlock the true potential of n8n in just a few clicks.",
            "readme_summary": "# n8n_automations\n\n[![English](https://img.shields.io/badge/English-Click-yellow)](README.md)\n[![ä¸­æ–‡æ–‡æ¡£](https://img.shields.io/badge/ä¸­æ–‡æ–‡æ¡£-ç‚¹å‡»æŸ¥çœ‹-orange)](README-zh.md)\n\nThis repository contains a collection of n8n automation templates sourced from the internet. These templates are designed to help automate a wide range of tasks and workflows using [n8n](https://n8n.partnerlinks.io/h1pwwf5m4toe), making it easier for users to discover and use ready-made automations for various platforms and services.\n\nğŸ‘‰ [Join n8n and start automating now! ğŸ’](https://n8n.partnerlinks.io/h1pwwf5m4toe)\n<a href=\"https://n8n.partnerlinks.io/h1pwwf5m4toe\">\n  <img src=\"/img/n8n.png\" alt=\"n8n\" style=\"max-height: 300px;\">\n</a>\n\n\n---\n\n## Disclaimer\nAll automation templates in this repository were found online and are uploaded here solely for easy access and sharing. None of the templates are created or owned by the repository author. If you encounter any issues, errors, or damages resulting from the use of these templates, the repository author assumes no responsibility or liability. All rights to the original templates belong to their respective creators.\n\n---\n\nâ˜• Before diving into the long list of categories and templates, grab your coffee-and if you enjoy my work, donâ€™t forget to buy me a coffee! \n\n<a href=\"https://buymeacoffee.com/enescingoz\" target=\"_blank\"><img src=\"https://cdn.buymeacoffee.com/buttons/default-orange.png\" alt=\"Buy Me A Coffee\" height=\"41\" width=\"174\"></a>\n\n--- \n\n## Categories & Template List\n\n---\n\nğŸ¤– Want to translate, rewrite, and repost Twitter (X) threads automatically?\n\nLooking to effortlessly transform and publish entire Twitter (X) threads in multiple languages?  \nCheck out my [n8n](https://n8n.partnerlinks.io/h1pwwf5m4toe) Twitter Thread (Flood) Translator & Poster workflowâ€”it automates extraction, translation, rewriting, and posting in one seamless process.  \nPerfect for creators, marketers, and anyone aiming to reach new audiences with minimal effort and ultra-low cost!\n\nğŸ‘‰ [Try the workflow here](https://n8n.io/workflows/4233-translate-and-repost-twitter-threads-in-multiple-languages-with-openai/)\n\n---\n\n## ğŸ§µ If you want to scrape Twitter (X) threads, definitely check this workflow\n\nLooking to extract and merge entire Twitter (X) threads quickly and affordably?  \nCheck out my [n8n Twitter Thread Fetcher workflow](https://n8n.io/workflows/4088-extract-and-merge-twitter-x-threads-using-twitterapiio/)-itâ€™s lightning-fast, cost-effective, and perfect for automating Twitter thread extraction for research, content curation, or archiving!\n\n---\n### Gmail & Email Automation\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Auto-label incoming Gmail messages with AI nodes | Automatically labels incoming Gmail messages using AI. The workflow retrieves message content, suggests labels like Partnership or Inquiry, and assigns them for better organization. | Ops | [Link to Template](Gmail_and_Email_Automation/Auto-label%20incoming%20Gmail%20messages%20with%20AI%20nodes.json) |\n| Basic Automatic Gmail Email Labelling with OpenAI and Gmail API | Uses OpenAI and Gmail API to trigger on new emails, analyze content, and assign or create labels automatically. Helps categorize emails efficiently using AI. | Ops | [Link to Template](Gmail_and_Email_Automation/Basic%20Automatic%20Gmail%20Email%20Labelling%20with%20OpenAI%20and%20Gmail%20API.json) |\n| Compose reply draft in Gmail with OpenAI Assistant | Generates draft replies in Gmail using OpenAI. Triggers on new emails, extracts content, and creates a suggested reply draft to streamline responses. | Executive | [Link to Template](Gmail_and_Email_Automation/Compose%20reply%20draft%20in%20Gmail%20with%20OpenAI%20Assistant.json) |\n| Analyze & Sort Suspicious Email Contents with ChatGPT | Analyzes suspicious emails using ChatGPT, classifies them, and can generate screenshots for review. Helps identify and sort potentially dangerous emails. | Security | [Link to Template](Gmail_and_Email_Automation/Analyze%20&%20Sort%20Suspicious%20Email%20Contents%20with%20ChatGPT.json) |\n| Analyze Suspicious Email Contents with ChatGPT Vision | Uses both text and image analysis (ChatGPT Vision) to evaluate suspicious emails. Extracts screenshots, analyzes headers and content, and flags phishing attempts. | Security | [Link to Template](Gmail_and_Email_Automation/Analyze%20Suspicious%20Email%20Contents%20with%20ChatGPT%20Vision.json) |\n| A Very Simple \"Human in the Loop\" Email Response System Using AI and IMAP | Implements a simple workflow for human-in-the-loop email responses. Uses IMAP to fetch emails, summarizes content with AI, and drafts professional replies for review before sending. | Support | [Link to Template](Gmail_and_Email_Automation/A%20Very%20Simple%20_Human%20in%20the%20Loop_%20Email%20Response%20System%20Using%20AI%20and%20IMAP.json) |\n| Auto Categorise Outlook Emails with AI | Automatically categorizes Outlook emails using AI models. Moves messages to folders and assigns categories based on content, reducing manual sorting. | Ops | [Link to Template](Gmail_and_Email_Automation/Auto%20Categorise%20Outlook%20Emails%20with%20AI.json) |\n| Microsoft Outlook AI Email Assistant with contact support from Monday and Airtable | An AI-powered assistant for Outlook that processes emails, sanitizes content, and assigns categories using rules from Airtable. Integrates with Monday.com for contact support. | Ops | [Link to Template](Gmail_and_Email_Automation/Microsoft%20Outlook%20AI%20Email%20Assistant%20with%20contact%20support%20from%20Monday%20and%20Airtable.json) |\n| ğŸ“ˆ Receive Daily Market News from FT.com to your Microsoft outlook inbox | Extracts financial news from FT.com and delivers daily updates to your Outlook inbox. Automates content extraction and email delivery for timely market insights. | Executive | [Link to Template](Gmail_and_Email_Automation/ğŸ“ˆ%20Receive%20Daily%20Market%20News%20from%20FT.com%20to%20your%20Microsoft%20outlook%20inbox.json) |\n\n### Telegram\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Agentic Telegram AI bot with LangChain nodes and new tools | An advanced Telegram bot leveraging LangChain and OpenAI for conversational AI. Supports memory, dynamic tool use, and handles incoming events for rich, context-aware chat interactions. | Support | [Link to Template](Telegram/Agentic%20Telegram%20AI%20bot%20with%20with%20LangChain%20nodes%20and%20new%20tools.json) |\n| AI-Powered Childrenâ€™s Arabic Storytelling on Telegram | A Telegram bot that uses OpenAI to generate and narrate childrenâ€™s stories in Arabic, making storytelling interactive and educational for young users. | Support | [Link to Template](Telegram/AI-Powered%20Children_s%20Arabic%20Storytelling%20on%20Telegram.json) |\n| AI-Powered Childrenâ€™s English Storytelling on Telegram with OpenAI | Creates and tells childrenâ€™s stories in English using OpenAI to engage young audiences in an interactive way. | Support | [Link to Template](Telegram/AI-Powered%20Children_s%20English%20Storytelling%20on%20Telegram%20with%20OpenAI.json) |\n| Automated AI image analysis and response via Telegram | Lets users send images to Telegram and receive AI-based analysis and feedback automatically. | Ops | [Link to Template](Telegram/Automated%20AI%20image%20analysis%20and%20response%20via%20Telegram.json) |\n| Angie, Personal AI Assistant with Telegram Voice and Text | Personal voice & text assistant bot that answers queries, manages tasks, and interacts naturally using AI. | Support | [Link to Template](Telegram/Angie,%20Personal%20AI%20Assistant%20with%20Telegram%20Voice%20and%20Text.json) |\n| Chat with OpenAIâ€™s GPT via a simple Telegram Bot | A minimal Telegram bot that forwards user messages to GPT and returns AI-generated replies. Ideal starting point for AI chat. | Support | [Link to Template](Telegram/Chat%20with%20OpenAIs%20GPT%20via%20a%20simple%20Telegram%20Bot.json) |\n| Telegram AI bot assistant: ready-made template for voice & text messages | Ready-made assistant bot handling both voice and text input, leveraging AI for smart conversational responses in Telegram. | Support | [Link to Template](Telegram/Telegram%20AI%20bot%20assistant_%20ready-made%20template%20for%20voice%20&%20text%20messages.json) |\n| Telegram AI Bot: NeurochainAI Text & Image | Integrates NeurochainAI API for text and image generation inside Telegram, enabling creative media interactions. | Marketing | [Link to Template](Telegram/Telegram%20AI%20Bot_%20NeurochainAI%20Text%20&%20Image%20-%20NeurochainAI%20Basic%20API%20Integration.json) |\n| Telegram AI bot with LangChain nodes | Uses LangChain nodes for advanced AI conversations and tool use in Telegram. | Support | [Link to Template](Telegram/Telegram%20AI%20bot%20with%20LangChain%20nodes.json) |\n| Telegram AI Chatbot | A general-purpose AI chatbot template for Telegram that can be customized for various use cases. | Support | [Link to Template](Telegram/Telegram%20AI%20Chatbot.json) |\n| Telegram Bot with Supabase memory and OpenAI assistant integration | Adds long-term memory with Supabase to a Telegram bot, coupled with OpenAI for rich, context-aware conversations. | Support | [Link to Template](Telegram/Telegram%20Bot%20with%20Supabase%20memory%20and%20OpenAI%20assistant%20integration.json) |\n| Telegram chat with PDF | Allows users to upload a PDF to Telegram and chat with its contents using AI-powered summarization and Q&A. | Ops | [Link to Template](Telegram/Telegram%20chat%20with%20PDF.json) |\n| ğŸ¤– Telegram Messaging Agent for Text_Audio_Images | Multi-modal agent that processes text, audio, and images in Telegram chats using AI for responses. | Support | [Link to Template](Telegram/%F0%9F%A4%96%20Telegram%20Messaging%20Agent%20for%20Text_Audio_Images.json) |\n| Telegram to Spotify with OpenAI | Lets users request songs or playlists in Telegram and automatically create them in Spotify via OpenAI. | Marketing | [Link to Template](Telegram/Telegram%20to%20Spotify%20with%20OpenAI.json) |\n| Send a random recipe once a day to Telegram | Scheduled workflow that fetches a random recipe daily and posts it to a Telegram chat. | Marketing | [Link to Template](Telegram/Send%20a%20random%20recipe%20once%20a%20day%20to%20Telegram.json) |\n| Detect toxic language in Telegram messages | Monitors Telegram chats and flags messages containing toxic language using AI moderation. | Security | [Link to Template](Telegram/Detect%20toxic%20language%20in%20Telegram%20messages.json) |\n| Translate Telegram audio messages with AI (55 supported languages) | Receives voice messages, transcribes them, and sends back translations in over 50 languages. | Support | [Link to Template](Telegram/Translate%20Telegram%20audio%20messages%20with%20AI%20(55%20supported%20languages).json) |\n| Empower Your AI Chatbot with Long-Term Memory and Dynamic Tool Routing | External workflow enhancing an AI chatbot with long-term memory and dynamic tool routing capabilities. | Support | [Link to Template](https://n8n.io/workflows/3025-empower-your-ai-chatbot-with-long-term-memory-and-dynamic-tool-routing/) |\n\n### Google Drive & Google Sheets\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Automated End-to-End Fine-Tuning of OpenAI Models with Google Drive Integration | Automates the fine-tuning of OpenAI models by integrating with Google Drive for data input and output, streamlining custom AI model training. | Engineering | [Link to Template](Google_Drive_and_Google_Sheets/Automated%20End-to-End%20Fine-Tuning%20of%20OpenAI%20Models%20with%20Google%20Drive%20Integration.json) |\n| Automatic Background Removal for Images in Google Drive | Automatically removes backgrounds from images stored in Google Drive, preparing them for various uses like product catalogs or marketing materials. | Marketing | [Link to Template](Google_Drive_and_Google_Sheets/Automatic%20Background%20Removal%20for%20Images%20in%20Google%20Drive.json) |\n| Build an OpenAI Assistant with Google Drive Integration | Demonstrates building an OpenAI Assistant that accesses and utilizes files in Google Drive, enabling it to answer questions or perform tasks based on document content. | Support | [Link to Template](Google_Drive_and_Google_Sheets/Build%20an%20OpenAI%20Assistant%20with%20Google%20Drive%20Integration.json) |\n| RAG Chatbot for Company Documents using Google Drive and Gemini | Creates a Retrieval-Augmented Generation (RAG) chatbot that answers questions based on company documents stored in Google Drive, leveraging Google Gemini. | Support | [Link to Template](Google_Drive_and_Google_Sheets/RAG%20Chatbot%20for%20Company%20Documents%20using%20Google%20Drive%20and%20Gemini.json) |\n| RAG_Context-Aware Chunking: Google Drive to Pinecone via OpenRouter & Gemini | Implements context-aware chunking for Google Drive documents, sending them to Pinecone for vector storage and using OpenRouter & Gemini for advanced RAG. | Engineering | [Link to Template](Google_Drive_and_Google_Sheets/RAG_Context-Aware%20Chunking%20_%20Google%20Drive%20to%20Pinecone%20via%20OpenRouter%20&%20Gemini.json) |\n| Summarize the New Documents from Google Drive and Save Summary in Google Sheet | Monitors Google Drive for new documents, summarizes their content using AI, and saves these summaries into a Google Sheet for quick overview and analysis. | Ops | [Link to Template](Google_Drive_and_Google_Sheets/Summarize%20the%20New%20Documents%20from%20Google%20Drive%20and%20Save%20Summary%20in%20Google%20Sheet.json) |\n| Upload to Instagram and Tiktok from Google Drive | Automates uploading media from Google Drive directly to Instagram and TikTok, streamlining social media content publishing. | Marketing | [Link to Template](Google_Drive_and_Google_Sheets/Upload%20to%20Instagram%20and%20Tiktok%20from%20Google%20Drive.json) |\n| Author and Publish Blog Posts From Google Sheets | Enables authoring blog posts in Google Sheets and automatically publishing them to a content management system, simplifying content creation and publishing. | Marketing | [Link to Template](Google_Drive_and_Google_Sheets/Author%20and%20Publish%20Blog%20Posts%20From%20Google%20Sheets.json) |\n| Chat with a Google Sheet using AI | Allows users to interact with and query data within a Google Sheet using natural language via an AI model, making data analysis more accessible. | Ops | [Link to Template](Google_Drive_and_Google_Sheets/Chat%20with%20a%20Google%20Sheet%20using%20AI.json) |\n| Chat with your event schedule from Google Sheets in Telegram | Connects a Google Sheet containing an event schedule to Telegram, allowing users to query their schedule through a Telegram bot. | Ops | [Link to Template](Google_Drive_and_Google_Sheets/Chat%20with%20your%20event%20schedule%20from%20Google%20Sheets%20in%20Telegram.json) |\n| Qualify new leads in Google Sheets via OpenAIâ€™s GPT-4 | Uses OpenAI's GPT-4 to analyze and qualify new leads entered into a Google Sheet, helping sales teams prioritize their outreach. | Sales | [Link to Template](Google_Drive_and_Google_Sheets/Qualify%20new%20leads%20in%20Google%20Sheets%20via%20OpenAI_s%20GPT-4.json) |\n| Screen Applicants With AI, notify HR and save them in a Google Sheet | Automates the screening of job applicants using AI, notifies HR of qualified candidates, and saves applicant data into a Google Sheet. | HR | [Link to Template](Google_Drive_and_Google_Sheets/Screen%20Applicants%20With%20AI,%20notify%20HR%20and%20save%20them%20in%20a%20Google%20Sheet.json) |\n| Summarize Google Sheets form feedback via OpenAIâ€™s GPT-4 | Summarizes feedback collected through Google Forms and stored in Google Sheets using OpenAI's GPT-4, providing quick insights from survey responses. | Marketing | [Link to Template](Google_Drive_and_Google_Sheets/Summarize%20Google%20Sheets%20form%20feedback%20via%20OpenAI_s%20GPT-4.json) |\n\n---\n\n*More sections and tables can be added below as the project expands.\n\n### WordPress\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Auto-Categorize blog posts in wordpress using A.I. | This workflow automates the categorization of WordPress blog posts using AI, streamlining content organization and management. | Marketing/Content | [Link to Template](WordPress/Auto-Categorize%20blog%20posts%20in%20wordpress%20using%20A.I..json) |\n| Auto-Tag Blog Posts in WordPress with AI | This workflow automatically tags WordPress blog posts using AI, improving SEO and content discoverability. | Marketing/Content | [Link to Template](WordPress/Auto-Tag%20Blog%20Posts%20in%20WordPress%20with%20AI.json) |\n| Automate Blog Creation in Brand Voice with AI | This workflow automates the creation of blog posts, ensuring they adhere to a specific brand voice using AI. | Marketing/Content | [Link to Template](WordPress/Automate%20Blog%20Creation%20in%20Brand%20Voice%20with%20AI.json) |\n| Automate Content Generator for WordPress with DeepSeek R1 | This workflow automates content generation for WordPress using the DeepSeek R1 AI model, enabling rapid content creation. | Marketing/Content | [Link to Template](WordPress/Automate%20Content%20Generator%20for%20WordPress%20with%20DeepSeek%20R1.json) |\n| WordPress - AI Chatbot to enhance user experience - with Supabase and OpenAI | This workflow integrates an AI chatbot into WordPress using Supabase and OpenAI to enhance user experience by providing intelligent interactions. | Customer Support/Marketing | [Link to Template](WordPress/WordPress%20-%20AI%20Chatbot%20to%20enhance%20user%20experience%20-%20with%20Supabase%20and%20OpenAI.json) |\n\n### PDF & Document Processing\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Ask questions about a PDF using AI | This workflow fetches a PDF from Google Drive, splits it into chunks, embeds the chunks using OpenAI embeddings, and enables chat interactions with the document content. | Customer Support/Knowledge Management | [Link to Template](PDF_and_Document_Processing/Ask%20questions%20about%20a%20PDF%20using%20AI.json) |\n| Breakdown Documents into Study Notes using Templating MistralAI and Qdrant | This workflow triggers on new files, processes documents with MistralAI embeddings, and stores data in Qdrant vector store for study note generation. | Education/Knowledge Management | [Link to Template](PDF_and_Document_Processing/Breakdown%20Documents%20into%20Study%20Notes%20using%20Templating%20MistralAI%20and%20Qdrant.json) |\n| CV Resume PDF Parsing with Multimodal Vision AI | This workflow converts candidate resume PDFs to images, uses a Vision Language Model to assess candidate fit, and includes logic to bypass hidden AI prompts in resumes. | HR | [Link to Template](PDF_and_Document_Processing/CV%20Resume%20PDF%20Parsing%20with%20Multimodal%20Vision%20AI.json) |\n| Chat with PDF docs using AI (quoting sources) | This workflow enables chat interactions with PDF documents, allowing users to ask questions and receive answers with quoted sources from the document. | Customer Support/Knowledge Management | [Link to Template](PDF_and_Document_Processing/Chat%20with%20PDF%20docs%20using%20AI%20(quoting%20sources).json) |\n| Convert URL HTML to Markdown Format and Get Page Links | This workflow converts HTML content from a given URL into Markdown format and extracts all page links, useful for content scraping and analysis. | Marketing/Content | [Link to Template](PDF_and_Document_Processing/Convert%20URL%20HTML%20to%20Markdown%20Format%20and%20Get%20Page%20Links.json) |\n| ETL pipeline for text processing | This workflow implements an ETL pipeline for text processing, extracting data from Twitter, storing it in MongoDB and PostgreSQL, and sending alerts to Slack based on sentiment analysis. | Data Analytics/IT | [Link to Template](PDF_and_Document_Processing/ETL%20pipeline%20for%20text%20processing.json) |\n| Extract and process information directly from PDF using Claude and Gemini | This workflow extracts and processes information directly from PDFs using advanced AI models like Claude and Gemini, enabling intelligent document analysis. | Data Extraction/IT | [Link to Template](PDF_and_Document_Processing/Extract%20and%20process%20information%20directly%20from%20PDF%20using%20Claude%20and%20Gemini.json) |\n| Extract data from resume and create PDF with Gotenberg | This workflow extracts structured data from resumes using AI, converts it into HTML, and then generates a well-formatted PDF using Gotenberg. | HR | [Link to Template](PDF_and_Document_Processing/Extract%20data%20from%20resume%20and%20create%20PDF%20with%20Gotenberg.json) |\n| Extract license plate number from image uploaded via an n8n form | This workflow extracts license plate numbers from images uploaded via an n8n form using a Vision Language Model, then displays the extracted information. | Operations/Logistics | [Link to Template](PDF_and_Document_Processing/Extract%20license%20plate%20number%20from%20image%20uploaded%20via%20an%20n8n%20form.json) |\n| Extract text from PDF and image using Vertex AI (Gemini) into CSV | This workflow extracts text from PDFs and images using Vertex AI (Gemini), routes based on file type, and converts the extracted data into a CSV format. | Data Extraction/IT | [Link to Template](PDF_and_Document_Processing/Extract%20text%20from%20PDF%20and%20image%20using%20Vertex%20AI%20(Gemini)%20into%20CSV.json) |\n| Invoice data extraction with LlamaParse and OpenAI | This workflow extracts structured data from invoices using LlamaParse and OpenAI, then processes it with a structured output parser for detailed invoice data extraction. | Finance/Admin | [Link to Template](PDF_and_Document_Processing/Invoice%20data%20extraction%20with%20LlamaParse%20and%20OpenAI.json) |\n| Write a WordPress post with AI (starting from a few keywords) | This workflow uses AI to write WordPress posts based on a few keywords, simplifying the content creation process. | Marketing/Content | [Link to Template](WordPress/Write%20a%20WordPress%20post%20with%20AI%20(starting%20from%20a%20few%20keywords).json) |\n\n### Discord\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Discord AI-powered bot | This workflow creates an AI-powered Discord bot that categorizes user messages (success story, urgent issue, ticket) and routes them to the appropriate department (customer success, IT, customer support). | Customer Support | [Link to Template](Discord/Discord%20AI-powered%20bot.json) |\n| Send daily translated Calvin and Hobbes Comics to Discord | This workflow automates the daily retrieval of Calvin and Hobbes comics, translates the dialogues into English and Korean (or other languages), and posts them to Discord. | Marketing/Content | [Link to Template](Discord/Send%20daily%20translated%20Calvin%20and%20Hobbes%20Comics%20to%20Discord.json) |\n| Share YouTube Videos with AI Summaries on Discord | This workflow automatically shares new YouTube videos on Discord along with AI-generated summaries of their content, leveraging caption data. | Marketing | [Link to Template](Discord/Share%20YouTube%20Videos%20with%20AI%20Summaries%20on%20Discord.json) |\n\n### Database & Storage\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Chat with Postgresql Database | This workflow enables an AI assistant to chat with a PostgreSQL database, allowing users to query and retrieve data using natural language. It supports custom SQL queries and schema introspection. | Data Analytics | [Link to Template](Database_and_Storage/Chat%20with%20Postgresql%20Database.json) |\n| Generate SQL queries from schema only - AI-powered | This workflow uses AI to generate SQL queries based on a given database schema, making it easier to interact with databases without manual query writing. | Engineering | [Link to Template](Database_and_Storage/Generate%20SQL%20queries%20from%20schema%20only%20-%20AI-powered.json) |\n| MongoDB AI Agent - Intelligent Movie Recommendations | This workflow creates an AI agent that provides intelligent movie recommendations by interacting with a MongoDB database, using aggregation pipelines to fetch relevant movie data. | Data Analytics | [Link to Template](Database_and_Storage/MongoDB%20AI%20Agent%20-%20Intelligent%20Movie%20Recommendations.json) |\n| Supabase Insertion & Upsertion & Retrieval | This workflow demonstrates how to perform insertion, upsertion, and retrieval operations with Supabase, specifically for handling vector embeddings and associated metadata. | Engineering | [Link to Template](Database_and_Storage/Supabase%20Insertion%20&%20Upsertion%20&%20Retrieval.json) |\n| Talk to your SQLite database with a LangChain AI Agent | This workflow allows users to interact with a SQLite database using a LangChain AI agent, enabling natural language queries and data retrieval from the database. | Data Analytics | [Link to Template](Database_and_Storage/Talk%20to%20your%20SQLite%20database%20with%20a%20LangChain%20AI%20Agent.json) |\n\n### Airtable\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| AI Agent for project management and meetings with Airtable and Fireflies | This workflow uses an AI agent to automate project management tasks and meeting follow-ups by analyzing call transcripts from Fireflies. It creates tasks in Airtable and notifies clients about their tasks. | Operations | [Link to Template](Airtable/AI%20Agent%20for%20project%20management%20and%20meetings%20with%20Airtable%20and%20Fireflies.json) |\n| AI Agent to chat with Airtable and analyze data | This workflow creates an AI agent that can chat with Airtable, analyze data, and perform queries based on user requests. It can handle aggregation functions and generate graphs/images. | Data Analytics | [Link to Template](Airtable/AI%20Agent%20to%20chat%20with%20Airtable%20and%20analyze%20data.json) |\n| Get Airtable data via AI and Obsidian Notes | This workflow retrieves data from Airtable using an AI agent and integrates it with Obsidian Notes, allowing for seamless data access and organization within Obsidian. | Productivity | [Link to Template](Airtable/Get%20Airtable%20data%20via%20AI%20and%20Obsidian%20Notes.json) |\n| Handling Job Application Submissions with AI and n8n Forms | This workflow automates the handling of job application submissions by extracting information from resumes (PDFs) using AI, parsing it into a structured format, and potentially storing it in Airtable. | HR | [Link to Template](Airtable/Handling%20Job%20Application%20Submissions%20with%20AI%20and%20n8n%20Forms.json) |\n| vAssistant for Hubspot Chat using OpenAi and Airtable | This workflow integrates an OpenAI assistant with HubSpot Chat and Airtable to provide automated responses and manage customer interactions. It fetches chat messages, processes them with AI, and can store relevant information in Airtable. | Sales | [Link to Template](Airtable/vAssistant%20for%20Hubspot%20Chat%20using%20OpenAi%20and%20Airtable.json) |\n\n### Notion\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Add positive feedback messages to a table in Notion | Captures positive feedback from Typeform, analyzes sentiment with Google Cloud Natural Language, and adds it to a Notion table, with Slack notifications for high-scoring feedback. | Support | [Link to Template](Notion/Add%20positive%20feedback%20messages%20to%20a%20table%20in%20Notion.json) |\n| Analyse papers from Hugging Face with AI and store them in Notion | Automatically fetches and analyzes papers from Hugging Face, extracts key information using AI, and stores the structured data in a Notion database. | Engineering | [Link to Template](Notion/Analyse%20papers%20from%20Hugging%20Face%20with%20AI%20and%20store%20them%20in%20Notion.json) |\n| Automate Competitor Research with Exa.ai, Notion and AI Agents | Builds a competitor research agent using Exa.ai to find similar companies. AI agents then scour the internet for company overviews, product offerings, and customer reviews, compiling a report into a Notion table. | Marketing | [Link to Template](Notion/Automate%20Competitor%20Research%20with%20Exa.ai,%20Notion%20and%20AI%20Agents.json) |\n| Automate LinkedIn Outreach with Notion and OpenAI | Automates LinkedIn outreach by fetching daily posts from a Notion database, formatting them with OpenAI for LinkedIn engagement, and then posting them to LinkedIn. | Marketing | [Link to Template](Notion/Automate%20LinkedIn%20Outreach%20with%20Notion%20and%20OpenAI.json) |\n| Notion AI Assistant Generator | Generates a custom AI Assistant chatbot workflow for a specific Notion database schema, allowing users to chat with their Notion data. | Engineering | [Link to Template](Notion/Notion%20AI%20Assistant%20Generator.json) |\n| Notion knowledge base AI assistant | Creates an AI assistant that can search and retrieve information from a Notion knowledge base, providing answers to user queries. | Support | [Link to Template](Notion/Notion%20knowledge%20base%20AI%20assistant.json) |\n| Notion to Pinecone Vector Store Integration | Integrates Notion with Pinecone, allowing Notion pages to be converted into vector embeddings and stored in Pinecone for advanced search and retrieval. | Engineering | [Link to Template](Notion/Notion%20to%20Pinecone%20Vector%20Store%20Integration.json) |\n| Store Notionâ€™s Pages as Vector Documents into Supabase with OpenAI | Automates storing Notion pages as vector documents in a Supabase database, using OpenAI to generate embeddings for the content. | Engineering | [Link to Template](Notion/Store%20Notion_s%20Pages%20as%20Vector%20Documents%20into%20Supabase%20with%20OpenAI.json) |\n| Turn Emails into AI-Enhanced Tasks in Notion (Multi-User Support) with Gmail, Airtable and Softr | Transforms emails into AI-enhanced tasks in Notion, supporting multiple users. It integrates with Gmail for email triggers, Airtable for routing, and Softr for a user interface. | Ops | [Link to Template](Notion/Turn%20Emails%20into%20AI-Enhanced%20Tasks%20in%20Notion%20(Multi-User%20Support)%20with%20Gmail,%20Airtable%20and%20Softr.json) |\n| Upsert huge documents in a vector store with Supabase and Notion | Manages large documents by splitting them into chunks, generating embeddings, and upserting them into a Supabase vector store, with Notion serving as the document source. | Engineering | [Link to Template](Notion/Upsert%20huge%20documents%20in%20a%20vector%20store%20with%20Supabase%20and%20Notion.json) |\n\n### Slack\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| AI-Powered Information Monitoring with OpenAI, Google Sheets, Jina AI and Slack | Monitors RSS feeds, summarizes articles with OpenAI and Jina AI, classifies them, and sends formatted notifications to Slack, enabling AI-powered information monitoring. | Marketing | [Link to Template](Slack/AI-Powered%20Information%20Monitoring%20with%20OpenAI,%20Google%20Sheets,%20Jina%20AI%20and%20Slack.json) |\n| Creating a AI Slack Bot with Google Gemini | Builds an AI Slack bot using Google Gemini, handling webhooks, integrating an AI agent, managing memory, and responding to Slack messages. | Engineering | [Link to Template](Slack/Creating%20a%20AI%20Slack%20Bot%20with%20Google%20Gemini.json) |\n| Customer Support Channel and Ticketing System with Slack and Linear | Automates customer support by querying Slack for messages with a ticket emoji, deciding if a new Linear ticket is needed, creating or updating tickets, and notifying Slack. | Support | [Link to Template](Slack/Customer%20Support%20Channel%20and%20Ticketing%20System%20with%20Slack%20and%20Linear.json) |\n| Enhance Security Operations with the Qualys Slack Shortcut Bot! | Creates a Slack shortcut bot for Qualys to enhance security operations, allowing users to trigger actions like creating reports or starting vulnerability scans directly from Slack. | Security | [Link to Template](Slack/Enhance%20Security%20Operations%20with%20the%20Qualys%20Slack%20Shortcut%20Bot!.json) |\n| Enrich Pipedrive's Organization Data with OpenAI GPT-4o & Notify it in Slack | Enriches Pipedrive organization data by scraping website content, using OpenAI GPT-4o to generate a summary, and adding it as a note in Pipedrive, then notifying a Slack channel. | Sales | [Link to Template](Slack/Enrich%20Pipedrive_s%20Organization%20Data%20with%20OpenAI%20GPT-4o%20&%20Notify%20it%20in%20Slack.json) |\n| IT Ops AI SlackBot Workflow - Chat with your knowledge base | Creates an AI Slackbot for IT Operations, enabling users to chat with a knowledge base to retrieve information and get answers directly within Slack. | IT | [Link to Template](Slack/IT%20Ops%20AI%20SlackBot%20Workflow%20-%20Chat%20with%20your%20knowledge%20base.json) |\n| Sentiment Analysis Tracking on Support Issues with Linear and Slack | Tracks sentiment on support issues by integrating with Linear and Slack, performing sentiment analysis using OpenAI on Linear comments, and notifying relevant Slack channels. | Support | [Link to Template](Slack/Sentiment%20Analysis%20Tracking%20on%20Support%20Issues%20with%20Linear%20and%20Slack.json) |\n| Slack slash commands AI Chat Bot | Implements an AI chatbot accessible via Slack slash commands, processing user commands, interacting with an AI model, and responding within Slack. | IT | [Link to Template](Slack/Slack%20slash%20commands%20AI%20Chat%20Bot.json) |\n| Venafi Cloud Slack Cert Bot | Provides a Slack bot that interacts with Venafi Cloud for certificate management, allowing users to check certificate status, receive alerts, or request certificate actions via Slack. | Security | [Link to Template](Slack/Venafi%20Cloud%20Slack%20Cert%20Bot.json) |*\n\n### OpenAI & LLMs\n\n| Title | Description | Department | Link |\n|---|---|---|---|\n| Advanced AI Demo (Presented at AI Developers #14 meetup) | Advanced AI capabilities demo. | AI/Development | [Link to Template](OpenAI_and_LLMs/Advanced%20AI%20Demo%20(Presented%20at%20AI%20Developers%20%2314%20meetup).json) |\n| AI agent chat | Basic AI chat agent. | AI/Customer Service | [Link to Template](OpenAI_and_LLMs/AI%20agent%20chat.json) |\n| AI agent that can scrape webpages | AI agent for web scraping. | AI/Data Extraction | [Link to Template](OpenAI_and_LLMs/AI%20agent%20that%20can%20scrape%20webpages.json) |\n| AI Crew to Automate Fundamental Stock Analysis - Q&A Workflow | Stock analysis automation. | Finance/AI/Data Analysis | [Link to Template](OpenAI_and_LLMs/AI%20Crew%20to%20Automate%20Fundamental%20Stock%20Analysis%20-%20Q&A%20Workflow.json) |\n| AI Customer feedback sentiment analysis | Sentiment analysis on customer feedback. | Customer Service/Marketing/Data Analysis | [Link to Template](OpenAI_and_LLMs/AI%20Customer%20feedback%20sentiment%20analysis.json) |\n| AI Data Extraction with Dynamic Prompts and Airtable | AI-driven data extraction with Airtable integration. | AI/Data Extraction/Database | [Link to Template](OpenAI_and_LLMs/AI%20Data%20Extraction%20with%20Dynamic%20Prompts%20and%20Airtable.json) |\n| AI Data Extraction with Dynamic Prompts and Baserow | AI-driven data extraction with Baserow integration. | AI/Data Extraction/Database | [Link to Template](OpenAI_and_LLMs/AI%20Data%20Extraction%20with%20Dynamic%20Prompts%20and%20Baserow.json) |\n| AI-Driven Lead Management and Inquiry Automation with ERPNext & n8n | Lead management automation. | Sales/CRM/AI | [Link to Template](OpenAI_and_LLMs/AI-Driven%20Lead%20Management%20and%20Inquiry%20Automation%20with%20ERPNext%20&%20n8n.json) |\n| AI Fitness Coach Strava Data Analysis and Personalized Training Insights | Fitness coaching via Strava data analysis. | Fitness/AI/Data Analysis | [Link to Template](OpenAI_and_LLMs/AI%20Fitness%20Coach%20Strava%20Data%20Analysis%20and%20Personalized%20Training%20Insights.json) |\n| AI-Powered Candidate Shortlisting Automation for ERPNext | Candidate shortlisting automation. | HR/AI/Recruitment | [Link to Template](OpenAI_and_LLMs/AI-Powered%20Candidate%20Shortlisting%20Automation%20for%20ERPNext.json) |\n| AI-Powered Email Automation for Business: Summarize & Respond with RAG | Email automation with summarization and response. | Business Automation/AI/Communication | [Link to Template](OpenAI_and_LLMs/AI-Powered%20Email%20Automation%20for%20Business_%20Summarize%20&%20Respond%20with%20RAG.json) |\n| AI-Powered RAG Workflow For Stock Earnings Report Analysis | Stock earnings report analysis with RAG. | Finance/AI/Data Analysis | [Link to Template](OpenAI_and_LLMs/AI-Powered%20RAG%20Workflow%20For%20Stock%20Earnings%20Report%20Analysis.json) |\n| AI-Powered Social Media Amplifier | Amplifies social media presence using AI. | Marketing/AI/Social Media | [Link to Template](OpenAI_and_LLMs/AI-Powered%20Social%20Media%20Amplifier.json) |\n| AI-powered WooCommerce Support-Agent | Creates an AI-powered support agent for WooCommerce stores. | E-commerce/AI/Customer Service | [Link to Template](OpenAI_and_LLMs/AI-powered%20WooCommerce%20Support-Agent.json) |\n| AI-Powered YouTube Video Summarization & Analysis | Summarizes and analyzes YouTube videos using AI. | Content Creation/AI/Data Analysis | [Link to Template](OpenAI_and_LLMs/%E2%9A%A1AI-Powered%20YouTube%20Video%20Summarization%20&%20Analysis.json) |\n| AI: Ask questions about any data source (using the n8n workflow retriever) | Allows users to ask questions about various data sources using an n8n workflow retriever. | AI/Data Analysis/Workflow Automation | [Link to Template](OpenAI_and_LLMs/AI_%20Ask%20questions%20about%20any%20data%20source%20(using%20the%20n8n%20workflow%20retriever).json) |\n| AI: Summarize podcast episode and enhance using Wikipedia | Summarizes podcast episodes and enhances the summary with information from Wikipedia using AI. | Content Creation/AI/Data Analysis | [Link to Template](OpenAI_and_LLMs/AI_%20Summarize%20podcast%20episode%20and%20enhance%20using%20Wikipedia.json) |\n\n### WhatsApp\n\n| Title | Description | Department | Link |\n|---|---|---|---|\n| Automate Sales Meeting Prep with AI & APIFY Sent To WhatsApp | This workflow automates sales meeting preparation using AI and Apify, sending relevant information to WhatsApp. | Sales/AI/Automation | [Link to Template](./WhatsApp/Automate%20Sales%20Meeting%20Prep%20with%20AI%20&%20APIFY%20Sent%20To%20WhatsApp.json) |\n| Building Your First WhatsApp Chatbot | This workflow guides you through building your first WhatsApp chatbot. | Customer Service/Development | [Link to Template](./WhatsApp/Building%20Your%20First%20WhatsApp%20Chatbot.json) |\n| Complete business WhatsApp AI-Powered RAG Chatbot using OpenAI | This workflow builds a complete business WhatsApp AI-powered RAG chatbot using OpenAI. | Customer Service/AI/Development | [Link to Template](./WhatsApp/Complete%20business%20WhatsApp%20AI-Powered%20RAG%20Chatbot%20using%20OpenAI.json) |\n| Respond to WhatsApp Messages with AI Like a Pro! | This workflow enables professional AI-powered responses to WhatsApp messages. | Customer Service/AI/Communication | [Link to Template](./WhatsApp/Respond%20to%20WhatsApp%20Messages%20with%20AI%20Like%20a%20Pro!.json) |\n\n### Instagram, Twitter, Social Media\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| AI agent for Instagram DM_inbox. Manychat + Open AI integration | Integrates Manychat with OpenAI to create an AI agent for managing Instagram direct messages. | Marketing/Customer Service/AI | [Link to Template](Instagram_Twitter_Social_Media/AI%20agent%20for%20Instagram%20DM_inbox.%20Manychat%20%2B%20Open%20AI%20integration.json) |\n| Create dynamic Twitter profile banner | Automates the creation of dynamic Twitter profile banners. | Marketing/Social Media | [Link to Template](Instagram_Twitter_Social_Media/Create%20dynamic%20Twitter%20profile%20banner.json) |\n| Generate Instagram Content from Top Trends with AI Image Generation | Creates Instagram content by analyzing top trends and generating relevant images using AI. | Marketing/AI/Content | [Link to Template](Instagram_Twitter_Social_Media/Generate%20Instagram%20Content%20from%20Top%20Trends%20with%20AI%20Image%20Generation.json) |\n| OpenAI-powered tweet generator | Generates tweets using OpenAI's language models. | Marketing/Social Media/AI | [Link to Template](Instagram_Twitter_Social_Media/OpenAI-powered%20tweet%20generator.json) |\n| Post New YouTube Videos to X | Automatically posts new YouTube videos to X (formerly Twitter). | Marketing/Social Media | [Link to Template](Instagram_Twitter_Social_Media/Post%20New%20YouTube%20Videos%20to%20X.json) |\n| Reddit AI digest | Creates an AI-generated digest of Reddit content. | Marketing/Content/AI | [Link to Template](Instagram_Twitter_Social_Media/Reddit%20AI%20digest.json) |\n| Social Media Analysis and Automated Email Generation | Analyzes social media data and generates automated email reports. | Marketing/Analytics | [Link to Template](Instagram_Twitter_Social_Media/Social%20Media%20Analysis%20and%20Automated%20Email%20Generation.json) |\n| Speed Up Social Media Banners With BannerBear.com | Automates the creation of social media banners using BannerBear.com. | Marketing/Design | [Link to Template](Instagram_Twitter_Social_Media/Speed%20Up%20Social%20Media%20Banners%20With%20BannerBear.com.json) |\n| Twitter Virtual AI Influencer | Manages a virtual AI influencer's Twitter account. | Marketing/AI | [Link to Template](Instagram_Twitter_Social_Media/Twitter%20Virtual%20AI%20Influencer.json) |\n| Update Twitter banner using HTTP request | Updates a Twitter banner using HTTP requests. | Marketing/Development | [Link to Template](Instagram_Twitter_Social_Media/Update%20Twitter%20banner%20using%20HTTP%20request.json) |\n\n### Other Integrations & Use Cases\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| API Schema Extractor | Extracts API schemas from web services for documentation or integration purposes. | Development/Integration | [Link to Template](Other_Integrations_and_Use_Cases/API%20Schema%20Extractor.json) |\n| Analyze feedback and send a message on Mattermost | Analyzes user feedback and sends notifications to Mattermost channels. | Support/Communication | [Link to Template](Other_Integrations_and_Use_Cases/Analyze%20feedback%20and%20send%20a%20message%20on%20Mattermost.json) |\n| Analyze feedback using AWS Comprehend | Performs sentiment analysis on feedback using AWS Comprehend and sends results to Mattermost. | Support/AI | [Link to Template](Other_Integrations_and_Use_Cases/Analyze%20feedback%20using%20AWS%20Comprehend%20and%20send%20it%20to%20a%20Mattermost%20channel.json) |\n| Automate Pinterest Analysis & AI-Powered Content Suggestions | Analyzes Pinterest data and provides AI-powered content suggestions. | Marketing/AI | [Link to Template](Other_Integrations_and_Use_Cases/Automate%20Pinterest%20Analysis%20%26%20AI-Powered%20Content%20Suggestions%20With%20Pinterest%20API.json) |\n| Automate SIEM Alert Enrichment | Enriches SIEM alerts with MITRE ATT&CK data and integrates with Zendesk. | Security/IT | [Link to Template](Other_Integrations_and_Use_Cases/Automate%20SIEM%20Alert%20Enrichment%20with%20MITRE%20ATT%26CK,%20Qdrant%20%26%20Zendesk%20in%20n8n.json) |\n| Automate Screenshots with URLbox & Analyze with AI | Takes screenshots of webpages and analyzes them using AI. | Development/Marketing | [Link to Template](Other_Integrations_and_Use_Cases/Automate%20Screenshots%20with%20URLbox%20%26%20Analyze%20them%20with%20AI.json) |\n| Automate testimonials in Strapi | Automates the process of collecting and managing testimonials in Strapi. | Marketing/Content | [Link to Template](Other_Integrations_and_Use_Cases/Automate%20testimonials%20in%20Strapi%20with%20n8n.json) |\n| Bitrix24 Chatbot Application | Example workflow for creating a Bitrix24 chatbot with webhook integration. | Business/Communication | [Link to Template](Other_Integrations_and_Use_Cases/Bitrix24%20Chatbot%20Application%20Workflow%20example%20with%20Webhook%20Integration.json) |\n| ChatGPT Automatic Code Review in Gitlab MR | Automates code reviews in GitLab merge requests using ChatGPT. | Development/DevOps | [Link to Template](Other_Integrations_and_Use_Cases/ChatGPT%20Automatic%20Code%20Review%20in%20Gitlab%20MR.json) |\n| Classify new bugs in Linear with OpenAI's GPT-4 | Automatically classifies and routes new bug reports in Linear using AI. | Development/QA | [Link to Template](Other_Integrations_and_Use_Cases/Classify%20new%20bugs%20in%20Linear%20with%20OpenAI_s%20GPT-4%20and%20move%20them%20to%20the%20right%20team.json) |\n| Create, update, and get a profile in Humantic AI | Manages user profiles in Humantic AI platform. | Marketing/AI | [Link to Template](Other_Integrations_and_Use_Cases/Create,%20update,%20and%20get%20a%20profile%20in%20Humantic%20AI.json) |\n| Enhance Customer Chat with Twilio and Redis | Implements message buffering for customer chats using Twilio and Redis. | Support/Development | [Link to Template](Other_Integrations_and_Use_Cases/Enhance%20Customer%20Chat%20by%20Buffering%20Messages%20with%20Twilio%20and%20Redis.json) |\n| Hacker News Throwback Machine | Shows what was popular on Hacker News on this day in previous years. | Development/Community | [Link to Template](Other_Integrations_and_Use_Cases/Hacker%20News%20Throwback%20Machine%20-%20See%20What%20Was%20Hot%20on%20This%20Day,%20Every%20Year!.json) |\n| Handling Appointment Leads with Twilio, Cal.com and AI | Manages appointment scheduling and follow-ups using Twilio and Cal.com. | Sales/Support | [Link to Template](Other_Integrations_and_Use_Cases/Handling%20Appointment%20Leads%20and%20Follow-up%20With%20Twilio,%20Cal.com%20and%20AI.json) |\n| Integrating AI with Open-Meteo API | Enhances weather forecasting with AI analysis. | Data Science/Weather | [Link to Template](Other_Integrations_and_Use_Cases/Integrating%20AI%20with%20Open-Meteo%20API%20for%20Enhanced%20Weather%20Forecasting.json) |\n| Introduction to the HTTP Tool | Basic tutorial on using HTTP tools in n8n. | Development | [Link to Template](Other_Integrations_and_Use_Cases/Introduction%20to%20the%20HTTP%20Tool.json) |\n| KB Tool - Confluence Knowledge Base | Integrates with Confluence for knowledge base management. | Documentation/IT | [Link to Template](Other_Integrations_and_Use_Cases/KB%20Tool%20-%20Confluence%20Knowledge%20Base.json) |\n| LINE Assistant with Google Calendar and Gmail | Creates a LINE assistant that integrates with Google Calendar and Gmail. | Productivity/Communication | [Link to Template](Other_Integrations_and_Use_Cases/LINE%20Assistant%20with%20Google%20Calendar%20and%20Gmail%20Integration.json) |\n| Monthly Spotify Track Archiving | Archives and classifies monthly Spotify tracks into playlists. | Personal/Music | [Link to Template](Other_Integrations_and_Use_Cases/Monthly%20Spotify%20Track%20Archiving%20and%20Playlist%20Classification.json) |\n| Obsidian Notes Read Aloud | Converts Obsidian notes into audio format as a podcast feed. | Productivity/Content | [Link to Template](Other_Integrations_and_Use_Cases/Obsidian%20Notes%20Read%20Aloud%20using%20AI_%20Available%20as%20a%20Podcast%20Feed.json) |\n| Optimize & Update Printify Title and Description | Automates optimization of Printify product titles and descriptions. | E-commerce | [Link to Template](Other_Integrations_and_Use_Cases/Optimize%20%26%20Update%20Printify%20Title%20and%20Description%20Workflow.json) |\n| Qualify replies from Pipedrive persons with AI | Uses AI to qualify and categorize replies from Pipedrive contacts. | Sales/AI | [Link to Template](Other_Integrations_and_Use_Cases/Qualify%20replies%20from%20Pipedrive%20persons%20with%20AI.json) |\n| Siri AI Agent with Apple Shortcuts | Creates a Siri-powered AI agent using Apple Shortcuts. | Personal/Productivity | [Link to Template](Other_Integrations_and_Use_Cases/Siri%20AI%20Agent_%20Apple%20Shortcuts%20powered%20voice%20template.json) |\n| Text automations using Apple Shortcuts | Implements text-based automations with Apple Shortcuts. | Personal/Productivity | [Link to Template](Other_Integrations_and_Use_Cases/Text%20automations%20using%20Apple%20Shortcuts.json) |\n| UTM Link Creator & QR Code Generator | Creates UTM links, generates QR codes, and schedules Google Analytics reports. | Marketing/Analytics | [Link to Template](Other_Integrations_and_Use_Cases/UTM%20Link%20Creator%20%26%20QR%20Code%20Generator%20with%20Scheduled%20Google%20Analytics%20Reports.json) |\n| Use AI to organize your Todoist Inbox | Automatically organizes tasks in Todoist using AI. | Productivity | [Link to Template](Other_Integrations_and_Use_Cases/Use%20AI%20to%20organize%20your%20Todoist%20Inbox.json) |\n| Using External Workflows as Tools in n8n | Demonstrates how to use external workflows as tools within n8n. | Development | [Link to Template](Other_Integrations_and_Use_Cases/Using%20External%20Workflows%20as%20Tools%20in%20n8n.json) |\n| Visualize SQL Agent queries with OpenAI and Quickchart.io | Creates visualizations from SQL queries using OpenAI and Quickchart.io. | Data Analysis/Visualization | [Link to Template](Other_Integrations_and_Use_Cases/Visualize%20your%20SQL%20Agent%20queries%20with%20OpenAI%20and%20Quickchart.io.json) |\n| Zoom AI Meeting Assistant | Creates meeting summaries, ClickUp tasks, and schedules follow-ups from Zoom meetings. | Productivity/Communication | [Link to Template](Other_Integrations_and_Use_Cases/Zoom%20AI%20Meeting%20Assistant%20creates%20mail%20summary,%20ClickUp%20tasks%20and%20follow-up%20call.json) |\n\n### Forms & Surveys\n\n| Title | Description | Department | Link |\n|-------|-------------|------------|------|\n| Conversational Interviews with AI Agents and n8n Forms | Implements AI-powered conversational interviews using n8n Forms for interactive data collection. | Research/Marketing | [Link to Template](Forms_and_Surveys/Conversational%20Interviews%20with%20AI%20Agents%20and%20n8n%20Forms.json) |\n| Email Subscription Service with n8n Forms, Airtable and AI | Manages email subscriptions with n8n Forms, stores data in Airtable, and uses AI for processing. | Marketing/Communication | [Link to Template](Forms_and_Surveys/Email%20Subscription%20Service%20with%20n8n%20Forms,%20Airtable%20and%20AI.json) |\n| Qualifying Appointment Requests with AI & n8n Forms | Uses AI to qualify and process appointment requests submitted through n8n Forms. | Sales/Support | [Link to Template](Forms_and_Surveys/Qualifying%20Appointment%20Requests%20with%20AI%20&%20n8n%20Forms.json) |\n\n### AI Research, RAG, and Data Analysis\n\n| Workflow Title | Description | Department | Link to Template |\n|---|---|---|---|\n| Analyze tradingview.com charts with Chrome extension, N8N and OpenAI | Analyzes TradingView charts using a Chrome extension, n8n, and OpenAI for automated insights. | Data Analysis | [Analyze tradingview.com charts with Chrome extension, N8N and OpenAI.txt](./AI_Research_RAG_and_Data_Analysis/Analyze%20tradingview.com%20charts%20with%20Chrome%20extension,%20N8N%20and%20OpenAI.json) |\n| Automated Hugging Face Paper Summary Fetching & Categorization Workflow | Automates fetching, summarizing, and categorizing research papers from Hugging Face. | AI Research | [Automated Hugging Face Paper Summary Fetching & Categorization Workflow.txt](./AI_Research_RAG_and_Data_Analysis/Automated%20Hugging%20Face%20Paper%20Summary%20Fetching%20%26%20Categorization%20Workflow.json) |\n| Autonomous AI crawler | An autonomous AI-powered web crawler for data collection and analysis. | AI Research | [Autonomous AI crawler.txt](./AI_Research_RAG_and_Data_Analysis/Autonomous%20AI%20crawler.json) |\n| Build Your Own Image Search Using AI Object Detection, CDN and ElasticSearch | Builds an image search engine using AI object detection, CDN, and Elasticsearch for efficient image retrieval. | AI Research | [Build Your Own Image Search Using AI Object Detection, CDN and ElasticSearchBuild Your Own Image Search Using AI Object Detection, CDN and ElasticSearch.txt](./AI_Research_RAG_and_Data_Analysis/Build%20Your%20Own%20Image%20Search%20Using%20AI%20Object%20Detection,%20CDN%20and%20ElasticSearchBuild%20Your%20Own%20Image%20Search%20Using%20AI%20Object%20Detection,%20CDN%20and%20ElasticSearch.json) |\n| Build a Financial Documents Assistant using Qdrant and Mistral.ai | Creates an AI assistant for financial document analysis using Qdrant for vector search and Mistral.ai for language processing. | Finance, AI Research | [Build a Financial Documents Assistant using Qdrant and Mistral.ai.txt](./AI_Research_RAG_and_Data_Analysis/Build%20a%20Financial%20Documents%20Assistant%20using%20Qdrant%20and%20Mistral.ai.json) |\n| Build a Tax Code Assistant with Qdrant, Mistral.ai and OpenAI | Develops an AI assistant for tax code queries using Qdrant, Mistral.ai, and OpenAI for comprehensive responses. | Finance, AI Research | [Build a Tax Code Assistant with Qdrant, Mistral.ai and OpenAI.txt](./AI_Research_RAG_and_Data_Analysis/Build%20a%20Tax%20Code%20Assistant%20with%20Qdrant,%20Mistral.ai%20and%20OpenAI.json) |\n| Building RAG Chatbot for Movie Recommendations with Qdrant and Open AI | Constructs a RAG-based chatbot for movie recommendations, leveraging Qdrant for retrieval and OpenAI for generation. | AI Research, Entertainment | [Building RAG Chatbot for Movie Recommendations with Qdrant and Open AI.txt](./AI_Research_RAG_and_Data_Analysis/Building%20RAG%20Chatbot%20for%20Movie%20Recommendations%20with%20Qdrant%20and%20Open%20AI.json) |\n| Chat with GitHub API Documentation: RAG-Powered Chatbot with Pinecone & OpenAI | Implements a RAG-powered chatbot for interacting with GitHub API documentation using Pinecone and OpenAI. | Development, AI Research | [Chat with GitHub API Documentation_ RAG-Powered Chatbot with Pinecone & OpenAI.txt](./AI_Research_RAG_and_Data_Analysis/Chat%20with%20GitHub%20API%20Documentation_%20RAG-Powered%20Chatbot%20with%20Pinecone%20%26%20OpenAI.json) |\n| Create a Google Analytics Data Report with AI and sent it to E-Mail and Telegram | Generates Google Analytics data reports using AI and sends them via email and Telegram. | Data Analysis, Marketing | [Create a Google Analytics Data Report with AI and sent it to E-Mail and Telegram.txt](./AI_Research_RAG_and_Data_Analysis/Create%20a%20Google%20Analytics%20Data%20Report%20with%20AI%20and%20sent%20it%20to%20E-Mail%20and%20Telegram.json) |\n| Customer Insights with Qdrant, Python and Information Extractor | Extracts customer insights using Qdrant, Python, and an information extraction module. | Data Analysis, Customer Service | [Customer Insights with Qdrant, Python and Information Extractor.txt](./AI_Research_RAG_and_Data_Analysis/Customer%20Insights%20with%20Qdrant,%20Python%20and%20Information%20Extractor.json) |\n| Deduplicate Scraping AI Grants for Eligibility using AI | Automates the deduplication and eligibility assessment of scraped AI grant data using AI. | AI Research, Data Management | [Deduplicate Scraping AI Grants for Eligibility using AI.txt](./AI_Research_RAG_and_Data_Analysis/Deduplicate%20Scraping%20AI%20Grants%20for%20Eligibility%20using%20AI.json) |\n| Enrich Property Inventory Survey with Image Recognition and AI Agent | Enhances property inventory surveys with image recognition and AI agents for automated data enrichment. | Real Estate, AI Research | [Enrich Property Inventory Survey with Image Recognition and AI Agent.txt](./AI_Research_RAG_and_Data_Analysis/Enrich%20Property%20Inventory%20Survey%20with%20Image%20Recognition%20and%20AI%20Agent.json) |\n| Extract insights & analyse YouTube comments via AI Agent chat | Extracts insights and analyzes YouTube comments through an AI agent chat interface. | Social Media, Data Analysis | [Extract insights & analyse YouTube comments via AI Agent chat.txt](./AI_Research_RAG_and_Data_Analysis/Extract%20insights%20%26%20analyse%20YouTube%20comments%20via%20AI%20Agent%20chat.json) |\n| Generate SEO Seed Keywords Using AI | Generates SEO seed keywords using AI to optimize content for search engines. | Marketing, AI Research | [Generate SEO Seed Keywords Using AI.txt](./AI_Research_RAG_and_Data_Analysis/Generate%20SEO%20Seed%20Keywords%20Using%20AI.json) |\n| Hacker News Job Listing Scraper and Parser | Scrapes and parses job listings from Hacker News for job seekers or recruiters. | Data Collection, HR | [Hacker News Job Listing Scraper and Parser.txt](./AI_Research_RAG_and_Data_Analysis/Hacker%20News%20Job%20Listing%20Scraper%20and%20Parser.json) |\n| Hacker News to Video Content | Converts Hacker News articles into video content automatically. | Content Creation, Media | [Hacker News to Video Content.txt](./AI_Research_RAG_and_Data_Analysis/Hacker%20News%20to%20Video%20Content.json) |\n| Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3 | Sets up a self-hosted AI deep research agent using n8n, Apify, and OpenAI. | AI Research, Automation | [Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3.txt](./AI_Research_RAG_and_Data_Analysis/Host%20Your%20Own%20AI%20Deep%20Research%20Agent%20with%20n8n,%20Apify%20and%20OpenAI%20o3.json) |\n| Intelligent Web Query and Semantic Re-Ranking Flow using Brave and Google Gemini | Performs intelligent web queries and semantic re-ranking using Brave browser and Google Gemini AI. | AI Research, Data Analysis | [Intelligent Web Query and Semantic Re-Ranking Flow using Brave and Google Gemini.txt](./AI_Research_RAG_and_Data_Analysis/Intelligent%20Web%20Query%20and%20Semantic%20Re-Ranking%20Flow%20using%20Brave%20and%20Google%20Gemini.json) |\n| Learn Anything from HN - Get Top Resource Recommendations from Hacker News | Extracts top resource recommendations from Hacker News to facilitate learning on any topic. | Education, Data Analysis | [Learn Anything from HN - Get Top Resource Recommendations from Hacker News.txt](./AI_Research_RAG_and_Data_Analysis/Learn%20Anything%20from%20HN%20-%20Get%20Top%20Resource%20Recommendations%20from%20Hacker%20News.json) |\n| Make OpenAI Citation for File Retrieval RAG | Generates citations for file retrieval in RAG systems using OpenAI. | AI Research, Documentation | [Make OpenAI Citation for File Retrieval RAG.txt](./AI_Research_RAG_and_Data_Analysis/Make%20OpenAI%20Citation%20for%20File%20Retrieval%20RAG.json) |\n| Open Deep Research - AI-Powered Autonomous Research Workflow | An AI-powered autonomous workflow for conducting deep research. | AI Research, Automation | [Open Deep Research - AI-Powered Autonomous Research Workflow.txt](./AI_Research_RAG_and_Data_Analysis/Open%20Deep%20Research%20-%20AI-Powered%20Autonomous%20Research%20Workflow.json) |\n| Query Perplexity AI from your n8n workflows | Integrates Perplexity AI into n8n workflows for advanced querying capabilities. | AI Research, Automation | [Query Perplexity AI from your n8n workflows.txt](./AI_Research_RAG_and_Data_Analysis/Query%20Perplexity%20AI%20from%20your%20n8n%20workflows.json) |\n| Recipe Recommendations with Qdrant and Mistral | Provides recipe recommendations using Qdrant for vector search and Mistral AI for content generation. | Food, AI Research | [Recipe Recommendations with Qdrant and Mistral.txt](./AI_Research_RAG_and_Data_Analysis/Recipe%20Recommendations%20with%20Qdrant%20and%20Mistral.json) |\n| Reconcile Rent Payments with Local Excel Spreadsheet and OpenAI | Reconciles rent payments by comparing local Excel spreadsheets with data processed by OpenAI. | Finance, Data Management | [Reconcile Rent Payments with Local Excel Spreadsheet and OpenAI.txt](./AI_Research_RAG_and_Data_Analysis/Reconcile%20Rent%20Payments%20with%20Local%20Excel%20Spreadsheet%20and%20OpenAI.json) |\n| Scrape Trustpilot Reviews with DeepSeek, Analyze Sentiment with OpenAI | Scrapes Trustpilot Reviews using DeepSeek and analyzes sentiment with OpenAI. | Marketing, Data Analysis | [Scrape Trustpilot Reviews with DeepSeek, Analyze Sentiment with OpenAI.txt](./AI_Research_RAG_and_Data_Analysis/Scrape%20Trustpilot%20Reviews%20with%20DeepSeek,%20Analyze%20Sentiment%20with%20OpenAI.json) |\n| Scrape and summarize posts of a news site without RSS feed using AI and save them to a NocoDB | Scrapes and summarizes news posts without RSS feeds using AI, saving the output to NocoDB. | Content Curation, Data Management | [Scrape and summarize posts of a news site without RSS feed using AI and save them to a NocoDB.txt](./AI_Research_RAG_and_Data_Analysis/Scrape%20and%20summarize%20posts%20of%20a%20news%20site%20without%20RSS%20feed%20using%20AI%20and%20save%20them%20to%20a%20NocoDB.json) |\n| Scrape and summarize webpages with AI | Scrapes and summarizes content from webpages using AI. | Content Curation, Data Analysis | [Scrape and summarize webpages with AI.txt](./AI_Research_RAG_and_Data_Analysis/Scrape%20and%20summarize%20webpages%20with%20AI.json) |\n| Send Google analytics data to A.I. to analyze then save results in Baserow | Sends Google Analytics data to AI for analysis and saves the results in Baserow. | Data Analysis, Marketing | [Send Google analytics data to A.I. to analyze then save results in Baserow.txt](./AI_Research_RAG_and_Data_Analysis/Send%20Google%20analytics%20data%20to%20A.I.%20to%20analyze%20then%20save%20results%20in%20Baserow.json) |\n| Spot Workplace Discrimination Patterns with AI | Identifies patterns of workplace discrimination using AI-driven analysis. | HR, AI Research | [Spot Workplace Discrimination Patterns with AI.txt](./AI_Research_RAG_and_Data_Analysis/Spot%20Workplace%20Discrimination%20Patterns%20with%20AI.json) |\n| Summarize SERPBear data with AI (via Openrouter) and save it to Baserow | Summarizes SERPBear data using AI (via Openrouter) and saves the insights to Baserow. | SEO, Data Analysis | [Summarize SERPBear data with AI (via Openrouter) and save it to Baserow.txt](./AI_Research_RAG_and_Data_Analysis/Summarize%20SERPBear%20data%20with%20AI%20(via%20Openrouter)%20and%20save%20it%20to%20Baserow.json) |\n| Summarize Umami data with AI (via Openrouter) and save it to Baserow | Summarizes Umami analytics data using AI (via Openrouter) and saves the insights to Baserow. | Data Analysis, Marketing | [Summarize Umami data with AI (via Openrouter) and save it to Baserow.txt](./AI_Research_RAG_and_Data_Analysis/Summarize%20Umami%20data%20with%20AI%20(via%20Openrouter)%20and%20save%20it%20to%20Baserow.json) |\n| Survey Insights with Qdrant, Python and Information Extractor | Extracts and analyzes insights from survey data using Qdrant, Python, and an information extractor. | Data Analysis, Market Research | [Survey Insights with Qdrant, Python and Information Extractor.txt](./AI_Research_RAG_and_Data_Analysis/Survey%20Insights%20with%20Qdrant,%20Python%20and%20Information%20Extractor.json) |\n| Ultimate Scraper Workflow for n8n | A comprehensive scraping workflow for n8n to extract data from various sources. | Data Collection, Automation | [Ultimate Scraper Workflow for n8n.txt](./AI_Research_RAG_and_Data_Analysis/Ultimate%20Scraper%20Workflow%20for%20n8n.json) |\n| Vector Database as a Big Data Analysis Tool for AI Agents [1/3 anomaly][1/2 KNN] | Utilizes a vector database for big data analysis, focusing on anomaly detection and KNN classification for AI agents. | AI Research, Data Analysis | [Vector Database as a Big Data Analysis Tool for AI Agents [1_3 anomaly][1_2 KNN].txt](./AI_Research_RAG_and_Data_Analysis/Vector%20Database%20as%20a%20Big%20Data%20Analysis%20Tool%20for%20AI%20Agents%20[1_3%20anomaly][1_2%20KNN].json) |\n| Vector Database as a Big Data Analysis Tool for AI Agents [2/2 KNN] | Continues the use of a vector database for big data analysis, focusing on KNN classification for AI agents. | AI Research, Data Analysis | [Vector Database as a Big Data Analysis Tool for AI Agents [2_2 KNN].txt](./AI_Research_RAG_and_Data_Analysis/Vector%20Database%20as%20a%20Big%20Data%20Analysis%20Tool%20for%20AI%20Agents%20[2_2%20KNN].json) |\n| Vector Database as a Big Data Analysis Tool for AI Agents [2/3 - anomaly] | Explores the use of a vector database for big data analysis, focusing on anomaly detection for AI agents. | AI Research, Data Analysis | [Vector Database as a Big Data Analysis Tool for AI Agents [2_3 - anomaly].txt](./AI_Research_RAG_and_Data_Analysis/Vector%20Database%20as%20a%20Big%20Data%20Analysis%20Tool%20for%20AI%20Agents%20[2_3%20-%20anomaly].json) |\n| Vector Database as a Big Data Analysis Tool for AI Agents [3/3 - anomaly] | Concludes the use of a vector database for big data analysis, focusing on anomaly detection for AI agents. | AI Research, Data Analysis | [Vector Database as a Big Data Analysis Tool for AI Agents [3_3 - anomaly].txt](./AI_Research_RAG_and_Data_Analysis/Vector%20Database%20as%20a%20Big%20Data%20Analysis%20Tool%20for%20AI%20Agents%20[3_3%20-%20anomaly].json) |\n| Visual Regression Testing with Apify and AI Vision Model | Performs visual regression testing using Apify and an AI vision model to detect UI changes. | QA, AI Research | [Visual Regression Testing with Apify and AI Vision Model.txt](./AI_Research_RAG_and_Data_Analysis/Visual%20Regression%20Testing%20with%20Apify%20and%20AI%20Vision%20Model.json) |\n| ğŸ” Perplexity Research to HTML: AI-Powered Content Creation | Transforms Perplexity AI research into HTML content for AI-powered content creation. | Content Creation, AI Research | [ğŸ” Perplexity Research to HTML_ AI-Powered Content Creation.txt](./AI_Research_RAG_and_Data_Analysis/%F0%9F%94%8D%20Perplexity%20Research%20to%20HTML_%20AI-Powered%20Content%20Creation.json) |\n\n\n### **Other**\n\n- ALL_unique_nodes.txt (node reference)\n\n... and more !\n\n---\n\nIf you would like to contribute additional templates or suggest new categories, feel free to open an issue or pull request!\n\n---\n\nğŸ‘‰ [Join n8n and start automating now! ğŸ’](https://n8n.partnerlinks.io/h1pwwf5m4toe)\n<a href=\"https://n8n.partnerlinks.io/h1pwwf5m4toe\">\n  <img src=\"/img/n8n.png\" alt=\"n8n\" style=\"max-height: 300px;\">\n</a>\n\n---\n\n### **Sponsors**\n- [mahezsh](https://github.com/mahezsh)\n"
        },
        {
            "url": "https://github.com/PixiEditor/PixiEditor",
            "language": "C#",
            "description": "PixiEditor is a Universal Editor for all your 2D needs",
            "readme_summary": "<div align=\"center\">\n\n[![Release](https://img.shields.io/github/v/release/flabbet/PixiEditor)](https://github.com/flabbet/PixiEditor/releases) \n[![Downloads](https://img.shields.io/github/downloads/PixiEditor/PixiEditor/total)](https://github.com/flabbet/PixiEditor/releases)\n[![Discord Server](https://badgen.net/badge/discord/join%20chat/7289DA?icon=discord)](https://discord.gg/qSRMYmq)\n[![Subreddit subscribers](https://img.shields.io/reddit/subreddit-subscribers/PixiEditor?label=%20r%2FPixiEditor&logoColor=%23e3002d)](https://reddit.com/r/PixiEditor)\n[![Forum](https://img.shields.io/badge/PixiEditor-Forum-red?link=https%3A%2F%2Fforum.pixieditor.net%2F)](https://forum.pixieditor.net/)\n\n<img width=\"50%\" align=\"center\" src=\"https://github.com/user-attachments/assets/bd08c8bd-f610-449d-b1e2-6a990e562518\">\n\n## The only 2D Graphics Editor you'll ever need\n\n**PixiEditor** is a universal 2D editor that was made to provide you with tools and features for all your 2D needs. Create beautiful sprites for your games, animations, edit images, create logos. All packed up in an intuitive and familiar interface.\n\n<a href=\"https://pixieditor.net/download\"><img src=\"https://github.com/nnakocaj/supreme-train/blob/main/download1.png\" width=\"250\" alt=\"Download\"/></a>\n\n</div>\n\n![](https://github.com/nnakocaj/supreme-train/blob/main/interface.png)\n\n### Toolsets for any scenario\n\nPixiEditor 2.0 comes by default with 3 toolsets: \n- **Pixel art** - it contains tool suited for pixel-perfect scenarios\n- **Painting** - basic painting tools, soft brushes, anti aliased shapes\n- **Vector** - shapes and paths for creating vectors\n\nAll **toolsets can be used on one canvas**. Mix vector with raster. Export to png, jpg, svg, gif, mp4 and more!\n\n<p align=\"center\">\n  <img src=\"https://github.com/nnakocaj/supreme-train/blob/main/toolsets.gif?raw=true\" width=\"70%\" />\n</p>\n\n### Animations\n\nVersion 2.0 comes with a timeline and animation capabilities. You can create frame by frame animations or use nodes to animate your custom shaders.\nKey frame animations with vectors are on our roadmap.\n\n![](https://github.com/nnakocaj/supreme-train/blob/main/timeline1.png)\n\n### Nodes\n\nNode render system is what powers such extensive capabilities. All layers, effects and the layer structure are nodes or a result of its connections. PixiEditor exposes node graph for every document, so you are free to customize your image however you want and create procedural art/animations!\n\n![](https://github.com/nnakocaj/supreme-train/blob/main/node.png)\n\n## Building from source\n\n<p>Check out our <a href=\"https://pixieditor.net/docs/contribution/compileguide/\">Compile Guide</a></p>\n\n## Contributing\n\n<p>For a seamless collaboration <a href=\"https://pixieditor.net/docs/contribution/starthere//\">Start Here</a></p>\n\n## Help\n\n<p>Got stuck? We are here to <a href=\"https://pixieditor.net/help\">Help</a></p>\n\n\n</br></br>\n\n\n<div align=\"center\">\n    <a href=\"https://discord.gg/DwaXAuXVzv\" target=\"_blank\"><img src=\"https://newsletter.pixieditor.net/uploads/discord.png\" alt=\"discord\" width=50/></a>&nbsp;&nbsp;&nbsp;\n    <a href=\"https://store.steampowered.com/app/2218560/PixiEditor__Pixel_Art_Editor/\" target=\"_blank\"><img src=\"https://newsletter.pixieditor.net/uploads/steam.png\" alt=\"steam\" width=50/></a>&nbsp;&nbsp;&nbsp;\n    <a href=\"https://www.youtube.com/@PixiEditor\" target=\"_blank\"><img src=\"https://newsletter.pixieditor.net/uploads/youtube.png\" alt=\"youtube\" width=50/></a>&nbsp;&nbsp;&nbsp;\n    <a href=\"https://twitter.com/PixiEditor\" target=\"_blank\"><img src=\"https://newsletter.pixieditor.net/uploads/twitter.png\" alt=\"twitter\" width=50/></a>&nbsp;&nbsp;&nbsp;\n    <a href=\"https://www.reddit.com/r/PixiEditor\" target=\"_blank\"><img src=\"https://newsletter.pixieditor.net/uploads/reddit.png\" alt=\"reddit\" width=50/></a>&nbsp;&nbsp;&nbsp;\n    <a href=\"https://www.linkedin.com/company/pixieditor\" target=\"_blank\"><img src=\"https://newsletter.pixieditor.net/uploads/linkedin.png\" alt=\"linkedin\" width=50/></a>\n</div>\n"
        },
        {
            "url": "https://github.com/immich-app/immich",
            "language": "TypeScript",
            "description": "High performance self-hosted photo and video management solution.",
            "readme_summary": "<p align=\"center\"> \n  <br/>\n  <a href=\"https://opensource.org/license/agpl-v3\"><img src=\"https://img.shields.io/badge/License-AGPL_v3-blue.svg?color=3F51B5&style=for-the-badge&label=License&logoColor=000000&labelColor=ececec\" alt=\"License: AGPLv3\"></a>\n  <a href=\"https://discord.immich.app\">\n    <img src=\"https://img.shields.io/discord/979116623879368755.svg?label=Discord&logo=Discord&style=for-the-badge&logoColor=000000&labelColor=ececec\" alt=\"Discord\"/>\n  </a>\n  <br/>\n  <br/>\n</p>\n\n<p align=\"center\">\n<img src=\"design/immich-logo-stacked-light.svg\" width=\"300\" title=\"Login With Custom URL\">\n</p>\n<h3 align=\"center\">High performance self-hosted photo and video management solution</h3>\n<br/>\n<a href=\"https://immich.app\">\n<img src=\"design/immich-screenshots.png\" title=\"Main Screenshot\">\n</a>\n<br/>\n\n<p align=\"center\">\n  <a href=\"readme_i18n/README_ca_ES.md\">CatalÃ </a>\n  <a href=\"readme_i18n/README_es_ES.md\">EspaÃ±ol</a>\n  <a href=\"readme_i18n/README_fr_FR.md\">FranÃ§ais</a>\n  <a href=\"readme_i18n/README_it_IT.md\">Italiano</a>\n  <a href=\"readme_i18n/README_ja_JP.md\">æ—¥æœ¬èª</a>\n  <a href=\"readme_i18n/README_ko_KR.md\">í•œêµ­ì–´</a>\n  <a href=\"readme_i18n/README_de_DE.md\">Deutsch</a>\n  <a href=\"readme_i18n/README_nl_NL.md\">Nederlands</a>\n  <a href=\"readme_i18n/README_tr_TR.md\">TÃ¼rkÃ§e</a>\n  <a href=\"readme_i18n/README_zh_CN.md\">ä¸­æ–‡</a>\n  <a href=\"readme_i18n/README_uk_UA.md\">Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°</a>\n  <a href=\"readme_i18n/README_ru_RU.md\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>\n  <a href=\"readme_i18n/README_pt_BR.md\">PortuguÃªs Brasileiro</a>\n  <a href=\"readme_i18n/README_sv_SE.md\">Svenska</a>\n  <a href=\"readme_i18n/README_ar_JO.md\">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>\n  <a href=\"readme_i18n/README_vi_VN.md\">Tiáº¿ng Viá»‡t</a>\n  <a href=\"readme_i18n/README_th_TH.md\">à¸ à¸²à¸©à¸²à¹„à¸—à¸¢</a>\n</p>\n\n## Disclaimer\n\n- âš ï¸ The project is under **very active** development.\n- âš ï¸ Expect bugs and breaking changes.\n- âš ï¸ **Do not use the app as the only way to store your photos and videos.**\n- âš ï¸ Always follow [3-2-1](https://www.backblaze.com/blog/the-3-2-1-backup-strategy/) backup plan for your precious photos and videos!\n\n> [!NOTE]\n> You can find the main documentation, including installation guides, at https://immich.app/.\n\n## Links\n\n- [Documentation](https://immich.app/docs)\n- [About](https://immich.app/docs/overview/introduction)\n- [Installation](https://immich.app/docs/install/requirements)\n- [Roadmap](https://immich.app/roadmap)\n- [Demo](#demo)\n- [Features](#features)\n- [Translations](https://immich.app/docs/developer/translations)\n- [Contributing](https://immich.app/docs/overview/support-the-project)\n\n## Demo\n\nAccess the demo [here](https://demo.immich.app). For the mobile app, you can use `https://demo.immich.app` for the `Server Endpoint URL`.\n\n### Login credentials\n\n| Email           | Password |\n| --------------- | -------- |\n| demo@immich.app | demo     |\n\n## Features\n\n| Features                                     | Mobile | Web |\n| :------------------------------------------- | ------ | --- |\n| Upload and view videos and photos            | Yes    | Yes |\n| Auto backup when the app is opened           | Yes    | N/A |\n| Prevent duplication of assets                | Yes    | Yes |\n| Selective album(s) for backup                | Yes    | N/A |\n| Download photos and videos to local device   | Yes    | Yes |\n| Multi-user support                           | Yes    | Yes |\n| Album and Shared albums                      | Yes    | Yes |\n| Scrubbable/draggable scrollbar               | Yes    | Yes |\n| Support raw formats                          | Yes    | Yes |\n| Metadata view (EXIF, map)                    | Yes    | Yes |\n| Search by metadata, objects, faces, and CLIP | Yes    | Yes |\n| Administrative functions (user management)   | No     | Yes |\n| Background backup                            | Yes    | N/A |\n| Virtual scroll                               | Yes    | Yes |\n| OAuth support                                | Yes    | Yes |\n| API Keys                                     | N/A    | Yes |\n| LivePhoto/MotionPhoto backup and playback    | Yes    | Yes |\n| Support 360 degree image display             | No     | Yes |\n| User-defined storage structure               | Yes    | Yes |\n| Public Sharing                               | Yes    | Yes |\n| Archive and Favorites                        | Yes    | Yes |\n| Global Map                                   | Yes    | Yes |\n| Partner Sharing                              | Yes    | Yes |\n| Facial recognition and clustering            | Yes    | Yes |\n| Memories (x years ago)                       | Yes    | Yes |\n| Offline support                              | Yes    | No  |\n| Read-only gallery                            | Yes    | Yes |\n| Stacked Photos                               | Yes    | Yes |\n| Tags                                         | No     | Yes |\n| Folder View                                  | Yes    | Yes |\n\n## Translations\n\nRead more about translations [here](https://immich.app/docs/developer/translations).\n\n<a href=\"https://hosted.weblate.org/engage/immich/\">\n<img src=\"https://hosted.weblate.org/widget/immich/immich/multi-auto.svg\" alt=\"Translation status\" />\n</a>\n\n## Repository activity\n\n![Activities](https://repobeats.axiom.co/api/embed/9e86d9dc3ddd137161f2f6d2e758d7863b1789cb.svg \"Repobeats analytics image\")\n\n## Star history\n\n<a href=\"https://star-history.com/#immich-app/immich&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=immich-app/immich&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=immich-app/immich&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=immich-app/immich&type=Date\" width=\"100%\" />\n </picture>\n</a>\n\n## Contributors\n\n<a href=\"https://github.com/alextran1502/immich/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=immich-app/immich\" width=\"100%\"/>\n</a>\n"
        },
        {
            "url": "https://github.com/Shubhamsaboo/awesome-llm-apps",
            "language": "Python",
            "description": "Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.",
            "readme_summary": "<p align=\"center\">\n  <a href=\"http://www.theunwindai.com\">\n    <img src=\"docs/banner/unwind_black.png\" width=\"900px\" alt=\"Unwind AI\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://www.linkedin.com/in/shubhamsaboo/\">\n    <img src=\"https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&style=flat-square\" alt=\"LinkedIn\">\n  </a>\n  <a href=\"https://twitter.com/Saboo_Shubham_\">\n    <img src=\"https://img.shields.io/twitter/follow/Shubham_Saboo\" alt=\"Twitter\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <!-- Keep these links. Translations will automatically update with the README. -->\n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=de\">Deutsch</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=es\">EspaÃ±ol</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=fr\">franÃ§ais</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ja\">æ—¥æœ¬èª</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ko\">í•œêµ­ì–´</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=pt\">PortuguÃªs</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ru\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a> | \n  <a href=\"https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=zh\">ä¸­æ–‡</a>\n</p>\n\n<hr/>\n\n# ğŸŒŸ Awesome LLM Apps\n\nA curated collection of **Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.** This repository features LLM apps that use models from OpenAI, Anthropic, Google, and open-source models like DeepSeek, Qwen or Llama that you can run locally on your computer.\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/9876\" target=\"_blank\">\n    <img src=\"https://trendshift.io/api/badge/repositories/9876\" alt=\"Shubhamsaboo%2Fawesome-llm-apps | Trendshift\" style=\"width: 250px; height: 55px;\" />\n  </a>\n</p>\n\n## ğŸ¤” Why Awesome LLM Apps?\n\n- ğŸ’¡ Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.\n- ğŸ”¥ Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP & RAG.\n- ğŸ“ Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.\n\n## ğŸ“‚ Featured AI Projects\n\n### AI Agents\n\n### ğŸŒ± Starter AI Agents\n\n*   [ğŸ™ï¸ AI Blog to Podcast Agent](starter_ai_agents/ai_blog_to_podcast_agent/)\n*   [â¤ï¸â€ğŸ©¹ AI Breakup Recovery Agent](starter_ai_agents/ai_breakup_recovery_agent/)\n*   [ğŸ“Š AI Data Analysis Agent](starter_ai_agents/ai_data_analysis_agent/)\n*   [ğŸ©» AI Medical Imaging Agent](starter_ai_agents/ai_medical_imaging_agent/)\n*   [ğŸ˜‚ AI Meme Generator Agent (Browser)](starter_ai_agents/ai_meme_generator_agent_browseruse/)\n*   [ğŸµ AI Music Generator Agent](starter_ai_agents/ai_music_generator_agent/)\n*   [ğŸ›« AI Travel Agent (Local & Cloud)](starter_ai_agents/ai_travel_agent/)\n*   [âœ¨ Gemini Multimodal Agent](starter_ai_agents/gemini_multimodal_agent_demo/)\n*   [ğŸŒ Local News Agent (OpenAI Swarm)](starter_ai_agents/local_news_agent_openai_swarm/)\n*   [ğŸ”„ Mixture of Agents](starter_ai_agents/mixture_of_agents/)\n*   [ğŸ“Š xAI Finance Agent](starter_ai_agents/xai_finance_agent/)\n*   [ğŸ” OpenAI Research Agent](starter_ai_agents/opeani_research_agent/)\n*   [ğŸ•¸ï¸ Web Scrapping AI Agent (Local & Cloud)](starter_ai_agents/web_scrapping_ai_agent/)\n\n### ğŸš€ Advanced AI Agents\n\n*   [ğŸ” AI Deep Research Agent](advanced_ai_agents/single_agent_apps/ai_deep_research_agent/)\n*   [ğŸ¤ AI Consultant Agent](advanced_ai_agents/single_agent_apps/ai_consultant_agent)\n*   [ğŸ—ï¸ AI System Architect Agent](advanced_ai_agents/single_agent_apps/ai_system_architect_r1/)\n*   [ğŸ¯ AI Lead Generation Agent](advanced_ai_agents/single_agent_apps/ai_lead_generation_agent/)\n*   [ğŸ’° AI Financial Coach Agent](advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/)\n*   [ğŸ¬ AI Movie Production Agent](advanced_ai_agents/single_agent_apps/ai_movie_production_agent/)\n*   [ğŸ“ˆ AI Investment Agent](advanced_ai_agents/single_agent_apps/ai_investment_agent/)\n*   [ğŸ‹ï¸â€â™‚ï¸ AI Health & Fitness Agent](advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/)\n*   [ğŸš€ AI Product Launch Intelligence Agent](advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent)\n*   [ğŸ—ï¸ AI Journalist Agent](advanced_ai_agents/single_agent_apps/ai_journalist_agent/)\n*   [ğŸ§  AI Mental Wellbeing Agent](advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/)\n*   [ğŸ“‘ AI Meeting Agent](advanced_ai_agents/single_agent_apps/ai_meeting_agent/)\n*   [ğŸ§¬ AI Self-Evolving Agent](advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/)\n*   [ğŸ§ AI Social Media News and Podcast Agent](advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/)\n\n### ğŸ® Autonomous Game Playing Agents\n\n*   [ğŸ® AI 3D Pygame Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/)\n*   [â™œ AI Chess Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/)\n*   [ğŸ² AI Tic-Tac-Toe Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/)\n\n### ğŸ¤ Multi-agent Teams\n\n*   [ğŸ§² AI Competitor Intelligence Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/)\n*   [ğŸ’² AI Finance Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/)\n*   [ğŸ¨ AI Game Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/)\n*   [ğŸ‘¨â€âš–ï¸ AI Legal Agent Team (Cloud & Local)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/)\n*   [ğŸ’¼ AI Recruitment Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/)\n*   [ğŸ  AI Real Estate Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team)\n*   [ğŸ‘¨â€ğŸ’¼ AI Services Agency (CrewAI)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/)\n*   [ğŸ‘¨â€ğŸ« AI Teaching Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/)\n*   [ğŸ’» Multimodal Coding Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/)\n*   [âœ¨ Multimodal Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/)\n*   [ğŸŒ AI Travel Planner Agent Team](/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/)\n\n### ğŸ—£ï¸ Voice AI Agents\n\n*   [ğŸ—£ï¸ AI Audio Tour Agent](voice_ai_agents/ai_audio_tour_agent/)\n*   [ğŸ“ Customer Support Voice Agent](voice_ai_agents/customer_support_voice_agent/)\n*   [ğŸ”Š Voice RAG Agent (OpenAI SDK)](voice_ai_agents/voice_rag_openaisdk/)\n\n\n### ğŸŒ MCP AI Agents\n\n*   [â™¾ï¸ Browser MCP Agent](mcp_ai_agents/browser_mcp_agent/)\n*   [ğŸ™ GitHub MCP Agent](mcp_ai_agents/github_mcp_agent/)\n*   [ğŸ“‘ Notion MCP Agent](mcp_ai_agents/notion_mcp_agent) \n*   [ğŸŒ AI Travel Planner MCP Agent](mcp_ai_agents/ai_travel_planner_mcp_agent_team)\n\n### ğŸ“€ RAG (Retrieval Augmented Generation)\n*   [ğŸ”— Agentic RAG](rag_tutorials/agentic_rag/)\n*   [ğŸ§ Agentic RAG with Reasoning](rag_tutorials/agentic_rag_with_reasoning/)\n*   [ğŸ“° AI Blog Search (RAG)](rag_tutorials/ai_blog_search/)\n*   [ğŸ” Autonomous RAG](rag_tutorials/autonomous_rag/)\n*   [ğŸ”„ Corrective RAG (CRAG)](rag_tutorials/corrective_rag/)\n*   [ğŸ‹ Deepseek Local RAG Agent](rag_tutorials/deepseek_local_rag_agent/)\n*   [ğŸ¤” Gemini Agentic RAG](rag_tutorials/gemini_agentic_rag/)\n*   [ğŸ‘€ Hybrid Search RAG (Cloud)](rag_tutorials/hybrid_search_rag/)\n*   [ğŸ”„ Llama 3.1 Local RAG](rag_tutorials/llama3.1_local_rag/)\n*   [ğŸ–¥ï¸ Local Hybrid Search RAG](rag_tutorials/local_hybrid_search_rag/)\n*   [ğŸ¦™ Local RAG Agent](rag_tutorials/local_rag_agent/)\n*   [ğŸ§© RAG-as-a-Service](rag_tutorials/rag-as-a-service/)\n*   [âœ¨ RAG Agent with Cohere](rag_tutorials/rag_agent_cohere/)\n*   [â›“ï¸ Basic RAG Chain](rag_tutorials/rag_chain/)\n*   [ğŸ“  RAG with Database Routing](rag_tutorials/rag_database_routing/)\n*   [ğŸ–¼ï¸ Vision RAG](rag_tutorials/vision_rag/)\n\n### ğŸ’¾ LLM Apps with Memory Tutorials\n\n*   [ğŸ’¾ AI ArXiv Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/)\n*   [ğŸ›©ï¸ AI Travel Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/)\n*   [ğŸ’¬ Llama3 Stateful Chat](advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/)\n*   [ğŸ“ LLM App with Personalized Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/)\n*   [ğŸ—„ï¸ Local ChatGPT Clone with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/)\n*   [ğŸ§  Multi-LLM Application with Shared Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/)\n\n\n### ğŸ’¬ Chat with X Tutorials\n\n*   [ğŸ’¬ Chat with GitHub (GPT & Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_github/)\n*   [ğŸ“¨ Chat with Gmail](advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/)\n*   [ğŸ“„ Chat with PDF (GPT & Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/)\n*   [ğŸ“š Chat with Research Papers (ArXiv) (GPT & Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/)\n*   [ğŸ“ Chat with Substack](advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/)\n*   [ğŸ“½ï¸ Chat with YouTube Videos](advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/)\n\n### ğŸ”§ LLM Fine-tuning Tutorials\n\n*   [ğŸ”§ Llama 3.2 Fine-tuning](advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/)\n\n### ğŸ§‘â€ğŸ« AI Agent Framework Crash Course\n\n- [Google ADK Crash Course](ai_agent_framework_crash_course/google_adk_crash_course/)\n  - Starter agent; modelâ€‘agnostic (OpenAI, Claude)\n  - Structured outputs (Pydantic)\n  - Tools: builtâ€‘in, function, thirdâ€‘party, MCP tools\n  - Memory; callbacks; Plugins\n  - Simple multiâ€‘agent; Multiâ€‘agent patterns\n\n## ğŸš€ Getting Started\n\n1. **Clone the repository** \n\n    ```bash \n    git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git \n    ```\n\n2. **Navigate to the desired project directory**\n\n    ```bash \n    cd awesome-llm-apps/starter_ai_agents/ai_travel_agent\n    ```\n\n3. **Install the required dependencies**\n\n    ```bash\n    pip install -r requirements.txt\n    ```\n\n4. **Follow the project-specific instructions** in each project's `README.md` file to set up and run the app.\n\n## ğŸ¤ Contributing to Open Source\n\nContributions are welcome! If you have any ideas, improvements, or new apps to add, please create a new [GitHub Issue](https://github.com/Shubhamsaboo/awesome-llm-apps/issues) or submit a pull request. Make sure to follow the existing project structure and include a detailed `README.md` for each new app.\n\n### Thank You, Community, for the Support! ğŸ™\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&type=Date)](https://star-history.com/#Shubhamsaboo/awesome-llm-apps&Date)\n\nğŸŒŸ **Donâ€™t miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.**\n"
        },
        {
            "url": "https://github.com/MotiaDev/motia",
            "language": "TypeScript",
            "description": "Modern Backend Framework that unifies APIs, background jobs, workflows, and AI agents into a single cohesive system with built-in observability and state management.",
            "readme_summary": "<a href=\"https://motia.dev\">\n  <img src=\"assets/github-readme-banner.png\" alt=\"Motia Banner\" width=\"100%\">\n</a>\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/14032\" style=\"margin-right:8px;\">\n    <img src=\"https://trendshift.io/api/badge/repositories/14032\" alt=\"Motia\" style=\"width: 250px; height: 55px; margin-right:8px;\" width=\"250\" height=\"55\"/>\n  </a>\n  <a href=\"https://vercel.com/blog/summer-2025-oss-program#motia\" target=\"_blank\" style=\"margin-left:8px;\">\n    <img alt=\"Vercel OSS Program\" src=\"https://vercel.com/oss/program-badge.svg\" style=\"width: 250px; height: 55px; margin-left:8px;\" width=\"250\" height=\"55\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  <strong>ğŸ”¥ The Unified Backend Framework That Eliminates Runtime Fragmentation ğŸ”¥</strong>\n</p>\n<p align=\"center\">\n  <em>APIs, background jobs, workflows, and AI agents in one system. JavaScript, TypeScript, Python, and more in one codebase.</em>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/motia\">\n    <img src=\"https://img.shields.io/npm/v/motia?style=flat&logo=npm&logoColor=white&color=CB3837&labelColor=000000\" alt=\"npm version\">\n  </a>\n  <a href=\"https://github.com/MotiaDev/motia/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/badge/license-MIT-green?style=flat&logo=opensourceinitiative&logoColor=white&labelColor=000000\" alt=\"license\">\n  </a>\n  <a href=\"https://github.com/MotiaDev/motia\">\n    <img src=\"https://img.shields.io/github/stars/MotiaDev/motia?style=flat&logo=github&logoColor=white&color=yellow&labelColor=000000\" alt=\"GitHub stars\">\n  </a>\n  <a href=\"https://twitter.com/motiadev\" target=\"_blank\">\n    <img src=\"https://img.shields.io/badge/Follow-@motiadev-1DA1F2?style=flat&logo=twitter&logoColor=white&labelColor=000000\" alt=\"Twitter Follow\">\n  </a>\n  <a href=\"https://discord.gg/motia\" target=\"_blank\">\n    <img src=\"https://img.shields.io/discord/1322278831184281721?style=flat&logo=discord&logoColor=white&color=5865F2&label=Discord&labelColor=000000\" alt=\"Discord\">\n  </a>\n</p>\n<p align=\"center\">\n  <a href=\"https://www.motia.dev/manifesto\">ğŸ’¡ Motia Manifesto</a> â€¢\n  <a href=\"https://www.motia.dev/docs/getting-started/quick-start\">ğŸš€ Quick Start</a> â€¢\n  <a href=\"https://www.motia.dev/docs/concepts/steps/defining-steps\">ğŸ“‹ Defining Steps</a> â€¢\n  <a href=\"https://www.motia.dev/docs\">ğŸ“š Docs</a>\n</p>\n\n---\n\n## ğŸ¯ What is Motia?\n\n**Motia solves backend fragmentation.** \n\nModern software engineering is splintered â€“ APIs live in one framework, background jobs in another, queues have their own tooling, and AI agents are springing up in yet more isolated runtimes. **This fragmentation demands a unified system.**\n\nMotia unifies APIs, background jobs, workflows, and AI agents into a **single coherent system** with shared observability and developer experience. Similar to how React simplified frontend development where everything is a component, **Motia simplifies backend development where everything is a Step**.\n\nWrite **JavaScript, TypeScript, Python, and more** in the same workflow. **What used to take 5 frameworks to build now comes out of the box with Motia.**\n\n[![Motia combines APIs, background queues, and AI agents into one system](assets/Motia_Github_Repository_GIF.gif)](https://motia.dev)\n\n## ğŸš€ Quickstart\n\nGet Motia project up and running in **under 60 seconds**:\n\n### 1. Bootstrap a New Motia Project\n\n```bash\nnpx motia@latest create -i   # runs the interactive terminal\n```\n\nFollow the prompts to pick a template, project name, and language.\n\n### 2. Start the Workbench\n\nInside your new project folder, launch the dev server:\n\n```bash\nnpx motia dev # âœ http://localhost:3000\n```\n\nThis spins up the Motia Workbench â€“ a local UI for building, testing & observing your backend in real-time.\n\n![motia-terminal](assets/motia-terminal.gif)\n\n### 3. Hit Your First Endpoint\n\nOpen a new terminal tab and run:\n\n```bash\ncurl http://localhost:3000/default\n```\n\nYou should see the JSON response:\n\n```json\n{ \"message\": \"Hello World from Motia!\" }\n```\n\n### 4. Explore the Workbench UI\n\n![new-workbench](assets/new-workbench.png)\nThe Workbench is your command centre:\n\n- **ğŸŒŠ Flows** â€“ Visualise how your Steps connect.\n- **ğŸ”Œ Endpoints** â€“ Test APIs with one click and stream results live.\n- **ğŸ‘ï¸ Traces** â€“ Inspect end-to-end traces of every execution.\n- **ğŸ“Š Logs** â€“ View structured logs grouped by trace.\n- **ğŸª State** â€“ Inspect the key-value store across Steps.\n\n---\n\nğŸ‰ **That's it!** You now have a production-ready backend with everything you need:\n\n- âœ… **REST API endpoints** with automatic validation and error handling\n- âœ… **Visual debugger** with real-time flow inspection and tracing  \n- âœ… **Built-in observability** - logs, traces, and state visualization\n- âœ… **Hot-reload** for instant feedback during development\n- âœ… **Event-driven architecture** ready for complex workflows\n- âœ… **Multi-language support** - add Python, Javascript, or other languages anytime\n- âœ… **Zero configuration** - no infrastructure setup required\n\n\n> ğŸ’¡ **Want a more detailed walkthrough?**  \n> Check out the [Quick Start guide in our docs](https://www.motia.dev/docs/getting-started/quick-start) for step-by-step instructions and more examples.\n\n### ğŸ§± The Step Philosophy\n\n**Everything is a Step** â€“ similar to how React made everything a component, Motia makes every backend pattern a Step:\n\n- **ğŸ¯ Steps Represent Distinct Entry Points**: APIs, background jobs, scheduled tasks, and AI agents â€“ all unified under a single primitive\n- **ğŸŒ Any Language, One Workflow**: Write **JavaScript, TypeScript, Python, and more** in the same project. Use Python for AI agents, TypeScript for APIs, JavaScript for workflows â€“ all sharing state effortlessly  \n- **âš¡ Enterprise-Grade, Out of the Box**: Get **event-driven architecture, fault tolerance, observability, and real-time streaming** without complex infrastructure setup\n- **ğŸ‘ï¸ Automatic Observability**: Complete end-to-end tracing, structured logging, and state visualization. **No setup required** â€“ works in both local development and production\n- **ğŸŒŠ Composable Workflows**: Connect Steps by emitting and subscribing to events. Build complex, multi-stage processes with simple, declarative code\n- **ğŸª Unified State Management**: All Steps share a traced key-value store. Every `get`, `set`, and `delete` is automatically tracked across your entire workflow\n- **ğŸ”„ Built-in Fault Tolerance**: Retry mechanisms, error handling, and queue infrastructure abstracted away â€“ focus on business logic, not infrastructure\n\n---\n\n## ğŸš§ The Fragmentation Problem\n\nToday, backend engineers face several recurring challenges:\n\n- **ğŸ§© Fragmented Systems**: APIs in Express, background jobs in Celery/BullMQ, AI agents in LangChain â€“ each with different deployment, debugging, and scaling patterns\n- **ğŸŒ Multi-Language Barriers**: AI tools in Python, business logic in TypeScript â€“ forcing teams to choose between cutting-edge tech and their existing skillset  \n- **ğŸ” Observability Gaps**: Tracing requests across multiple frameworks and runtimes is complex and often incomplete\n- **âš–ï¸ Scalability vs. Velocity**: Choose between fast development (monolith) or proper scaling (microservices complexity)\n- **ğŸš€ Deployment Complexity**: Multiple runtimes mean multiple deploy targets, configs, and failure points\n\n**The rapid advancement of AI has made this worse** â€“ many cutting-edge AI tools are only available in specific languages, forcing companies to abandon their existing tech stack or miss out on breakthrough technologies.\n\n---\n\n## âœ… The Motia Solution\n\n**Motia removes this limitation** by unifying your entire backend into a single runtime where everything is a **Step**:\n\n### ğŸ¯ **Unified vs. Fragmented**\n- **Before**: APIs in Express, jobs in BullMQ, AI agents in LangChain\n- **After**: All backend patterns as composable Steps with shared state and observability\n\n### ğŸŒ **True Multi-Language Support**  \n- **Before**: Choose between Python AI tools OR your existing TypeScript stack\n- **After**: Each Step can be written in any language while sharing common state â€“ use Python for AI, TypeScript for APIs, JavaScript for workflows\n\n### ğŸ” **Built-in Observability**\n- **Before**: Complex tracing setups across multiple frameworks\n- **After**: Complete observability toolkit available in both cloud and local environments out of the box\n\n### âš–ï¸ **Scalability Without Complexity**\n- **Before**: Choose between monolith simplicity or microservice complexity  \n- **After**: Each Step scales independently, avoiding bottlenecks while maintaining development velocity\n\n### ğŸš€ **One-Click Everything**\n- **Before**: Multiple deployment pipelines, configs, and failure points\n- **After**: Single deployable with atomic blue/green deployments and instant rollbacks\n\n| **Traditional Stack**       | **Motia**                               |\n| --------------------------- | --------------------------------------- |\n| Multiple deployment targets | **Single unified deployment**           |\n| Fragmented observability    | **End-to-end tracing**                  |\n| Language silos              | **JavaScript, TypeScript, Python, etc** |\n| Context-switching overhead  | **Single intuitive model**              |\n| Manual error handling       | **Automatic retries & fault tolerance** |\n| Complex infrastructure      | **Zero-config queue & streaming**       |\n\n---\n\n## ğŸ”§ Supported Step Types\n\n| Type        | Trigger               | Use Case                              |\n| ----------- | --------------------- | ------------------------------------- |\n| **`api`**   | HTTP Request          | Expose REST endpoints                 |\n| **`event`** | Emitted Topics        | React to internal or external events  |\n| **`cron`**  | Scheduled Time (cron) | Automate recurring jobs               |\n| **`noop`**  | None                  | Placeholder for manual/external tasks |\n\n---\n\n### ğŸ¤” How it Works\n\n**One framework. All backend patterns.** Motia replaces your entire backend stack with a single, event-driven system:\n\n**ğŸš€ Replace Multiple Frameworks:**\n- **Instead of**: Express/Nest.js + BullMQ + Temporal + LangChain + custom observability\n- **Use**: Motia Steps with automatic observability, queuing, and multi-language support\n\n**âš¡ Simple but Powerful:**\n- **Need a REST API?** Create an `api` step â†’ instant HTTP endpoint with validation, tracing, and error handling\n- **Need background processing?** Emit an event â†’ `event` steps pick it up asynchronously with built-in retries and fault tolerance  \n- **Need scheduled jobs?** Use a `cron` step â†’ automatic scheduling with full observability\n- **Need AI agents?** Write Python steps with access to the entire ecosystem (PyTorch, transformers, etc.) while sharing state with TypeScript APIs\n\n**ğŸ”„ Event-Driven by Design:**\nEach Step can emit events that trigger other Steps, creating powerful workflows that automatically handle:\n- **Parallel processing** across multiple languages\n- **Fault tolerance** with automatic retries  \n- **Real-time updates** streamed to clients\n- **Complete traceability** of every operation\n\n**The result?** What used to require 5+ frameworks, complex deployment pipelines, and weeks of infrastructure setup now works out of the box with Motia.\n\n## âš¡ Core Concepts\n\nThe **Step** is Motia's core primitive. The following concepts are deeply integrated with Steps to help you build powerful, complex, and scalable backends:\n\n### ğŸ”‘ Steps & Step Types\n\nUnderstand the three ways Steps are triggered:\n\n- **HTTP (`api`)** â€“ Build REST/GraphQL endpoints with zero boilerplate.\n- **Events (`event`)** â€“ React to internal or external events emitted by other steps.\n- **Cron (`cron`)** â€“ Schedule recurring jobs with a familiar cron syntax.\n\n### ğŸ“£ Emit & Subscribe (Event-Driven Workflows)\n\nSteps talk to each other by **emitting** and **subscribing** to topics. This decouples producers from consumers and lets you compose complex workflows with simple, declarative code.\n\n### ğŸª State Management\n\nAll steps share a unified key-value state store. Every `get`, `set`, and `delete` is automatically traced so you always know when and where your data changed.\n\n### ğŸ“Š Structured Logging\n\nMotia provides structured, JSON logs correlated with trace IDs and step names. Search and filter your logs without regex hassle.\n\n### ğŸ“¡ Streams: Real-time Messaging\n\nPush live updates from long-running or asynchronous workflows to clients without polling. Perfect for dashboards, progress indicators, and interactive AI agents.\n\n### ğŸ‘ï¸ End-to-End Observability with Traces\n\nEvery execution generates a full trace, capturing step timelines, state operations, emits, stream calls, and logs. Visualise everything in the Workbench's Traces UI and debug faster.\n\n---\n\n## ğŸ—‚ Production-Ready Examples\n\n**â­ Explore 20+ sophisticated examples** demonstrating real-world use cases from AI agents to enterprise workflows: **[View All Examples â†’](https://github.com/MotiaDev/motia-examples)**\n\n### ğŸ¤– **AI Agents & Workflows**\n\n| **AI Deep Research Agent** | **Finance Analysis Agent** | **PDF RAG System** |\n|----------------------------|----------------------------|-------------------|\n| Comprehensive web research with iterative analysis and synthesis | Real-time financial data + AI insights for investment analysis | Document processing with Docling, Weaviate, and OpenAI RAG |\n| [View Example â†’](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-deep-research-agent) | [View Example â†’](https://github.com/MotiaDev/motia-examples/tree/main/examples/finance-agent) | [View Example â†’](https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-docling-weaviate) |\n\n| **GitHub PR Manager** | **Gmail Intelligence** | **Vision Analysis** |\n|-----------------------|------------------------|-------------------|\n| AI-powered PR classification, labeling, and reviewer assignment | Smart email analysis, auto-responses, and Discord summaries | Multi-modal conversation analysis with visual understanding |\n| [View Example â†’](https://github.com/MotiaDev/motia-examples/tree/main/examples/github-integration-workflow) | [View Example â†’](https://github.com/MotiaDev/motia-examples/tree/main/examples/gmail-workflow) | [View Example â†’](https://github.com/MotiaDev/motia-examples/tree/main/examples/conversation-analyzer-vision) |\n\n### ğŸŒŠ **Real-Time Streaming & Chat**\n\n| **Streaming AI Chatbot** | **Real-Time Chat App** | **Live Health Monitor** |\n|--------------------------|------------------------|------------------------|\n| Token-by-token AI responses with WebSocket streaming | Multi-user chat with real-time message processing and moderation | Production uptime monitoring with intelligent Discord alerts |\n| [View Example â†’](https://github.com/MotiaDev/motia-examples/tree/main/examples/streaming-ai-chatbot) | [View Example â†’](https://github.com/MotiaDev/motia-examples/tree/main/examples/realtime-chat-application) | [View Example â†’](https://github.com/MotiaDev/motia-examples/tree/main/examples/realtime-uptime-monitor) |\n\n### âš¡ **Parallel Processing & Workflows** \n\n| **Parallel Execution Demo** | **Content Automation** | **Task Management** |\n|-----------------------------|------------------------|-------------------|\n| Concurrent task processing with workload distribution | Blog-to-Tweet automation with AI content optimization | Trello workflow automation with AI task validation |\n| [View Example â†’](https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-parallel-execution) | [View Example â†’](https://github.com/MotiaDev/motia-examples/tree/main/examples/blog-to-tweet-automation) | [View Example â†’](https://github.com/MotiaDev/motia-examples/tree/main/examples/trello-flow) |\n\n### ğŸ¯ **Key Features Demonstrated:**\n- âœ… **Multi-Language Workflows** - JavaScript, TypeScript, Python working together\n- âœ… **Real-Time Streaming** - WebSocket integration with live updates  \n- âœ… **AI Integration** - OpenAI, Claude, vision models, and custom AI workflows\n- âœ… **Event-Driven Architecture** - Complex workflows with automatic retry and fault tolerance\n- âœ… **Production Monitoring** - Health checks, uptime monitoring, and intelligent alerting\n- âœ… **Parallel Processing** - Concurrent execution and workload distribution\n- âœ… **Enterprise Integration** - GitHub, Gmail, Trello, Discord, and social media APIs\n\n**ğŸš€ Each example includes:** Complete source code â€¢ Step-by-step tutorials â€¢ Production deployment guides â€¢ Docker configurations\n\n---\n\n## ğŸŒ Language Support\n\nWrite steps in your preferred language:\n\n| Language       | Status         | Example           |\n| -------------- | -------------- | ----------------- |\n| **JavaScript** | âœ… Stable      | `handler.step.js` |\n| **TypeScript** | âœ… Stable      | `handler.step.ts` |\n| **Python**     | âœ… Stable      | `handler.step.py` |\n| **Ruby**       | ğŸš§ Beta        | `handler.step.rb` |\n| **Go**         | ğŸ”„ Coming Soon | `handler.step.go` |\n| **Rust**       | ğŸ”„ Coming Soon | `handler.step.rs` |\n\n---\n\n### ğŸ’¬ **Get Help**\n\n- **ğŸ“‹ Questions**: Use our [Discord community](https://discord.gg/motia)\n- **ğŸ› Bug Reports**: [GitHub Issues](https://github.com/MotiaDev/motia/issues)\n- **ğŸ“– Documentation**: [Official Docs](https://motia.dev/docs)\n- **ğŸ“° Blog**: [Motia Blog](https://blog.motia.dev)\n- **ğŸ¥ Youtube**: [Motia Youtube](https://www.youtube.com/@motiadev)\n\n### ğŸ¤ **Contributing**\n\nWe welcome contributions! Whether it's:\n\n- ğŸ› Bug fixes and improvements\n- âœ¨ New features and step types\n- ğŸ“š Documentation and examples\n- ğŸŒ Language support additions\n- ğŸ¨ Workbench UI enhancements\n\nCheck out our [Contributing Guide](https://github.com/MotiaDev/motia/blob/main/CONTRIBUTING.md) to get started.\n\n---\n\n<div align=\"center\">\n\n**ğŸŒŸ Ready to unify your backend?**\n\n[ğŸš€ **Get Started Now**](https://motia.dev) â€¢ [ğŸ“– **Read the Docs**](https://motia.dev/docs) â€¢ [ğŸ’¬ **Join Discord**](https://discord.com/invite/nJFfsH5d6v)\n\n</div>\n\n---\n\n<div align=\"center\">\n\n[![Star History Chart](https://api.star-history.com/svg?repos=motiadev/motia&type=Date)](https://www.star-history.com/#motiadev/motia&Date)\n\n<sub>Built with â¤ï¸ by the Motia team â€¢ **Star us if you find [Motia](https://github.com/orgs/MotiaDev/motia) useful!** â­</sub>\n\n</div>\n\n### ğŸš§ Roadmap\n\nWe have a public roadmap for Motia, you can view it [here](https://github.com/orgs/MotiaDev/projects/2/views/4).\n\nFeel free to add comments to the issues, or create a new issue if you have a feature request.\n\n| Feature                               | Status  | Link                                                 | Description                            |\n| ------------------------------------- | ------- | ---------------------------------------------------- | -------------------------------------- |\n| Python Types                          | Planned | [#485](https://github.com/MotiaDev/motia/issues/485) | Add support for Python types           |\n| Streams: RBAC                         | Planned | [#495](https://github.com/MotiaDev/motia/issues/495) | Add support for RBAC                   |\n| Streams: Workbench UI                 | Planned | [#497](https://github.com/MotiaDev/motia/issues/497) | Add support for Workbench UI           |\n| Queue Strategies                      | Planned | [#476](https://github.com/MotiaDev/motia/issues/476) | Add support for Queue Strategies       |\n| Reactive Steps                        | Planned | [#477](https://github.com/MotiaDev/motia/issues/477) | Add support for Reactive Steps         |\n| Allow cloud configuration             | Planned | [#478](https://github.com/MotiaDev/motia/issues/478) | Add support for cloud configuration    |\n| BYOC: Bring your own Cloud: AWS       | Planned | [#479](https://github.com/MotiaDev/motia/issues/479) | Add support for AWS                    |\n| Point in time triggers                | Planned | [#480](https://github.com/MotiaDev/motia/issues/480) | Add support for Point in time triggers |\n| Workbench plugins                     | Planned | [#481](https://github.com/MotiaDev/motia/issues/481) | Add support for Workbench plugins      |\n| Rewrite our Core in either Go or Rust | Planned | [#482](https://github.com/MotiaDev/motia/issues/482) | Rewrite our Core in either Go or Rust  |\n| Decrease deployment time              | Planned | [#483](https://github.com/MotiaDev/motia/issues/483) | Decrease deployment time               |\n| Built-in database support             | Planned | [#484](https://github.com/MotiaDev/motia/issues/484) | Add support for built-in database      |\n| BYOC: Google Cloud Platform           | Planned | [#486](https://github.com/MotiaDev/motia/issues/486) | Add support for Google Cloud Platform  |\n| BYOC: Microsoft Azure                 | Planned | [#487](https://github.com/MotiaDev/motia/issues/487) | Add support for Microsoft Azure        |\n| BYOC: Vercel                          | Planned | [#488](https://github.com/MotiaDev/motia/issues/488) | Add support for Vercel                 |\n| BYOC: Cloudflare                      | Planned | [#489](https://github.com/MotiaDev/motia/issues/489) | Add support for Cloudflare             |\n| New languages: Go                     | Planned | [#490](https://github.com/MotiaDev/motia/issues/490) | Add support for Go                     |\n| New languages: Rust                   | Planned | [#491](https://github.com/MotiaDev/motia/issues/491) | Add support for Rust                   |\n| New languages: Java                   | Planned | [#492](https://github.com/MotiaDev/motia/issues/492) | Add support for Java                   |\n| New languages: Ruby                   | Planned | [#493](https://github.com/MotiaDev/motia/issues/493) | Add support for Ruby                   |\n| New languages: C#                     | Planned | [#494](https://github.com/MotiaDev/motia/issues/494) | Add support for C#                     |\n| BYOC: Kubernetes                      | Planned | [#496](https://github.com/MotiaDev/motia/issues/496) | Add support for Kubernetes             |\n"
        },
        {
            "url": "https://github.com/OpenBB-finance/OpenBB",
            "language": "Python",
            "description": "Financial data aggregator for humans and AI agents.",
            "readme_summary": "<br />\n<img src=\"https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-light.svg?raw=true#gh-light-mode-only\" alt=\"OpenBB Platform logo\" width=\"600\">\n<img src=\"https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only\" alt=\"OpenBB Platform logo\" width=\"600\">\n<br />\n<br />\n\n[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&label=Follow%20%40openbb_finance)](https://x.com/openbb_finance)\n[![Discord Shield](https://img.shields.io/discord/831165782750789672)](https://discord.com/invite/xPHTuHCmuV)\n[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB)\n<a href=\"https://codespaces.new/OpenBB-finance/OpenBB\">\n  <img src=\"https://github.com/codespaces/badge.svg\" height=\"20\" />\n</a>\n<a target=\"_blank\" href=\"https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb\">\n  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n[![PyPI](https://img.shields.io/pypi/v/openbb?color=blue&label=PyPI%20Package)](https://pypi.org/project/openbb/)\n\nThe first financial Platform that is open source.\n\nThe OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.\n\nGet started with: `pip install openbb`\n\n```python\nfrom openbb import obb\noutput = obb.equity.price.historical(\"AAPL\")\ndf = output.to_dataframe()\n```\n\nYou can sign up to the [OpenBB Hub](https://my.openbb.co/login) to get the most out of the OpenBB ecosystem.\n\nData integrations available can be found here: <https://docs.openbb.co/platform/reference>\n\n---\n\n## OpenBB Workspace\n\nWhile the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.\n\nIf you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at <https://pro.openbb.co>.\n\n<a href=\"https://pro.openbb.co\">\n  <div align=\"center\">\n  <img src=\"https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png\" alt=\"Logo\" width=\"1000\">\n  </div>\n</a>\n\nData integration:\n\n- You can learn more about adding data to the OpenBB workspace from the [docs](https://docs.openbb.co/workspace) or [this open source repository](https://github.com/OpenBB-finance/backends-for-openbb).\n\nAI Agents integration:\n\n- You can learn more about adding AI agents to the OpenBB workspace from [this open source repository](https://github.com/OpenBB-finance/agents-for-openbb).\n\n### Integrating OpenBB Platform to the OpenBB Workspace\n\nConnect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.\n\n#### Run OpenBB Platform backend\n\n- Install the packages.\n\n```sh\npip install \"openbb[all]\"\n```\n\n- Start the API server over localhost.\n\n```sh\nopenbb-api\n```\n\nThis will launch a FastAPI server, via Uvicorn, at `127.0.0.1:6900`.\n\nYou can check that it works by going to <http://127.0.0.1:6900>.\n\n#### Integrate OpenBB Platform backend to OpenBB Workspace\n\nSign-in to the [OpenBB Workspace](https://pro.openbb.co/), and follow the following steps:\n\n![CleanShot 2025-05-17 at 09 51 56@2x](https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069)\n\n1. Go to the \"Apps\" tab\n2. Click on \"Connect backend\"\n3. Fill in the form with:\n   Name: OpenBB Platform\n   URL: <http://127.0.0.1:6900>\n4. Click on \"Test\". You should get a \"Test successful\" with the number of apps found.\n5. Click on \"Add\".\n\nThat's it.\n\n---\n\n<!-- TABLE OF CONTENTS -->\n<details closed=\"closed\">\n  <summary><h2 style=\"display: inline-block\">Table of Contents</h2></summary>\n  <ol>\n    <li><a href=\"#1-installation\">Installation</a></li>\n    <li><a href=\"#2-contributing\">Contributing</a></li>\n    <li><a href=\"#3-license\">License</a></li>\n    <li><a href=\"#4-disclaimer\">Disclaimer</a></li>\n    <li><a href=\"#5-contacts\">Contacts</a></li>\n    <li><a href=\"#6-star-history\">Star History</a></li>\n    <li><a href=\"#7-contributors\">Contributors</a></li>\n  </ol>\n</details>\n\n## 1. Installation\n\nThe OpenBB Platform can be installed as a [PyPI package](https://pypi.org/project/openbb/) by running `pip install openbb`\n\nor by cloning the repository directly with `git clone https://github.com/OpenBB-finance/OpenBB.git`.\n\nPlease find more about the installation process, in the [OpenBB Documentation](https://docs.openbb.co/platform/installation).\n\n### OpenBB Platform CLI installation\n\nThe OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.\n\nIt can be installed by running `pip install openbb-cli`\n\nor by cloning the repository directly with  `git clone https://github.com/OpenBB-finance/OpenBB.git`.\n\nPlease find more about the installation process in the [OpenBB Documentation](https://docs.openbb.co/cli/installation).\n\n## 2. Contributing\n\nThere are three main ways of contributing to this project. (Hopefully you have starred the project by now â­ï¸)\n\n### Become a Contributor\n\n- More information on our [Contributing Documentation](https://docs.openbb.co/platform/developer_guide/misc/contributing).\n\n### Create a GitHub ticket\n\nBefore creating a ticket make sure the one you are creating doesn't exist already [here](https://github.com/OpenBB-finance/OpenBB/issues)\n\n- [Report bug](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&labels=bug&template=bug_report.md&title=%5BBug%5D)\n- [Suggest improvement](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&labels=enhancement&template=enhancement.md&title=%5BIMPROVE%5D)\n- [Request a feature](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&labels=new+feature&template=feature_request.md&title=%5BFR%5D)\n\n### Provide feedback\n\nWe are most active on [our Discord](https://openbb.co/discord), but feel free to reach out to us in any of [our social media](https://openbb.co/links) for feedback.\n\n## 3. License\n\nDistributed under the AGPLv3 License. See\n[LICENSE](https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE) for more information.\n\n## 4. Disclaimer\n\nTrading in financial instruments involves high risks including the risk of losing some, or all, of your investment\namount, and may not be suitable for all investors.\n\nBefore deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.\n\nThe data contained in the OpenBB Platform is not necessarily accurate.\n\nOpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.\n\nAll names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.\n\nOur use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.\n\n## 5. Contacts\n\nIf you have any questions about the platform or anything OpenBB, feel free to email us at `support@openbb.co`\n\nIf you want to say hi, or are interested in partnering with us, feel free to reach us at `hello@openbb.co`\n\nAny of our social media platforms: [openbb.co/links](https://openbb.co/links)\n\n## 6. Star History\n\nThis is a proxy of our growth and that we are just getting started.\n\nBut for more metrics important to us check [openbb.co/open](https://openbb.co/open).\n\n[![Star History Chart](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&type=Date&theme=dark)](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&type=Date&theme=dark)\n\n## 7. Contributors\n\nOpenBB wouldn't be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.\n\n<a href=\"https://github.com/OpenBB-finance/OpenBB/graphs/contributors\">\n   <img src=\"https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB\" width=\"800\"/>\n</a>\n\n<!-- MARKDOWN LINKS & IMAGES -->\n<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->\n\n[contributors-shield]: https://img.shields.io/github/contributors/OpenBB-finance/OpenBB.svg?style=for-the-badge\n[contributors-url]: https://github.com/OpenBB-finance/OpenBB/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/OpenBB-finance/OpenBB.svg?style=for-the-badge\n[forks-url]: https://github.com/OpenBB-finance/OpenBB/network/members\n[stars-shield]: https://img.shields.io/github/stars/OpenBB-finance/OpenBB.svg?style=for-the-badge\n[stars-url]: https://github.com/OpenBB-finance/OpenBB/stargazers\n[issues-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB.svg?style=for-the-badge&color=blue\n[issues-url]: https://github.com/OpenBB-finance/OpenBB/issues\n[bugs-open-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&color=yellow\n[bugs-open-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aopen\n[bugs-closed-shield]: https://img.shields.io/github/issues-closed/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&color=success\n[bugs-closed-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aclosed\n[license-shield]: https://img.shields.io/github/license/OpenBB-finance/OpenBB.svg?style=for-the-badge\n[license-url]: https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE.txt\n[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555\n[linkedin-url]: https://linkedin.com/in/DidierRLopes\n"
        }
    ],
    "L2 Summary": [
        "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual   Mathematical Reasoning\n\nå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¤šé¡¹ä»»åŠ¡ä¸­å±•ç°äº†å‡ºè‰²çš„èƒ½åŠ›ï¼Œä½†åœ¨å¤æ‚æ•°å­¦æ¨ç†æ–¹é¢ä»å­˜åœ¨ä¸è¶³ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­äºæ•°æ®é›†æ„å»ºå’Œæ–¹æ³•ä¼˜åŒ–ï¼Œå¾€å¾€å¿½è§†äº†ä¸¤ä¸ªå…³é”®æ–¹é¢ï¼šå…¨é¢çš„çŸ¥è¯†é©±åŠ¨è®¾è®¡å’Œä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ•°æ®ç©ºé—´å»ºæ¨¡ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†We-Math 2.0ï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€ç³»ç»Ÿï¼Œé›†æˆäº†ç»“æ„åŒ–çš„æ•°å­¦çŸ¥è¯†ä½“ç³»ã€ä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ•°æ®ç©ºé—´å»ºæ¨¡ä»¥åŠåŸºäºå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒèŒƒå¼ï¼Œä»¥å…¨é¢æå‡MLLMsçš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚\n\nWe-Math 2.0çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬å››ä¸ªæ–¹é¢ï¼šé¦–å…ˆï¼Œæ„å»ºäº†ä¸€ä¸ªåä¸ºMathBookçš„çŸ¥è¯†ç³»ç»Ÿï¼ŒåŒ…å«äº”ä¸ªå±‚çº§çš„491ä¸ªçŸ¥è¯†ç‚¹å’Œ1819æ¡åŸºæœ¬åŸåˆ™ã€‚å…¶æ¬¡ï¼Œå¼€å‘äº†MathBook-Standardæ•°æ®é›†ï¼Œç¡®ä¿å¹¿æ³›çš„æ¦‚å¿µè¦†ç›–å’Œçµæ´»æ€§ï¼Œå¹¶é€šè¿‡åŒé‡æ‰©å±•å®ç°ã€‚æ­¤å¤–ï¼Œå®šä¹‰äº†ä¸€ä¸ªä¸‰ç»´éš¾åº¦ç©ºé—´ï¼Œä¸ºæ¯ä¸ªé—®é¢˜ç”Ÿæˆ7ä¸ªæ¸è¿›å˜ä½“ï¼Œå½¢æˆäº†MathBook-Proï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¼ºå¥è®­ç»ƒçš„æŒ‘æˆ˜æ€§æ•°æ®é›†ã€‚ç¬¬ä¸‰ï¼Œæå‡ºäº†MathBook-RLï¼Œä¸€ä¸ªä¸¤é˜¶æ®µçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼ŒåŒ…æ‹¬å†·å¯åŠ¨å¾®è°ƒï¼Œæ—¨åœ¨å°†æ¨¡å‹ä¸çŸ¥è¯†å¯¼å‘çš„æ€ç»´é“¾æ¨ç†å¯¹é½ï¼Œä»¥åŠæ¸è¿›å¯¹é½å¼ºåŒ–å­¦ä¹ ï¼Œåˆ©ç”¨å¹³å‡å¥–åŠ±å­¦ä¹ å’ŒåŠ¨æ€æ•°æ®è°ƒåº¦å®ç°ä¸åŒéš¾åº¦æ°´å¹³çš„æ¸è¿›å¯¹é½ã€‚\n\næœ€åï¼ŒWe-Math 2.0å¼•å…¥äº†MathBookEvalï¼Œä¸€ä¸ªå…¨é¢çš„åŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–æ‰€æœ‰491ä¸ªçŸ¥è¯†ç‚¹ï¼Œå¹¶å…·æœ‰å¤šæ ·çš„æ¨ç†æ­¥éª¤åˆ†å¸ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMathBook-RLåœ¨å››ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹¶åœ¨MathBookEvalä¸Šå–å¾—äº†å¼ºåŠ²çš„ç»“æœï¼Œæ˜¾ç¤ºå‡ºåœ¨æ•°å­¦æ¨ç†æ–¹é¢çš„è‰¯å¥½æ³›åŒ–èƒ½åŠ›ã€‚",
        "NextStep-1: Toward Autoregressive Image Generation with Continuous   Tokens at Scale\n\nå½“å‰ä¸»æµçš„è‡ªå›å½’ï¼ˆARï¼‰æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­ï¼Œé€šå¸¸ä¾èµ–äºè®¡ç®—é‡å¤§çš„æ‰©æ•£æ¨¡å‹æ¥å¤„ç†è¿ç»­çš„å›¾åƒæ ‡è®°ï¼Œæˆ–è€…ä½¿ç”¨å‘é‡é‡åŒ–ï¼ˆVQï¼‰æ¥è·å–ç¦»æ•£æ ‡è®°ï¼Œä½†è¿™ä¼šå¯¼è‡´é‡åŒ–æŸå¤±ã€‚æœ¬æ–‡æå‡ºäº†NextStep-1ï¼Œè¿™æ˜¯ä¸€ä¸ªæ‹¥æœ‰140äº¿å‚æ•°çš„è‡ªå›å½’æ¨¡å‹ï¼Œé…å¤‡äº†ä¸€ä¸ª1.57äº¿å‚æ•°çš„æµåŒ¹é…å¤´ï¼Œé‡‡ç”¨ç¦»æ•£æ–‡æœ¬æ ‡è®°å’Œè¿ç»­å›¾åƒæ ‡è®°è¿›è¡Œè®­ç»ƒï¼Œç›®æ ‡æ˜¯ä¸‹ä¸€ä¸ªæ ‡è®°çš„é¢„æµ‹ã€‚NextStep-1åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å®ç°äº†è‡ªå›å½’æ¨¡å‹çš„æœ€å…ˆè¿›æ€§èƒ½ï¼Œå±•ç°äº†åœ¨é«˜ä¿çœŸå›¾åƒåˆæˆæ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ã€‚\n\næ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å›¾åƒç¼–è¾‘æ–¹é¢ä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œçªæ˜¾äº†æˆ‘ä»¬ç»Ÿä¸€æ–¹æ³•çš„å¼ºå¤§å’Œå¤šæ ·æ€§ã€‚ä¸ºäº†ä¿ƒè¿›å¼€æ”¾ç ”ç©¶ï¼Œæˆ‘ä»¬è®¡åˆ’å‘ç¤¾åŒºå‘å¸ƒæˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹ï¼Œä»¥ä¾¿æ›´å¤šçš„ç ”ç©¶è€…èƒ½å¤Ÿä½¿ç”¨å’Œæ”¹è¿›è¿™ä¸€æŠ€æœ¯ã€‚è¿™ä¸€åˆ›æ–°ä¸ä»…æ¨åŠ¨äº†è‡ªå›å½’æ¨¡å‹çš„å‘å±•ï¼Œä¹Ÿä¸ºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå¸¦æ¥äº†æ–°çš„å¯èƒ½æ€§ï¼Œå±•ç¤ºäº†åœ¨ç”Ÿæˆå’Œç¼–è¾‘å›¾åƒæ–¹é¢çš„å¹¿æ³›åº”ç”¨æ½œåŠ›ã€‚",
        "ToonComposer: Streamlining Cartoon Production with Generative   Post-Keyframing\n\nä¼ ç»Ÿçš„å¡é€šå’ŒåŠ¨æ¼«åˆ¶ä½œè¿‡ç¨‹åŒ…æ‹¬å…³é”®å¸§ã€è¡¥é—´å’Œä¸Šè‰²ç­‰å¤šä¸ªé˜¶æ®µï¼Œè¿™äº›é˜¶æ®µé€šå¸¸éœ€è¦å¤§é‡çš„äººå·¥åŠªåŠ›ã€‚å°½ç®¡è¿‘å¹´æ¥äººå·¥æ™ºèƒ½æŠ€æœ¯æœ‰æ‰€è¿›æ­¥ï¼Œä½†ç°æœ‰çš„æ–¹æ³•å¾€å¾€å°†è¿™äº›é˜¶æ®µåˆ†å¼€å¤„ç†ï¼Œå¯¼è‡´é”™è¯¯ç´¯ç§¯å’Œä¼ªå½±çš„äº§ç”Ÿã€‚ä¾‹å¦‚ï¼Œè¡¥é—´æ–¹æ³•åœ¨å¤„ç†å¤§å¹…åº¦è¿åŠ¨æ—¶è¡¨ç°ä¸ä½³ï¼Œè€Œä¸Šè‰²æ–¹æ³•åˆ™éœ€è¦å¯†é›†çš„é€å¸§è‰å›¾ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ToonComposerï¼Œè¿™æ˜¯ä¸€ç§å°†è¡¥é—´å’Œä¸Šè‰²ç»Ÿä¸€ä¸ºå•ä¸€åå…³é”®å¸§é˜¶æ®µçš„ç”Ÿæˆæ¨¡å‹ã€‚\n\nToonComposeré‡‡ç”¨ç¨€ç–è‰å›¾æ³¨å…¥æœºåˆ¶ï¼Œé€šè¿‡å…³é”®å¸§è‰å›¾æä¾›ç²¾ç¡®æ§åˆ¶ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜ä½¿ç”¨ç©ºé—´ä½ç§©é€‚é…å™¨çš„å¡é€šé€‚åº”æ–¹æ³•ï¼Œå°†ç°ä»£è§†é¢‘åŸºç¡€æ¨¡å‹è°ƒæ•´åˆ°å¡é€šé¢†åŸŸï¼ŒåŒæ—¶ä¿æŒå…¶æ—¶é—´å…ˆéªŒä¸å˜ã€‚ToonComposeråªéœ€ä¸€ä¸ªè‰å›¾å’Œä¸€ä¸ªä¸Šè‰²å‚è€ƒå¸§ï¼Œå°±èƒ½åœ¨ç¨€ç–è¾“å…¥ä¸‹è¡¨ç°å‡ºè‰²ï¼ŒåŒæ—¶è¿˜æ”¯æŒåœ¨ä»»ä½•æ—¶é—´ä½ç½®ä½¿ç”¨å¤šä¸ªè‰å›¾ï¼Œä»¥å®ç°æ›´ç²¾ç¡®çš„è¿åŠ¨æ§åˆ¶ã€‚è¿™ç§åŒé‡èƒ½åŠ›å‡å°‘äº†äººå·¥å·¥ä½œé‡ï¼Œæé«˜äº†çµæ´»æ€§ï¼Œä½¿è‰ºæœ¯å®¶åœ¨å®é™…åº”ç”¨ä¸­æ›´åŠ å¾—å¿ƒåº”æ‰‹ã€‚\n\nä¸ºäº†è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥åˆ›å»ºäº†PKBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«äººæ‰‹ç»˜åˆ¶è‰å›¾çš„åŸºå‡†ï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„ä½¿ç”¨åœºæ™¯ã€‚æˆ‘ä»¬çš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒToonComposeråœ¨è§†è§‰è´¨é‡ã€è¿åŠ¨ä¸€è‡´æ€§å’Œç”Ÿäº§æ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæä¾›äº†ä¸€ç§æ›´ä¼˜è¶Šå’Œçµæ´»çš„AIè¾…åŠ©å¡é€šåˆ¶ä½œè§£å†³æ–¹æ¡ˆã€‚",
        "PRELUDE: A Benchmark Designed to Require Global Comprehension and   Reasoning over Long Contexts\n\næˆ‘ä»¬ä»‹ç»äº†PRELUDEï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°é•¿æ–‡æœ¬ç†è§£èƒ½åŠ›çš„åŸºå‡†ï¼Œä»»åŠ¡æ˜¯åˆ¤æ–­ä¸€ä¸ªè§’è‰²çš„å‰ä¼ æ•…äº‹æ˜¯å¦ä¸åŸè‘—çš„å™è¿°ä¸€è‡´ã€‚ä¸ç°æœ‰åŸºå‡†ç›¸æ¯”ï¼Œè¿™ä¸€ä»»åŠ¡å¯¹æ•´ä½“ç†è§£å’Œæ·±åº¦æ¨ç†çš„è¦æ±‚æ›´é«˜ï¼Œå› ä¸ºå‰ä¼ å¹¶ä¸æ˜¯åŸæ•…äº‹çš„ä¸€éƒ¨åˆ†ï¼Œè¯„ä¼°å…¶åˆç†æ€§é€šå¸¸éœ€è¦æœç´¢å’Œæ•´åˆé—´æ¥ç›¸å…³çš„ä¿¡æ¯ã€‚å®è¯ç ”ç©¶è¡¨æ˜ï¼Œ88%çš„æ¡ˆä¾‹éœ€è¦ä»å™è¿°çš„å¤šä¸ªéƒ¨åˆ†è·å–è¯æ®ã€‚\n\nå®éªŒç»“æœçªæ˜¾äº†è¿™ä¸€ä»»åŠ¡çš„æŒ‘æˆ˜æ€§ï¼šåœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œä½¿ç”¨æœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œé¢†åŸŸå†…è®­ç»ƒï¼Œä»¥åŠå•†ä¸šæ·±åº¦ç ”ç©¶æœåŠ¡çš„è¡¨ç°ä¸Šï¼Œæ¨¡å‹çš„è¡¨ç°æ™®éè½åäºäººç±»è¶…è¿‡15%ã€‚è¿›ä¸€æ­¥çš„äººç±»ç ”ç©¶æ˜¾ç¤ºï¼Œå°½ç®¡æ¨¡å‹ç»å¸¸èƒ½ç»™å‡ºæ­£ç¡®ç­”æ¡ˆï¼Œä½†å…¶æ¨ç†è¿‡ç¨‹å­˜åœ¨ç¼ºé™·ï¼Œå¯¼è‡´æ¨ç†å‡†ç¡®æ€§ä¸äººç±»ç›¸æ¯”å­˜åœ¨è¶…è¿‡30%çš„å·®è·ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†åœ¨é•¿æ–‡æœ¬ç†è§£å’Œæ¨ç†æ–¹é¢ä»æœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ã€‚",
        "UI-Venus Technical Report: Building High-performance UI Agents with RFT\n\næˆ‘ä»¬ä»‹ç»äº†UI-Venusï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„åŸç”Ÿç”¨æˆ·ç•Œé¢ä»£ç†ï¼Œèƒ½å¤Ÿä»…é€šè¿‡æˆªå›¾ä½œä¸ºè¾“å…¥ã€‚UI-Venusåœ¨ç”¨æˆ·ç•Œé¢å®šä½å’Œå¯¼èˆªä»»åŠ¡ä¸Šå®ç°äº†å½“å‰çš„æœ€ä½³æ€§èƒ½ï¼Œä½¿ç”¨äº†ä»…æ•°åä¸‡ä¸ªé«˜è´¨é‡çš„è®­ç»ƒæ ·æœ¬ï¼Œå¹¶é€šè¿‡åŸºäºQwen2.5-VLçš„å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰è¿›è¡Œä¼˜åŒ–ã€‚å…·ä½“è€Œè¨€ï¼ŒUI-Venusçš„7Bå’Œ72Bç‰ˆæœ¬åœ¨æ ‡å‡†å®šä½åŸºå‡†æµ‹è¯•Screenspot-V2å’ŒProä¸Šåˆ†åˆ«è·å¾—äº†94.1%å’Œ50.8%ã€95.3%å’Œ61.9%çš„æˆç»©ï¼Œè¶…è¶Šäº†åŒ…æ‹¬å¼€æºçš„GTA1å’Œé—­æºçš„UI-TARS-1.5åœ¨å†…çš„å…ˆå‰æœ€ä½³åŸºçº¿ã€‚\n\nä¸ºäº†å±•ç¤ºUI-Venusçš„æ€»ç»“å’Œè§„åˆ’èƒ½åŠ›ï¼Œæˆ‘ä»¬è¿˜åœ¨AndroidWorldè¿™ä¸€åœ¨çº¿ç”¨æˆ·ç•Œé¢å¯¼èˆªå¹³å°ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤º7Bå’Œ72Bç‰ˆæœ¬çš„æˆåŠŸç‡åˆ†åˆ«ä¸º49.1%å’Œ65.9%ï¼ŒåŒæ ·ä¼˜äºç°æœ‰æ¨¡å‹ã€‚ä¸ºå®ç°è¿™ä¸€æˆæœï¼Œæˆ‘ä»¬å¼•å…¥äº†ç²¾å¿ƒè®¾è®¡çš„å¥–åŠ±å‡½æ•°ï¼Œé’ˆå¯¹ç”¨æˆ·ç•Œé¢å®šä½å’Œå¯¼èˆªä»»åŠ¡ï¼Œå¹¶åˆ¶å®šäº†ç›¸åº”çš„é«˜æ•ˆæ•°æ®æ¸…ç†ç­–ç•¥ã€‚ä¸ºäº†è¿›ä¸€æ­¥æå‡å¯¼èˆªæ€§èƒ½ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªæˆ‘æ¼”å˜è½¨è¿¹å†å²å¯¹é½ä¸ç¨€ç–åŠ¨ä½œå¢å¼ºçš„æ–¹æ³•ï¼Œè¿™ä¸€æ–¹æ³•èƒ½å¤Ÿä¼˜åŒ–å†å²æ¨ç†è½¨è¿¹ï¼Œå¹¶å¹³è¡¡ç¨€ç–ä½†å…³é”®åŠ¨ä½œçš„åˆ†å¸ƒï¼Œä»è€Œå®ç°æ›´è¿è´¯çš„è§„åˆ’å’Œåœ¨å¤æ‚ç”¨æˆ·ç•Œé¢ä»»åŠ¡ä¸­çš„æ›´å¥½æ³›åŒ–èƒ½åŠ›ã€‚\n\næˆ‘ä»¬çš„è´¡çŒ®åŒ…æ‹¬å‘å¸ƒå½“å‰æœ€ä½³çš„å¼€æºç”¨æˆ·ç•Œé¢ä»£ç†ã€å…¨é¢çš„æ•°æ®æ¸…ç†åè®®ä»¥åŠä¸€ç§æ–°é¢–çš„è‡ªæˆ‘æ¼”å˜æ¡†æ¶ï¼Œä»¥æå‡å¯¼èˆªæ€§èƒ½ï¼Œè¿™äº›éƒ½ä¸ºç¤¾åŒºçš„è¿›ä¸€æ­¥ç ”ç©¶å’Œå¼€å‘æä¾›äº†æ”¯æŒã€‚ç›¸å…³ä»£ç å¯åœ¨https://github.com/inclusionAI/UI-Venusè·å–ã€‚",
        "Puppeteer: Rig and Animate Your 3D Models\n\nç°ä»£äº’åŠ¨åº”ç”¨å¯¹åŠ¨æ€3Då†…å®¹çš„éœ€æ±‚æ—¥ç›Šå¢åŠ ï¼Œä½†å°†é™æ€3Dæ¨¡å‹è½¬åŒ–ä¸ºåŠ¨ç”»èµ„äº§çš„è¿‡ç¨‹åœ¨å†…å®¹åˆ›ä½œä¸­ä»ç„¶æ˜¯ä¸€ä¸ªé‡è¦ç“¶é¢ˆã€‚å°½ç®¡æœ€è¿‘ç”Ÿæˆæ€§äººå·¥æ™ºèƒ½åœ¨é™æ€3Dæ¨¡å‹åˆ›å»ºæ–¹é¢å–å¾—äº†çªç ´ï¼Œä½†ç»‘å®šå’ŒåŠ¨ç”»åˆ¶ä½œä»ç„¶é«˜åº¦ä¾èµ–ä¸“å®¶çš„å¹²é¢„ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†Puppeteerï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°å¤šæ ·åŒ–3Då¯¹è±¡çš„è‡ªåŠ¨ç»‘å®šå’ŒåŠ¨ç”»ã€‚\n\nè¯¥ç³»ç»Ÿé¦–å…ˆé€šè¿‡è‡ªå›å½’å˜æ¢å™¨é¢„æµ‹åˆç†çš„éª¨éª¼ç»“æ„ï¼Œé‡‡ç”¨åŸºäºå…³èŠ‚çš„æ ‡è®°ç­–ç•¥ä»¥å®ç°ç´§å‡‘è¡¨ç¤ºï¼Œå¹¶ç»“åˆå±‚æ¬¡åŒ–æ’åºæ–¹æ³•å’Œéšæœºæ‰°åŠ¨ï¼Œå¢å¼ºåŒå‘å­¦ä¹ èƒ½åŠ›ã€‚æ¥ç€ï¼Œå®ƒåˆ©ç”¨åŸºäºæ³¨æ„åŠ›çš„æ¶æ„æ¨æ–­çš®è‚¤æƒé‡ï¼Œè¯¥æ¶æ„ç»“åˆäº†æ‹“æ‰‘æ„ŸçŸ¥çš„å…³èŠ‚æ³¨æ„åŠ›ï¼Œæ˜ç¡®ç¼–ç äº†åŸºäºéª¨éª¼å›¾è·ç¦»çš„å…³èŠ‚é—´å…³ç³»ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡å¯å¾®ä¼˜åŒ–çš„åŠ¨ç”»ç®¡é“è¡¥å……äº†è¿™äº›ç»‘å®šè¿›å±•ï¼Œç”Ÿæˆç¨³å®šä¸”é«˜ä¿çœŸçš„åŠ¨ç”»ï¼ŒåŒæ—¶åœ¨è®¡ç®—æ•ˆç‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚\n\nåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨éª¨éª¼é¢„æµ‹å‡†ç¡®æ€§å’Œçš®è‚¤è´¨é‡æ–¹é¢æ˜¾è‘—ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æŠ€æœ¯ã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿç¨³å¥åœ°å¤„ç†å¤šæ ·åŒ–çš„3Då†…å®¹ï¼Œä»ä¸“ä¸šè®¾è®¡çš„æ¸¸æˆèµ„äº§åˆ°AIç”Ÿæˆçš„å½¢çŠ¶ï¼Œç”Ÿæˆçš„åŠ¨ç”»æ—¶é—´ä¸Šè¿è´¯ï¼Œæ¶ˆé™¤äº†ç°æœ‰æ–¹æ³•ä¸­å¸¸è§çš„æŠ–åŠ¨é—®é¢˜ã€‚",
        "STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer\n\næˆ‘ä»¬æå‡ºäº†STream3Rï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„3Dé‡å»ºæ–¹æ³•ï¼Œå°†ç‚¹å›¾é¢„æµ‹é‡æ–°å®šä¹‰ä¸ºä»…ä½¿ç”¨è§£ç å™¨çš„Transformeré—®é¢˜ã€‚ç°æœ‰çš„å¤šè§†è§’é‡å»ºæœ€å…ˆè¿›æ–¹æ³•é€šå¸¸ä¾èµ–äºæ˜‚è´µçš„å…¨å±€ä¼˜åŒ–ï¼Œæˆ–æ˜¯ä¾èµ–äºç®€å•çš„è®°å¿†æœºåˆ¶ï¼Œè¿™äº›æœºåˆ¶åœ¨åºåˆ—é•¿åº¦å¢åŠ æ—¶è¡¨ç°ä¸ä½³ã€‚ä¸æ­¤ä¸åŒï¼ŒSTream3Rå¼•å…¥äº†ä¸€ç§æµå¼æ¡†æ¶ï¼Œåˆ©ç”¨å› æœæ³¨æ„åŠ›é«˜æ•ˆå¤„ç†å›¾åƒåºåˆ—ï¼Œè¿™ä¸€æ€è·¯å—åˆ°ç°ä»£è¯­è¨€å»ºæ¨¡è¿›å±•çš„å¯å‘ã€‚é€šè¿‡ä»å¤§è§„æ¨¡3Dæ•°æ®é›†ä¸­å­¦ä¹ å‡ ä½•å…ˆéªŒï¼ŒSTream3Råœ¨å¤šæ ·åŒ–å’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨åŠ¨æ€åœºæ™¯ä¸­ï¼Œä¼ ç»Ÿæ–¹æ³•å¾€å¾€éš¾ä»¥åº”å¯¹ã€‚\n\nå¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é™æ€å’ŒåŠ¨æ€åœºæ™¯åŸºå‡†æµ‹è¯•ä¸­å‡æŒç»­è¶…è¶Šä»¥å¾€çš„ç ”ç©¶æˆæœã€‚æ­¤å¤–ï¼ŒSTream3Rä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é£æ ¼çš„è®­ç»ƒåŸºç¡€è®¾æ–½å¤©ç„¶å…¼å®¹ï¼Œä½¿å¾—åœ¨å„ç§ä¸‹æ¸¸3Dä»»åŠ¡ä¸­å®ç°é«˜æ•ˆçš„å¤§è§„æ¨¡é¢„è®­ç»ƒå’Œå¾®è°ƒæˆä¸ºå¯èƒ½ã€‚æˆ‘ä»¬çš„ç»“æœå¼ºè°ƒäº†å› æœTransformeræ¨¡å‹åœ¨åœ¨çº¿3Dæ„ŸçŸ¥ä¸­çš„æ½œåŠ›ï¼Œä¸ºæµåª’ä½“ç¯å¢ƒä¸­çš„å®æ—¶3Dç†è§£é“ºå¹³äº†é“è·¯ã€‚æ›´å¤šç»†èŠ‚å¯ä»¥åœ¨æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢æ‰¾åˆ°ã€‚",
        "A Survey on Diffusion Language Models\n\næ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆDLMsï¼‰æ­£åœ¨è¿…é€Ÿå´›èµ·ï¼Œæˆä¸ºä¸€ç§å¼ºå¤§ä¸”æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå–ä»£äº†ä¸»æµçš„è‡ªå›å½’ï¼ˆARï¼‰æ¨¡å‹ã€‚DLMsé€šè¿‡è¿­ä»£å»å™ªè¿‡ç¨‹å¹¶è¡Œç”Ÿæˆæ ‡è®°ï¼Œå…·æœ‰å‡å°‘æ¨ç†å»¶è¿Ÿå’Œæ•æ‰åŒå‘ä¸Šä¸‹æ–‡çš„å›ºæœ‰ä¼˜åŠ¿ï¼Œä»è€Œå®ç°å¯¹ç”Ÿæˆè¿‡ç¨‹çš„ç»†ç²’åº¦æ§åˆ¶ã€‚è¿‘æœŸçš„è¿›å±•ä½¿å¾—DLMsåœ¨é€Ÿåº¦ä¸Šå®ç°äº†æ•°å€çš„æå‡ï¼ŒåŒæ—¶åœ¨æ€§èƒ½ä¸Šä¸è‡ªå›å½’æ¨¡å‹ç›¸å½“ï¼Œä½¿å…¶æˆä¸ºå„ç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„æœ‰åŠ›é€‰æ‹©ã€‚\n\næœ¬è°ƒæŸ¥æä¾›äº†å½“å‰DLMé¢†åŸŸçš„å…¨é¢æ¦‚è¿°ï¼Œè¿½æº¯å…¶å‘å±•å†ç¨‹åŠä¸å…¶ä»–æ¨¡å‹ï¼ˆå¦‚è‡ªå›å½’å’Œæ©è”½è¯­è¨€æ¨¡å‹ï¼‰çš„å…³ç³»ï¼Œæ¶µç›–äº†åŸºç¡€åŸç†å’Œæœ€å…ˆè¿›çš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„ç ”ç©¶æä¾›äº†æœ€æ–°çš„åˆ†ç±»æ³•ï¼Œå¹¶æ·±å…¥åˆ†æäº†å½“å‰æŠ€æœ¯ï¼Œä»é¢„è®­ç»ƒç­–ç•¥åˆ°å…ˆè¿›çš„åè®­ç»ƒæ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¯¹DLMæ¨ç†ç­–ç•¥å’Œä¼˜åŒ–è¿›è¡Œäº†è¯¦å°½çš„å›é¡¾ï¼ŒåŒ…æ‹¬è§£ç å¹¶è¡Œæ€§ã€ç¼“å­˜æœºåˆ¶å’Œç”Ÿæˆè´¨é‡çš„æ”¹è¿›ã€‚\n\næˆ‘ä»¬è¿˜å¼ºè°ƒäº†DLMåœ¨å¤šæ¨¡æ€æ‰©å±•æ–¹é¢çš„æœ€æ–°æ–¹æ³•ï¼Œå¹¶é˜æ˜äº†å…¶åœ¨å„ç§å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚åŒæ—¶ï¼Œè®¨è®ºä¸­ä¹ŸæåŠäº†DLMsçš„å±€é™æ€§å’ŒæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ•ˆç‡ã€é•¿åºåˆ—å¤„ç†å’ŒåŸºç¡€è®¾æ–½éœ€æ±‚ï¼Œå¹¶æ¦‚è¿°äº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ï¼Œä»¥æ¨åŠ¨è¿™ä¸€å¿«é€Ÿå‘å±•çš„é¢†åŸŸçš„è¿›æ­¥ã€‚",
        "Pass@k Training for Adaptively Balancing Exploration and Exploitation of   Large Reasoning Models\n\nå¼ºåŒ–å­¦ä¹ ä¸­çš„å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰é€šå¸¸é‡‡ç”¨Pass@1ä½œä¸ºå¥–åŠ±ï¼Œä½†åœ¨æ¢ç´¢ä¸åˆ©ç”¨ä¹‹é—´çš„å¹³è¡¡ä¸Šå­˜åœ¨é—®é¢˜ï¼Œå¯¼è‡´ç­–ç•¥å€¾å‘äºä¿å®ˆè¡Œä¸ºï¼Œä»è€Œæ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜è§£ã€‚å› æ­¤ï¼Œç¡®å®šåˆé€‚çš„å¥–åŠ±æŒ‡æ ‡æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚å°½ç®¡ä»¥å¾€çš„ç ”ç©¶ä¸­ä½¿ç”¨äº†Pass@kè¿›è¡Œè¯„ä¼°ï¼Œä½†å…¶ä¸RLVRä¸­å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¢ç´¢èƒ½åŠ›çš„å…³ç³»å´æœªå¾—åˆ°å……åˆ†å…³æ³¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨Pass@kä½œä¸ºå¥–åŠ±æ¥è®­ç»ƒç­–ç•¥æ¨¡å‹ï¼ˆå³â€œPass@kè®­ç»ƒâ€ï¼‰ï¼Œå¹¶è§‚å¯Ÿå…¶åœ¨æ¢ç´¢èƒ½åŠ›ä¸Šçš„æå‡ã€‚\n\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºPass@kè®­ç»ƒçš„ä¼˜åŠ¿çš„è§£æè§£ï¼Œä»è€Œå½¢æˆä¸€ä¸ªé«˜æ•ˆä¸”æœ‰æ•ˆçš„è¿‡ç¨‹ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œæ¢ç´¢ä¸åˆ©ç”¨å¹¶éå›ºæœ‰çš„å¯¹ç«‹ç›®æ ‡ï¼Œåè€Œå¯ä»¥ç›¸äº’ä¿ƒè¿›ã€‚æ­¤å¤–ï¼ŒåŸºäºè§£ææ¨å¯¼çš„Pass@kè®­ç»ƒæœ¬è´¨ä¸Šæ¶‰åŠç›´æ¥è®¾è®¡ä¼˜åŠ¿å‡½æ•°ã€‚å—åˆ°è¿™ä¸€å‘ç°çš„å¯å‘ï¼Œæˆ‘ä»¬åˆæ­¥æ¢ç´¢äº†RLVRä¸­çš„ä¼˜åŠ¿è®¾è®¡ï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„ç»“æœï¼Œå¹¶å¼ºè°ƒäº†æœªæ¥ç ”ç©¶çš„æ½œåœ¨æ–¹å‘ã€‚è¿™äº›ç ”ç©¶ä¸ä»…ä¸ºRLVRæä¾›äº†æ–°çš„è§†è§’ï¼Œä¹Ÿä¸ºä¼˜åŒ–ç­–ç•¥çš„è®¾è®¡æä¾›äº†ç†è®ºåŸºç¡€ï¼Œæ¨åŠ¨äº†å¼ºåŒ–å­¦ä¹ é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚",
        "HumanSense: From Multimodal Perception to Empathetic Context-Aware   Responses through Reasoning MLLMs\n\nå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å®ç°äººç±»èˆ¬çš„äº’åŠ¨æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†ç”±äºç¼ºä¹é’ˆå¯¹äººæœ¬åœºæ™¯çš„ç»†è‡´è¯„ä¼°æ¡†æ¶ï¼Œè¿›å±•å—åˆ°é™åˆ¶ã€‚è¿™äº›æ¡†æ¶éœ€è¦æ¶µç›–å¯¹å¤æ‚äººç±»æ„å›¾çš„ç†è§£ä»¥åŠæä¾›å¯Œæœ‰åŒæƒ…å¿ƒå’Œä¸Šä¸‹æ–‡æ„è¯†çš„å›åº”ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†HumanSenseï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°MLLMsçš„äººæœ¬æ„ŸçŸ¥å’Œäº’åŠ¨èƒ½åŠ›ï¼Œç‰¹åˆ«å…³æ³¨å¯¹æ‰©å±•å¤šæ¨¡æ€ä¸Šä¸‹æ–‡çš„æ·±åˆ»ç†è§£å’Œåˆç†åé¦ˆçš„å½¢æˆã€‚\n\næˆ‘ä»¬çš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œé¢†å…ˆçš„MLLMsåœ¨é«˜çº§äº’åŠ¨ä»»åŠ¡ä¸Šä»æœ‰ç›¸å½“å¤§çš„æ”¹è¿›ç©ºé—´ã€‚é€šè¿‡å°†è§†è§‰è¾“å…¥ä¸éŸ³é¢‘å’Œæ–‡æœ¬ä¿¡æ¯ç›¸ç»“åˆï¼Œå¯ä»¥æ˜¾è‘—æå‡æ¨¡å‹çš„è¡¨ç°ï¼Œè€Œå…¨æ¨¡æ€æ¨¡å‹åœ¨è¿™äº›ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¤ä¸ºï¼Œé€‚å½“çš„åé¦ˆæºäºå¯¹å¯¹è¯è€…éœ€æ±‚å’Œæƒ…æ„Ÿçš„ä¸Šä¸‹æ–‡åˆ†æï¼Œè€Œæ¨ç†èƒ½åŠ›åˆ™æ˜¯è§£é”è¿™ä¸€åé¦ˆçš„å…³é”®ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é‡‡ç”¨å¤šé˜¶æ®µã€æ¨¡æ€æ¸è¿›çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ¥å¢å¼ºå…¨æ¨¡æ€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä»è€Œåœ¨è¯„ä¼°ç»“æœä¸Šå–å¾—æ˜¾è‘—æå‡ã€‚\n\næˆ‘ä»¬è¿˜è§‚å¯Ÿåˆ°ï¼ŒæˆåŠŸçš„æ¨ç†è¿‡ç¨‹å±•ç°å‡ºé«˜åº¦ä¸€è‡´çš„æ€ç»´æ¨¡å¼ã€‚é€šè¿‡è®¾è®¡ç›¸åº”çš„æç¤ºï¼Œæˆ‘ä»¬ä¹Ÿåœ¨æ— è®­ç»ƒçš„æƒ…å†µä¸‹æå‡äº†éæ¨ç†æ¨¡å‹çš„è¡¨ç°ã€‚è¿™äº›ç ”ç©¶æˆæœä¸ºè¿›ä¸€æ­¥æ¨åŠ¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„åº”ç”¨å’Œå‘å±•æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€å’Œå®è·µæŒ‡å¯¼ã€‚",
        "Processing and acquisition traces in visual encoders: What does CLIP   know about your camera?\n\nä»¥å¾€çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨è§†è§‰ç¼–ç å™¨å¯¹å›¾åƒå˜æ¢å’ŒæŸåçš„é²æ£’æ€§ï¼Œå°¤å…¶æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æœªè§è¿‡çš„æƒ…å†µä¸‹ã€‚è¿™ç§æƒ…å†µä¼šåœ¨æµ‹è¯•æ—¶å¼•å…¥åˆ†å¸ƒåç§»ï¼Œé€šå¸¸å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚ç ”ç©¶çš„é‡ç‚¹å¤šé›†ä¸­åœ¨ä¸¥é‡çš„æŸåä¸Šï¼Œè¿™äº›æŸååœ¨å¼ºçƒˆåº”ç”¨æ—¶ä¼šæ‰­æ›²è¿›è¡Œå‡†ç¡®è¯­ä¹‰é¢„æµ‹æ‰€éœ€çš„æœ‰ç”¨ä¿¡å·ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬é‡‡å–äº†ä¸åŒçš„è§†è§’ï¼Œåˆ†æäº†å›¾åƒè·å–è¿‡ç¨‹å’Œå˜æ¢çš„å‚æ•°ï¼Œè¿™äº›å‚æ•°å¯èƒ½æ˜¯å¾®å¦™çš„ï¼Œç”šè‡³å¯¹äººçœ¼ä¸å¯å¯Ÿè§‰ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œè¿™äº›å‚æ•°åœ¨å­¦ä¹ çš„è§†è§‰è¡¨å¾ä¸­è¢«ç³»ç»Ÿæ€§åœ°ç¼–ç ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾æ¢å¤ã€‚\n\næ›´å¼•äººæ³¨ç›®çš„æ˜¯ï¼Œè¿™äº›å‚æ•°çš„å­˜åœ¨å¯¹è¯­ä¹‰é¢„æµ‹æœ‰ç€æ·±è¿œçš„å½±å“ï¼Œå¯èƒ½æ˜¯ç§¯æçš„ä¹Ÿå¯èƒ½æ˜¯æ¶ˆæçš„ã€‚è¿™ç§å½±å“å–å†³äºè¯­ä¹‰æ ‡ç­¾ä¸è¿™äº›åŸºäºè·å–æˆ–å¤„ç†çš„æ ‡ç­¾ä¹‹é—´æ˜¯å¦å­˜åœ¨å¼ºç›¸å…³æ€§æˆ–åç›¸å…³æ€§ã€‚é€šè¿‡è¿™ç§åˆ†æï¼Œæˆ‘ä»¬æ­ç¤ºäº†å›¾åƒè·å–è¿‡ç¨‹ä¸­çš„ç»†å¾®å˜åŒ–å¦‚ä½•å½±å“è§†è§‰ç¼–ç å™¨çš„æ€§èƒ½ï¼Œå¼ºè°ƒäº†åœ¨å®é™…åº”ç”¨ä¸­è€ƒè™‘è¿™äº›å› ç´ çš„é‡è¦æ€§ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®å·²å…¬å¼€ï¼Œä¾›ç ”ç©¶è€…è¿›ä¸€æ­¥æ¢ç´¢è¿™ä¸€é¢†åŸŸã€‚",
        "From Black Box to Transparency: Enhancing Automated Interpreting   Assessment with Explainable AI in College Classrooms\n\nè¿‘å¹´æ¥ï¼Œæœºå™¨å­¦ä¹ çš„è¿›æ­¥å¼•å‘äº†å¯¹è‡ªåŠ¨åŒ–å£è¯‘è´¨é‡è¯„ä¼°çš„å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶åœ¨è¯­è¨€ä½¿ç”¨è´¨é‡çš„æ£€éªŒä¸Šå­˜åœ¨ä¸è¶³ï¼Œæ¨¡å‹æ•ˆæœå› æ•°æ®ç¨€ç¼ºå’Œä¸å¹³è¡¡è€Œä¸å°½å¦‚äººæ„ï¼ŒåŒæ—¶å¯¹æ¨¡å‹é¢„æµ‹çš„è§£é‡Šæ€§ä¹Ÿç¼ºä¹è¶³å¤Ÿçš„å…³æ³¨ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šç»´å»ºæ¨¡æ¡†æ¶ï¼Œç»“åˆäº†ç‰¹å¾å·¥ç¨‹ã€æ•°æ®å¢å¼ºå’Œå¯è§£é‡Šçš„æœºå™¨å­¦ä¹ ã€‚è¯¥æ–¹æ³•ä¼˜å…ˆè€ƒè™‘å¯è§£é‡Šæ€§ï¼Œé¿å…â€œé»‘ç®±â€é¢„æµ‹ï¼Œé‡‡ç”¨ä¸æ„å»ºç›¸å…³çš„é€æ˜ç‰¹å¾ï¼Œå¹¶è¿›è¡ŒShapleyå€¼ï¼ˆSHAPï¼‰åˆ†æã€‚\n\næˆ‘ä»¬çš„ç ”ç©¶ç»“æœåœ¨ä¸€ä¸ªæ–°çš„è‹±æ±‰è¿ç»­å£è¯‘æ•°æ®é›†ä¸Šæ˜¾ç¤ºå‡ºå¼ºå¤§çš„é¢„æµ‹æ€§èƒ½ï¼Œå‘ç°BLEURTå’ŒCometKiwiè¯„åˆ†æ˜¯è¯„ä¼°å¿ å®åº¦çš„æœ€å¼ºé¢„æµ‹ç‰¹å¾ï¼Œè€Œä¸åœé¡¿ç›¸å…³çš„ç‰¹å¾åˆ™ä¸æµç•…åº¦å¯†åˆ‡ç›¸å…³ï¼Œä¸­æ–‡ç‰¹æœ‰çš„çŸ­è¯­å¤šæ ·æ€§æŒ‡æ ‡åˆ™ç”¨äºè¯­è¨€ä½¿ç”¨çš„è¯„ä¼°ã€‚æ€»ä½“è€Œè¨€ï¼Œé€šè¿‡å¼ºè°ƒå¯è§£é‡Šæ€§ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ç§å¯æ‰©å±•ã€å¯é ä¸”é€æ˜çš„æ›¿ä»£ä¼ ç»Ÿäººå·¥è¯„ä¼°çš„æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•ä¸ä»…èƒ½å¤Ÿä¸ºå­¦ä¹ è€…æä¾›è¯¦ç»†çš„è¯Šæ–­åé¦ˆï¼Œè¿˜æ”¯æŒè‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ çš„ä¼˜åŠ¿ï¼Œè€Œè¿™äº›æ˜¯å•çº¯ä¾èµ–è‡ªåŠ¨è¯„åˆ†æ‰€æ— æ³•å®ç°çš„ã€‚",
        "When Explainability Meets Privacy: An Investigation at the Intersection   of Post-hoc Explainability and Differential Privacy in the Context of Natural   Language Processing\n\nåœ¨å¯ä¿¡è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çš„ç ”ç©¶ä¸­ï¼Œè§£é‡Šæ€§å’Œéšç§ä¿æŠ¤æˆä¸ºäº†ä¸¤ä¸ªé‡è¦çš„ç ”ç©¶é¢†åŸŸã€‚å°½ç®¡è¿‘å¹´æ¥å¯¹å¯è§£é‡Šæ€§å’Œéšç§ä¿æŠ¤çš„NLPç ”ç©¶å…´è¶£æ˜¾è‘—å¢åŠ ï¼Œä½†ä¸¤è€…äº¤å‰é¢†åŸŸçš„ç ”ç©¶ä»ç„¶ä¸è¶³ã€‚è¿™ä½¿å¾—æˆ‘ä»¬å¯¹å®ç°å¯è§£é‡Šæ€§ä¸éšç§ä¿æŠ¤æ˜¯å¦å¯èƒ½å­˜åœ¨è¾ƒå¤§ç©ºç™½ï¼Œæˆ–è€…ä¸¤è€…æ˜¯å¦å­˜åœ¨çŸ›ç›¾çš„ç†è§£ä¸å¤Ÿæ·±å…¥ã€‚æœ¬ç ”ç©¶é€šè¿‡å®è¯è°ƒæŸ¥ï¼Œæ¢è®¨äº†NLPä¸­çš„éšç§ä¸å¯è§£é‡Šæ€§ä¹‹é—´çš„æƒè¡¡ï¼Œä¸»è¦ä¾æ‰˜äºå·®åˆ†éšç§ï¼ˆDPï¼‰å’Œäº‹åè§£é‡Šæ€§ç­‰æµè¡Œæ–¹æ³•ã€‚\n\næˆ‘ä»¬çš„ç ”ç©¶ç»“æœæ­ç¤ºäº†éšç§ä¸å¯è§£é‡Šæ€§ä¹‹é—´å¤æ‚çš„å…³ç³»ï¼Œè¿™ç§å…³ç³»å—åˆ°å¤šä¸ªå› ç´ çš„å½±å“ï¼ŒåŒ…æ‹¬ä¸‹æ¸¸ä»»åŠ¡çš„æ€§è´¨ä»¥åŠæ–‡æœ¬éšç§åŒ–å’Œè§£é‡Šæ€§æ–¹æ³•çš„é€‰æ‹©ã€‚åœ¨è¿™ä¸€è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¼ºè°ƒäº†éšç§ä¸å¯è§£é‡Šæ€§å…±å­˜çš„æ½œåŠ›ï¼Œå¹¶æ€»ç»“å‡ºä¸€ç³»åˆ—å®ç”¨å»ºè®®ï¼Œä»¥æŒ‡å¯¼æœªæ¥åœ¨è¿™ä¸€é‡è¦äº¤å‰é¢†åŸŸçš„ç ”ç©¶å·¥ä½œã€‚è¿™äº›å»ºè®®æ—¨åœ¨å¸®åŠ©ç ”ç©¶è€…æ›´å¥½åœ°ç†è§£å’Œåº”å¯¹éšç§ä¸å¯è§£é‡Šæ€§ä¹‹é—´çš„æŒ‘æˆ˜ï¼Œä»è€Œæ¨åŠ¨NLPæŠ€æœ¯çš„å¯ä¿¡æ€§å’Œå®ç”¨æ€§å‘å±•ã€‚",
        "https://github.com/coleam00/Archon\n\nArchon OSç›®å‰å¤„äºæµ‹è¯•é˜¶æ®µï¼Œæ—¨åœ¨ä¸ºAIç¼–ç åŠ©æ‰‹æä¾›çŸ¥è¯†å’Œä»»åŠ¡ç®¡ç†çš„æ ¸å¿ƒæ”¯æŒã€‚ä½œä¸ºä¸€ä¸ªå‘½ä»¤ä¸­å¿ƒï¼ŒArchonä¸ºç”¨æˆ·æä¾›äº†ä¸€ä¸ªç®€æ´çš„ç•Œé¢ï¼Œä»¥ç®¡ç†é¡¹ç›®çš„çŸ¥è¯†ã€ä¸Šä¸‹æ–‡å’Œä»»åŠ¡ï¼ŒåŒæ—¶ä¸ºAIåŠ©æ‰‹æä¾›äº†ä¸€ä¸ªæ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰æœåŠ¡å™¨ï¼Œä½¿å…¶èƒ½å¤Ÿå…±äº«ç›¸åŒçš„çŸ¥è¯†å’Œä»»åŠ¡ã€‚ç”¨æˆ·å¯ä»¥å°†å¤šä¸ªAIå·¥å…·è¿æ¥åˆ°Archonï¼Œåˆ©ç”¨å…¶æ™ºèƒ½æœç´¢ã€ä»»åŠ¡ç®¡ç†å’Œå®æ—¶æ›´æ–°ç­‰åŠŸèƒ½ï¼Œä»è€Œæå‡AIé©±åŠ¨ç¼–ç çš„æ•ˆç‡ã€‚\n\nArchonçš„è®¾è®¡ç†å¿µæ˜¯æ›¿ä»£ä¹‹å‰çš„agenteerï¼Œæˆä¸ºä¸€ä¸ªæ›´å¼ºå¤§çš„å·¥å…·ã€‚æ— è®ºæ˜¯æ–°é¡¹ç›®è¿˜æ˜¯ç°æœ‰ä»£ç åº“ï¼ŒArchonçš„çŸ¥è¯†å’Œä»»åŠ¡ç®¡ç†èƒ½åŠ›éƒ½èƒ½æ˜¾è‘—æ”¹å–„è¾“å‡ºæ•ˆæœã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡GitHubè®¨è®ºåŒºå‚ä¸äº¤æµï¼Œè´¡çŒ®ä»£ç æˆ–åé¦ˆé—®é¢˜ï¼Œå¸®åŠ©å›¢é˜Ÿä¸æ–­æ”¹è¿›Archonã€‚\n\nåœ¨å¿«é€Ÿå¯åŠ¨æ–¹é¢ï¼Œç”¨æˆ·éœ€è¦å®‰è£…Dockerå’ŒSupabaseï¼Œå¹¶è·å–OpenAI APIå¯†é’¥ã€‚è®¾ç½®è¿‡ç¨‹åŒ…æ‹¬å…‹éš†ä»£ç åº“ã€é…ç½®ç¯å¢ƒå˜é‡ã€è®¾ç½®æ•°æ®åº“ä»¥åŠå¯åŠ¨æœåŠ¡ã€‚Archonçš„æ¶æ„é‡‡ç”¨å¾®æœåŠ¡ç»“æ„ï¼Œç¡®ä¿å„ä¸ªæœåŠ¡ä¹‹é—´çš„ç‹¬ç«‹æ€§å’Œçµæ´»æ€§ï¼Œæ”¯æŒå®æ—¶åä½œå’Œå¤šç”¨æˆ·æ“ä½œã€‚\n\nArchonçš„æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬æ™ºèƒ½ç½‘é¡µçˆ¬è™«ã€æ–‡æ¡£å¤„ç†ã€ä»£ç ç¤ºä¾‹æå–å’Œå‘é‡æœç´¢ç­‰çŸ¥è¯†ç®¡ç†å·¥å…·ï¼Œä»¥åŠä¸AIåŠ©æ‰‹çš„æ— ç¼é›†æˆã€‚é¡¹ç›®å’Œä»»åŠ¡ç®¡ç†åŠŸèƒ½å…è®¸ç”¨æˆ·ä»¥å±‚æ¬¡åŒ–çš„æ–¹å¼ç»„ç»‡å·¥ä½œï¼Œå¹¶é€šè¿‡AIåŠ©æ‰‹ç”Ÿæˆé¡¹ç›®éœ€æ±‚å’Œä»»åŠ¡ã€‚æ­¤å¤–ï¼ŒArchonè¿˜æ”¯æŒå®æ—¶æ›´æ–°å’Œå¥åº·ç›‘æµ‹ï¼Œç¡®ä¿ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œé«˜æ•ˆæ€§ã€‚\n\næ€»ä¹‹ï¼ŒArchon OSä¸ºAIç¼–ç åŠ©æ‰‹æä¾›äº†ä¸€ä¸ªå¼ºå¤§çš„çŸ¥è¯†å’Œä»»åŠ¡ç®¡ç†å¹³å°ï¼Œæ—¨åœ¨é€šè¿‡é›†æˆå¤šç§åŠŸèƒ½å’ŒæœåŠ¡ï¼Œæå‡å¼€å‘è€…çš„å·¥ä½œæ•ˆç‡å’Œåä½œä½“éªŒã€‚",
        "https://github.com/emcie-co/parlant\n\nParlantæ˜¯ä¸€ç§æ–°å‹çš„AIä»£ç†å¼€å‘æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¼€å‘è€…åœ¨æ„å»ºç”Ÿäº§çº§AIä»£ç†æ—¶å¸¸é‡åˆ°çš„é—®é¢˜ï¼Œå¦‚ç³»ç»Ÿæç¤ºè¢«å¿½è§†ã€å…³é”®æ—¶åˆ»çš„é”™è¯¯å“åº”ä»¥åŠæ— æ³•ä¸€è‡´å¤„ç†è¾¹ç¼˜æ¡ˆä¾‹ç­‰ã€‚ä¼ ç»Ÿçš„AIå¼€å‘æ–¹æ³•å¾€å¾€ä¾èµ–å¤æ‚çš„ç³»ç»Ÿæç¤ºå’Œä¸ç¡®å®šçš„è¡Œä¸ºï¼Œè€ŒParlantåˆ™é€šè¿‡è‡ªç„¶è¯­è¨€å®šä¹‰è§„åˆ™ï¼Œç¡®ä¿ä»£ç†éµå¾ªè¿™äº›è§„åˆ™ï¼Œä»è€Œå®ç°å¯é¢„æµ‹å’Œä¸€è‡´çš„è¡Œä¸ºã€‚\n\nä½¿ç”¨Parlantï¼Œå¼€å‘è€…å¯ä»¥åœ¨çŸ­çŸ­60ç§’å†…å¯åŠ¨ä»£ç†ã€‚é€šè¿‡ç®€å•çš„ä»£ç ï¼Œç”¨æˆ·å¯ä»¥å®šä¹‰ä»£ç†çš„è¡Œä¸ºå’Œå“åº”ï¼Œç¡®ä¿å…¶åœ¨å®é™…åº”ç”¨ä¸­èƒ½å¤Ÿæœ‰æ•ˆåœ°æ»¡è¶³ç”¨æˆ·éœ€æ±‚ã€‚Parlantçš„è®¾è®¡ç†å¿µæ˜¯å°†è§„åˆ™çš„å®šä¹‰ä¸è‡ªç„¶è¯­è¨€ç»“åˆï¼Œä½¿å¾—å¼€å‘è¿‡ç¨‹æ›´åŠ ç›´è§‚å’Œé«˜æ•ˆã€‚\n\nè¯¥æ¡†æ¶ç‰¹åˆ«é€‚ç”¨äºé‡‘èæœåŠ¡ã€åŒ»ç–—ä¿å¥ã€ç”µå­å•†åŠ¡å’Œæ³•å¾‹ç§‘æŠ€ç­‰é¢†åŸŸï¼Œå…·å¤‡åˆè§„æ€§è®¾è®¡ã€é£é™©ç®¡ç†ã€å®¢æˆ·æœåŠ¡è‡ªåŠ¨åŒ–ç­‰åŠŸèƒ½ã€‚Parlantè¿˜æä¾›äº†ä¸€ç³»åˆ—ä¼ä¸šçº§ç‰¹æ€§ï¼Œå¦‚å¯¹è¯æ—…ç¨‹å¼•å¯¼ã€åŠ¨æ€è§„åˆ™åŒ¹é…ã€å¯é çš„å·¥å…·é›†æˆå’Œæ·±å…¥çš„å¯¹è¯åˆ†æï¼Œå¸®åŠ©å¼€å‘è€…ä¸æ–­ä¼˜åŒ–ä»£ç†çš„å“åº”ã€‚\n\nç›®å‰ï¼Œå·²æœ‰è¶…è¿‡5000åå¼€å‘è€…åœ¨ä½¿ç”¨Parlantï¼Œè®¸å¤šé‡‘èæœºæ„ã€åŒ»ç–—æä¾›è€…å’Œæ³•å¾‹å…¬å¸ç­‰ä¼ä¸šå·²å°†å…¶åº”ç”¨äºç”Ÿäº§ç¯å¢ƒã€‚å¼€å‘è€…ä»¬å¯¹Parlantçš„è¯„ä»·æ™®éç§¯æï¼Œè®¤ä¸ºå…¶æ˜¯ä¸€ä¸ªä¼˜é›…ä¸”é«˜æ•ˆçš„å¯¹è¯AIæ¡†æ¶ï¼Œæå¤§åœ°ç®€åŒ–äº†å¼€å‘æµç¨‹ã€‚\n\næ€»ä¹‹ï¼ŒParlantä¸ºAIä»£ç†çš„å¼€å‘æä¾›äº†ä¸€ç§å…¨æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œç¡®ä¿ä»£ç†èƒ½å¤Ÿåœ¨çœŸå®ç¯å¢ƒä¸­ç¨³å®šè¿è¡Œï¼Œæ»¡è¶³ç”¨æˆ·çš„å®é™…éœ€æ±‚ã€‚",
        "https://github.com/DataExpert-io/data-engineer-handbook\n\nè¯¥é¡¹ç›®æ˜¯ä¸€ä¸ªæ•°æ®å·¥ç¨‹å­¦ä¹ èµ„æºçš„æ±‡æ€»åº“ï¼Œæ—¨åœ¨å¸®åŠ©ç”¨æˆ·æˆä¸ºä¼˜ç§€çš„æ•°æ®å·¥ç¨‹å¸ˆã€‚å¯¹äºåˆå­¦è€…ï¼Œå»ºè®®ä»2024å¹´æ•°æ®å·¥ç¨‹å…¥é—¨è·¯çº¿å›¾å¼€å§‹å­¦ä¹ ï¼Œæ­¤å¤–è¿˜æä¾›äº†ä¸ºæœŸå…­å‘¨çš„å…è´¹YouTubeè®­ç»ƒè¥ï¼Œæ¶µç›–äº†è½¯ä»¶éœ€æ±‚ã€é¡¹ç›®å®è·µã€é¢è¯•æŠ€å·§ç­‰å†…å®¹ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡é¡¹ç›®éƒ¨åˆ†è·å–æ›´å¤šå®è·µæ¡ˆä¾‹ï¼Œé€šè¿‡é¢è¯•éƒ¨åˆ†è·å–é¢è¯•å»ºè®®ï¼Œé€šè¿‡ä¹¦ç±éƒ¨åˆ†æ‰¾åˆ°é«˜è´¨é‡çš„å‚è€ƒä¹¦ç±ï¼Œå¹¶åŠ å…¥ç›¸å…³ç¤¾åŒºä»¥è·å–æ›´å¤šæ”¯æŒã€‚\n\nèµ„æºéƒ¨åˆ†åˆ—å‡ºäº†è¶…è¿‡25æœ¬ä¹¦ç±ï¼Œå…¶ä¸­æ¨èçš„ä¸‰æœ¬ä¹¦åŒ…æ‹¬ã€Šæ•°æ®å·¥ç¨‹åŸºç¡€ã€‹ã€ã€Šè®¾è®¡æ•°æ®å¯†é›†å‹åº”ç”¨ã€‹å’Œã€Šè®¾è®¡æœºå™¨å­¦ä¹ ç³»ç»Ÿã€‹ã€‚æ­¤å¤–ï¼Œè¿˜æ¨èäº†10ä¸ªæ•°æ®å·¥ç¨‹å’Œæœºå™¨å­¦ä¹ ç›¸å…³çš„ç¤¾åŒºï¼Œä¾›ç”¨æˆ·åŠ å…¥ä»¥æ‹“å±•äººè„‰å’Œè·å–ä¿¡æ¯ã€‚é¡¹ç›®è¿˜åˆ—å‡ºäº†å¤šå®¶ç›¸å…³å…¬å¸çš„ä¿¡æ¯ï¼Œæ¶µç›–äº†æ•°æ®æ¹–ã€æ•°æ®ä»“åº“ã€æ•°æ®è´¨é‡ç­‰å¤šä¸ªé¢†åŸŸï¼Œå¸®åŠ©ç”¨æˆ·äº†è§£è¡Œä¸šç°çŠ¶å’ŒæŠ€æœ¯è¶‹åŠ¿ã€‚\n\nåœ¨åšå®¢ã€ç™½çš®ä¹¦å’Œç¤¾äº¤åª’ä½“æ–¹é¢ï¼Œé¡¹ç›®æä¾›äº†å¤šå®¶å…¬å¸çš„æ•°æ®å·¥ç¨‹åšå®¢é“¾æ¥ã€é‡è¦çš„ç™½çš®ä¹¦ä»¥åŠæ•°æ®å·¥ç¨‹é¢†åŸŸçš„ç¤¾äº¤åª’ä½“è´¦å·ï¼Œä¾¿äºç”¨æˆ·è·å–æœ€æ–°çš„è¡Œä¸šåŠ¨æ€å’ŒæŠ€æœ¯åˆ†äº«ã€‚é¡¹ç›®è¿˜æ¨èäº†ä¸€äº›ä¼˜ç§€çš„æ’­å®¢å’Œé€šè®¯ï¼Œå¸®åŠ©ç”¨æˆ·é€šè¿‡ä¸åŒçš„åª’ä»‹æŒç»­å­¦ä¹ ã€‚\n\næœ€åï¼Œé¡¹ç›®è¿˜æä¾›äº†è¯¾ç¨‹å’Œè®¤è¯ä¿¡æ¯ï¼Œæ¶µç›–äº†å¤šä¸ªåœ¨çº¿å­¦ä¹ å¹³å°å’Œè®¤è¯è¯¾ç¨‹ï¼Œå¸®åŠ©ç”¨æˆ·åœ¨æ•°æ®å·¥ç¨‹é¢†åŸŸè·å¾—ä¸“ä¸šèµ„æ ¼å’ŒæŠ€èƒ½æå‡ã€‚æ•´ä½“è€Œè¨€ï¼Œè¯¥é¡¹ç›®ä¸ºå¸Œæœ›è¿›å…¥æ•°æ®å·¥ç¨‹é¢†åŸŸçš„å­¦ä¹ è€…æä¾›äº†å…¨é¢çš„èµ„æºå’Œæ”¯æŒã€‚",
        "https://github.com/rasbt/LLMs-from-scratch\n\nè¯¥é¡¹ç›®æ—¨åœ¨ä»é›¶å¼€å§‹ä½¿ç”¨PyTorchå®ç°ä¸€ä¸ªç±»ä¼¼ChatGPTçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå¹¶æä¾›äº†ç›¸å…³çš„ä»£ç å’Œæ•™ç¨‹ã€‚è¯¥ä»£ç åº“æ˜¯ä¹¦ç±ã€Šä»é›¶å¼€å§‹æ„å»ºå¤§å‹è¯­è¨€æ¨¡å‹ã€‹çš„å®˜æ–¹ä»£ç åº“ï¼Œä¹¦ä¸­è¯¦ç»†è®²è§£äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„å·¥ä½œåŸç†ï¼Œé€æ­¥æŒ‡å¯¼è¯»è€…åˆ›å»ºè‡ªå·±çš„LLMï¼Œæ¶µç›–äº†æ¯ä¸ªé˜¶æ®µçš„æ¸…æ™°æ–‡æœ¬ã€å›¾ç¤ºå’Œç¤ºä¾‹ã€‚ä¹¦ä¸­æ‰€æè¿°çš„è®­ç»ƒå’Œå¼€å‘æ–¹æ³•ä¸åˆ›å»ºå¤§å‹åŸºç¡€æ¨¡å‹çš„æ–¹å¼ç›¸ä¼¼ï¼ŒåŒæ—¶ä¹Ÿæä¾›äº†åŠ è½½æ›´å¤§é¢„è®­ç»ƒæ¨¡å‹æƒé‡ä»¥è¿›è¡Œå¾®è°ƒçš„ä»£ç ã€‚\n\nè¯»è€…éœ€è¦å…·å¤‡æ‰å®çš„Pythonç¼–ç¨‹åŸºç¡€ï¼Œäº†è§£æ·±åº¦ç¥ç»ç½‘ç»œçš„æ¦‚å¿µå°†æœ‰åŠ©äºç†è§£LLMçš„æ„å»ºã€‚ä¹¦ä¸­ä½¿ç”¨PyTorchå®ç°ä»£ç ï¼Œå°½ç®¡ä¸è¦æ±‚ç²¾é€šPyTorchï¼Œä½†ç†Ÿæ‚‰å…¶åŸºæœ¬çŸ¥è¯†ä¼šæœ‰æ‰€å¸®åŠ©ã€‚ä¹¦ä¸­è¿˜æä¾›äº†é™„å½•ï¼Œä»‹ç»äº†PyTorchçš„åŸºç¡€çŸ¥è¯†ã€‚ä»£ç è®¾è®¡ä¸ºèƒ½å¤Ÿåœ¨æ™®é€šç¬”è®°æœ¬ç”µè„‘ä¸Šè¿è¡Œï¼Œå¹¶èƒ½è‡ªåŠ¨åˆ©ç”¨å¯ç”¨çš„GPUï¼Œç¡®ä¿å¹¿æ³›çš„å—ä¼—èƒ½å¤Ÿå‚ä¸å­¦ä¹ ã€‚\n\næ­¤å¤–ï¼Œä¹¦ä¸­æ¯ç« éƒ½åŒ…å«å¤šä¸ªç»ƒä¹ ï¼Œè§£å†³æ–¹æ¡ˆæ±‡æ€»åœ¨é™„å½•ä¸­ï¼Œè¯»è€…è¿˜å¯ä»¥ä¸‹è½½å…è´¹çš„170é¡µPDFæ–‡ä»¶è¿›è¡Œè‡ªæµ‹ã€‚é¡¹ç›®è¿˜æä¾›äº†é¢å¤–çš„ææ–™å’Œè§†é¢‘è¯¾ç¨‹ï¼Œå¸®åŠ©è¯»è€…æ›´æ·±å…¥åœ°ç†è§£å†…å®¹ã€‚å¯¹äºæœ‰å…´è¶£çš„è¯»è€…ï¼Œé¡¹ç›®æ¬¢è¿åé¦ˆå’Œè®¨è®ºï¼Œä½†ç”±äºä»£ç ä¸ä¹¦ç±å†…å®¹ç´§å¯†ç›¸å…³ï¼Œæš‚ä¸æ¥å—æ‰©å±•å†…å®¹çš„è´¡çŒ®ã€‚\n\nå¦‚æœè¯»è€…åœ¨ç ”ç©¶ä¸­å‘ç°è¯¥ä¹¦æˆ–ä»£ç æœ‰ç”¨ï¼Œå»ºè®®å¼•ç”¨è¯¥ä¹¦ç±ã€‚æ•´ä½“è€Œè¨€ï¼Œè¯¥é¡¹ç›®ä¸ºå¸Œæœ›æ·±å…¥äº†è§£å’Œæ„å»ºå¤§å‹è¯­è¨€æ¨¡å‹çš„å­¦ä¹ è€…æä¾›äº†å…¨é¢çš„èµ„æºå’ŒæŒ‡å¯¼ã€‚",
        "https://github.com/enescingoz/awesome-n8n-templates\n\nè¯¥é¡¹ç›®æ—¨åœ¨é€šè¿‡æä¾›ä¸€ç³»åˆ—n8nè‡ªåŠ¨åŒ–æ¨¡æ¿æ¥æå‡å·¥ä½œæµç¨‹çš„è‡ªåŠ¨åŒ–æ•ˆç‡ã€‚è¿™äº›æ¨¡æ¿å¯ä»¥å¿«é€Ÿè¿æ¥ç”¨æˆ·å¸¸ç”¨çš„åº”ç”¨ç¨‹åºï¼Œå¦‚Gmailã€Telegramã€Google Driveå’ŒSlackï¼Œåˆ©ç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯å®ç°å³ç”¨å‹è‡ªåŠ¨åŒ–ï¼Œå¸®åŠ©ç”¨æˆ·èŠ‚çœæ—¶é—´ã€æé«˜ç”Ÿäº§åŠ›ã€‚é¡¹ç›®çš„æ–‡æ¡£ä¸­åŒ…å«äº†ä»äº’è”ç½‘æ”¶é›†çš„å¤šç§n8nè‡ªåŠ¨åŒ–æ¨¡æ¿ï¼Œæ—¨åœ¨ç®€åŒ–ç”¨æˆ·çš„ä»»åŠ¡å’Œå·¥ä½œæµç¨‹ï¼Œä½¿å…¶æ›´å®¹æ˜“å‘ç°å’Œä½¿ç”¨ç°æˆçš„è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆã€‚\n\né¡¹ç›®ä¸­åŒ…å«çš„æ¨¡æ¿æ¶µç›–äº†å¤šä¸ªé¢†åŸŸï¼ŒåŒ…æ‹¬ç¤¾äº¤åª’ä½“è‡ªåŠ¨åŒ–ã€ç”µå­é‚®ä»¶ç®¡ç†ã€æ•°æ®å¤„ç†å’Œåˆ†æç­‰ã€‚ä¾‹å¦‚ï¼Œç”¨æˆ·å¯ä»¥ä½¿ç”¨æ¨¡æ¿è‡ªåŠ¨ç¿»è¯‘å’Œå‘å¸ƒTwitterçº¿ç¨‹ï¼Œæˆ–é€šè¿‡Gmailè‡ªåŠ¨æ ‡è®°å’Œåˆ†ç±»é‚®ä»¶ã€‚æ­¤å¤–ï¼Œé¡¹ç›®è¿˜æä¾›äº†ä¸Telegramå’ŒGoogle Driveçš„é›†æˆï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡AIåŠ©æ‰‹ä¸è¿™äº›å¹³å°è¿›è¡Œäº¤äº’ï¼Œæå‡å·¥ä½œæ•ˆç‡ã€‚\n\néœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ‰€æœ‰æ¨¡æ¿å‡ä¸ºåœ¨çº¿æ”¶é›†ï¼Œé¡¹ç›®ä½œè€…ä¸å¯¹ä½¿ç”¨è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„é—®é¢˜æˆ–æŸå¤±æ‰¿æ‹…è´£ä»»ã€‚ç”¨æˆ·åœ¨ä½¿ç”¨è¿™äº›æ¨¡æ¿æ—¶åº”è‡ªè¡Œæ‰¿æ‹…é£é™©ã€‚é¡¹ç›®é¼“åŠ±ç”¨æˆ·å‚ä¸è´¡çŒ®æ–°çš„æ¨¡æ¿æˆ–å»ºè®®æ–°ç±»åˆ«ï¼Œä»¥è¿›ä¸€æ­¥ä¸°å¯Œèµ„æºåº“ã€‚\n\næ€»ä¹‹ï¼Œè¯¥é¡¹ç›®ä¸ºå¸Œæœ›é€šè¿‡è‡ªåŠ¨åŒ–æå‡å·¥ä½œæ•ˆç‡çš„ç”¨æˆ·æä¾›äº†ä¸°å¯Œçš„å·¥å…·å’Œèµ„æºï¼Œç”¨æˆ·åªéœ€ç®€å•å‡ æ­¥å³å¯å¼€å§‹ä½¿ç”¨n8nè¿›è¡Œè‡ªåŠ¨åŒ–æ“ä½œã€‚",
        "https://github.com/PixiEditor/PixiEditor\n\nPixiEditoræ˜¯ä¸€æ¬¾é€šç”¨çš„2Dç¼–è¾‘å™¨ï¼Œæ—¨åœ¨ä¸ºç”¨æˆ·æä¾›æ»¡è¶³å„ç§2Déœ€æ±‚çš„å·¥å…·å’ŒåŠŸèƒ½ã€‚ç”¨æˆ·å¯ä»¥åˆ©ç”¨PixiEditoråˆ›å»ºç²¾ç¾çš„æ¸¸æˆç²¾çµã€åŠ¨ç”»ã€ç¼–è¾‘å›¾åƒä»¥åŠè®¾è®¡æ ‡å¿—ï¼Œæ‰€æœ‰è¿™äº›åŠŸèƒ½éƒ½é›†æˆåœ¨ä¸€ä¸ªç›´è§‚ä¸”ç†Ÿæ‚‰çš„ç•Œé¢ä¸­ã€‚è¯¥è½¯ä»¶çš„2.0ç‰ˆæœ¬é»˜è®¤æä¾›ä¸‰ç§å·¥å…·é›†ï¼Œåˆ†åˆ«æ˜¯åƒç´ è‰ºæœ¯å·¥å…·ã€åŸºç¡€ç»˜ç”»å·¥å…·å’ŒçŸ¢é‡å·¥å…·ï¼Œç”¨æˆ·å¯ä»¥åœ¨åŒä¸€ç”»å¸ƒä¸Šæ··åˆä½¿ç”¨è¿™äº›å·¥å…·ï¼Œæ”¯æŒå¯¼å‡ºä¸ºå¤šç§æ ¼å¼ï¼Œå¦‚pngã€jpgã€svgã€gifå’Œmp4ç­‰ã€‚\n\nåœ¨åŠ¨ç”»æ–¹é¢ï¼ŒPixiEditor 2.0å¼•å…¥äº†æ—¶é—´è½´å’ŒåŠ¨ç”»åŠŸèƒ½ï¼Œç”¨æˆ·å¯ä»¥é€å¸§åˆ›å»ºåŠ¨ç”»ï¼Œæˆ–ä½¿ç”¨èŠ‚ç‚¹æ¥åŠ¨ç”»è‡ªå®šä¹‰ç€è‰²å™¨ã€‚æœªæ¥çš„ç‰ˆæœ¬è®¡åˆ’æ”¯æŒå…³é”®å¸§åŠ¨ç”»ä¸çŸ¢é‡ç»“åˆã€‚èŠ‚ç‚¹æ¸²æŸ“ç³»ç»Ÿæ˜¯è¯¥è½¯ä»¶å¼ºå¤§åŠŸèƒ½çš„æ ¸å¿ƒï¼Œæ‰€æœ‰å›¾å±‚ã€æ•ˆæœå’Œå±‚ç»“æ„éƒ½ä»¥èŠ‚ç‚¹çš„å½¢å¼å­˜åœ¨ï¼Œç”¨æˆ·å¯ä»¥è‡ªç”±å®šåˆ¶å›¾åƒï¼Œåˆ›é€ ç¨‹åºåŒ–è‰ºæœ¯å’ŒåŠ¨ç”»ã€‚\n\næ­¤å¤–ï¼ŒPixiEditorè¿˜æä¾›äº†ä»æºä»£ç æ„å»ºçš„æŒ‡å—ï¼Œé¼“åŠ±ç”¨æˆ·å‚ä¸è´¡çŒ®å’Œåä½œã€‚å¯¹äºé‡åˆ°é—®é¢˜çš„ç”¨æˆ·ï¼ŒPixiEditorå›¢é˜Ÿä¹Ÿæä¾›äº†å¸®åŠ©å’Œæ”¯æŒã€‚æ€»ä¹‹ï¼ŒPixiEditoræ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§ä¸”çµæ´»çš„2Dç¼–è¾‘å·¥å…·ï¼Œé€‚åˆå„ç§åˆ›ä½œéœ€æ±‚ã€‚",
        "https://github.com/immich-app/immich\n\nè¯¥é¡¹ç›®æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„è‡ªæ‰˜ç®¡ç…§ç‰‡å’Œè§†é¢‘ç®¡ç†è§£å†³æ–¹æ¡ˆï¼Œæ­£åœ¨ç§¯æå¼€å‘ä¸­ï¼Œç”¨æˆ·éœ€æ³¨æ„å¯èƒ½å­˜åœ¨çš„é”™è¯¯å’Œé‡å¤§å˜æ›´ã€‚é¡¹ç›®ä¸å»ºè®®ä½œä¸ºå”¯ä¸€çš„ç…§ç‰‡å’Œè§†é¢‘å­˜å‚¨æ–¹å¼ï¼Œç”¨æˆ·åº”éµå¾ª3-2-1å¤‡ä»½ç­–ç•¥ä»¥ç¡®ä¿æ•°æ®å®‰å…¨ã€‚é¡¹ç›®çš„ä¸»è¦æ–‡æ¡£å’Œå®‰è£…æŒ‡å—å¯åœ¨å®˜æ–¹ç½‘ç«™æ‰¾åˆ°ã€‚\n\nè¯¥è§£å†³æ–¹æ¡ˆæ”¯æŒå¤šç§è¯­è¨€ï¼Œæä¾›äº†ä¸°å¯Œçš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬åœ¨ç§»åŠ¨ç«¯å’Œç½‘é¡µä¸Šä¸Šä¼ å’ŒæŸ¥çœ‹è§†é¢‘åŠç…§ç‰‡ã€è‡ªåŠ¨å¤‡ä»½ã€é¿å…é‡å¤èµ„äº§ã€é€‰æ‹©æ€§å¤‡ä»½ç›¸å†Œã€ä¸‹è½½æœ¬åœ°è®¾å¤‡ã€æ”¯æŒå¤šç”¨æˆ·ã€å…±äº«ç›¸å†Œã€æ”¯æŒåŸå§‹æ ¼å¼ã€å…ƒæ•°æ®æŸ¥çœ‹ã€ä»¥åŠåŸºäºå…ƒæ•°æ®å’Œå¯¹è±¡çš„æœç´¢ç­‰ã€‚ç§»åŠ¨åº”ç”¨è¿˜å…·å¤‡åå°å¤‡ä»½ã€è™šæ‹Ÿæ»šåŠ¨ã€OAuthæ”¯æŒç­‰åŠŸèƒ½ã€‚\n\nç”¨æˆ·å¯ä»¥é€šè¿‡æä¾›çš„æ¼”ç¤ºé“¾æ¥ä½“éªŒè¯¥åº”ç”¨ï¼Œæ¼”ç¤ºè´¦æˆ·çš„ç™»å½•ä¿¡æ¯ä¹Ÿå·²å…¬å¼€ã€‚é¡¹ç›®çš„æ–‡æ¡£ä¸­è¯¦ç»†åˆ—å‡ºäº†åŠŸèƒ½ç‰¹æ€§ï¼Œå¹¶æä¾›äº†å®‰è£…å’Œä½¿ç”¨çš„ç›¸å…³æŒ‡å¯¼ã€‚ç”¨æˆ·è¿˜å¯ä»¥æŸ¥çœ‹é¡¹ç›®çš„å¼€å‘è·¯çº¿å›¾å’Œè´¡çŒ®æ–¹å¼ï¼Œå‚ä¸åˆ°é¡¹ç›®çš„è¿›ä¸€æ­¥å‘å±•ä¸­ã€‚\n\næ­¤å¤–ï¼Œé¡¹ç›®è¿˜å…·å¤‡é¢éƒ¨è¯†åˆ«ã€è®°å¿†åŠŸèƒ½ã€ç¦»çº¿æ”¯æŒç­‰å…ˆè¿›ç‰¹æ€§ï¼Œæ—¨åœ¨ä¸ºç”¨æˆ·æä¾›å…¨é¢çš„ç…§ç‰‡å’Œè§†é¢‘ç®¡ç†ä½“éªŒã€‚æ•´ä½“è€Œè¨€ï¼Œè¯¥é¡¹ç›®ä¸ºç”¨æˆ·æä¾›äº†ä¸€ä¸ªçµæ´»ä¸”åŠŸèƒ½å¼ºå¤§çš„å·¥å…·ï¼Œé€‚åˆä¸ªäººå’Œå›¢é˜Ÿä½¿ç”¨ã€‚",
        "https://github.com/Shubhamsaboo/awesome-llm-apps\n\nè¯¥é¡¹ç›®æ˜¯ä¸€ä¸ªæ±‡é›†äº†ä¼—å¤šä¼˜ç§€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨çš„é›†åˆï¼Œä¸»è¦åˆ©ç”¨OpenAIã€Anthropicã€Geminiç­‰æ¨¡å‹ä»¥åŠå¼€æºæ¨¡å‹å¦‚DeepSeekã€Qwenå’ŒLlamaï¼Œæ”¯æŒæœ¬åœ°è¿è¡Œã€‚é¡¹ç›®æ—¨åœ¨å±•ç¤ºLLMåœ¨å„ä¸ªé¢†åŸŸçš„å®é™…åº”ç”¨ï¼ŒåŒ…æ‹¬ä»£ç åº“ã€ç”µå­é‚®ä»¶ç­‰ï¼Œé¼“åŠ±ç”¨æˆ·æ¢ç´¢ç»“åˆAIä»£ç†ã€ä»£ç†å›¢é˜Ÿã€MCPå’ŒRAGçš„åº”ç”¨ã€‚\n\né¡¹ç›®ä¸­åŒ…å«äº†å¤šç§AIä»£ç†çš„ç¤ºä¾‹ï¼ŒåŒ…æ‹¬åˆçº§å’Œé«˜çº§ä»£ç†ï¼Œå¦‚AIåšå®¢è½¬æ’­ä»£ç†ã€AIæ•°æ®åˆ†æä»£ç†ã€AIåŒ»ç–—å½±åƒä»£ç†ç­‰ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰è‡ªä¸»æ¸¸æˆä»£ç†ã€å¤šä¸ªä»£ç†å›¢é˜Ÿçš„åä½œåº”ç”¨ï¼Œä»¥åŠè¯­éŸ³AIä»£ç†å’ŒMCP AIä»£ç†ç­‰å¤šç§ç±»å‹çš„åº”ç”¨ã€‚RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯ä¹Ÿè¢«å¹¿æ³›åº”ç”¨äºå¤šä¸ªé¡¹ç›®ä¸­ï¼Œæä¾›äº†å¤šç§æ£€ç´¢å’Œç”Ÿæˆçš„ç»„åˆæ–¹å¼ã€‚\n\nç”¨æˆ·å¯ä»¥é€šè¿‡å…‹éš†é¡¹ç›®åº“ã€è¿›å…¥ç‰¹å®šé¡¹ç›®ç›®å½•å¹¶å®‰è£…æ‰€éœ€ä¾èµ–æ¥å¿«é€Ÿä¸Šæ‰‹ã€‚åŒæ—¶ï¼Œé¡¹ç›®é¼“åŠ±ç¤¾åŒºè´¡çŒ®ï¼Œæ¬¢è¿ç”¨æˆ·æå‡ºæ–°æƒ³æ³•æˆ–æ”¹è¿›å»ºè®®ï¼Œå¹¶é€šè¿‡GitHubæäº¤é—®é¢˜æˆ–æ‹‰å–è¯·æ±‚ã€‚é¡¹ç›®çš„ç›®æ ‡æ˜¯ä¿ƒè¿›å¼€æºç”Ÿæ€ç³»ç»Ÿçš„å‘å±•ï¼Œè®©æ›´å¤šäººå‚ä¸åˆ°LLMé©±åŠ¨çš„åº”ç”¨å¼€å‘ä¸­ã€‚\n\næ€»ä¹‹ï¼Œè¯¥é¡¹ç›®ä¸ä»…æä¾›äº†ä¸°å¯Œçš„LLMåº”ç”¨å®ä¾‹ï¼Œè¿˜ä¸ºå¼€å‘è€…æä¾›äº†å­¦ä¹ å’Œè´¡çŒ®çš„æœºä¼šï¼Œæ¨åŠ¨äº†AIæŠ€æœ¯çš„æ™®åŠä¸åº”ç”¨ã€‚",
        "https://github.com/MotiaDev/motia\n\nMotiaæ˜¯ä¸€ä¸ªç°ä»£åŒ–çš„åç«¯æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å½“å‰åç«¯å¼€å‘ä¸­çš„ç¢ç‰‡åŒ–é—®é¢˜ã€‚ä¼ ç»Ÿçš„åç«¯å¼€å‘é€šå¸¸æ¶‰åŠå¤šä¸ªæ¡†æ¶å’Œå·¥å…·ï¼Œä¾‹å¦‚APIã€åå°ä½œä¸šã€é˜Ÿåˆ—å’ŒAIä»£ç†ç­‰ï¼Œå¯¼è‡´å¼€å‘è¿‡ç¨‹å¤æ‚ä¸”éš¾ä»¥ç®¡ç†ã€‚Motiaé€šè¿‡å°†è¿™äº›åŠŸèƒ½ç»Ÿä¸€åˆ°ä¸€ä¸ªç³»ç»Ÿä¸­ï¼Œæä¾›äº†å…±äº«çš„å¯è§‚å¯Ÿæ€§å’Œå¼€å‘ä½“éªŒï¼Œä½¿å¾—åç«¯å¼€å‘å˜å¾—æ›´åŠ ç®€æ´é«˜æ•ˆã€‚å¼€å‘è€…å¯ä»¥åœ¨åŒä¸€ä¸ªå·¥ä½œæµä¸­ä½¿ç”¨JavaScriptã€TypeScriptå’ŒPythonç­‰å¤šç§è¯­è¨€ï¼Œæå¤§åœ°ç®€åŒ–äº†å¼€å‘è¿‡ç¨‹ã€‚\n\nMotiaçš„æ ¸å¿ƒæ¦‚å¿µæ˜¯â€œæ­¥éª¤â€ï¼ˆStepï¼‰ï¼Œæ¯ä¸ªæ­¥éª¤ä»£è¡¨ä¸€ä¸ªç‹¬ç«‹çš„å…¥å£ç‚¹ï¼Œå¯ä»¥æ˜¯APIã€åå°ä½œä¸šã€å®šæ—¶ä»»åŠ¡æˆ–AIä»£ç†ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¼€å‘è€…å¯ä»¥åœ¨åŒä¸€ä¸ªé¡¹ç›®ä¸­çµæ´»åœ°ä½¿ç”¨ä¸åŒçš„ç¼–ç¨‹è¯­è¨€ï¼ŒåŒæ—¶å…±äº«çŠ¶æ€å’Œæ•°æ®ã€‚Motiaè¿˜æä¾›äº†å†…ç½®çš„å¯è§‚å¯Ÿæ€§å·¥å…·ï¼Œæ”¯æŒå®Œæ•´çš„ç«¯åˆ°ç«¯è¿½è¸ªã€ç»“æ„åŒ–æ—¥å¿—è®°å½•å’ŒçŠ¶æ€å¯è§†åŒ–ï¼Œå¸®åŠ©å¼€å‘è€…å¿«é€Ÿè°ƒè¯•å’Œç›‘æ§åº”ç”¨ã€‚\n\nä½¿ç”¨Motiaï¼Œå¼€å‘è€…å¯ä»¥åœ¨ä¸åˆ°60ç§’çš„æ—¶é—´å†…å¯åŠ¨ä¸€ä¸ªæ–°é¡¹ç›®ï¼Œå¹¶é€šè¿‡ç®€å•çš„å‘½ä»¤åˆ›å»ºREST APIã€å¤„ç†åå°ä»»åŠ¡æˆ–è°ƒåº¦å®šæ—¶ä½œä¸šã€‚Motiaçš„å·¥ä½œå°æä¾›äº†å¯è§†åŒ–çš„ç•Œé¢ï¼Œæ–¹ä¾¿å¼€å‘è€…å®æ—¶æ„å»ºã€æµ‹è¯•å’Œè§‚å¯Ÿåç«¯åº”ç”¨ã€‚è¯¥æ¡†æ¶è¿˜æ”¯æŒäº‹ä»¶é©±åŠ¨æ¶æ„ï¼Œå…è®¸å¼€å‘è€…é€šè¿‡å‘å‡ºå’Œè®¢é˜…äº‹ä»¶æ¥æ„å»ºå¤æ‚çš„å·¥ä½œæµã€‚\n\nMotiaçš„è®¾è®¡ç†å¿µæ˜¯æ¶ˆé™¤åç«¯å¼€å‘ä¸­çš„å¤æ‚æ€§ï¼Œæä¾›ä¸€ä¸ªç»Ÿä¸€çš„è¿è¡Œæ—¶ç¯å¢ƒï¼Œä½¿å¾—å¼€å‘è€…èƒ½å¤Ÿä¸“æ³¨äºä¸šåŠ¡é€»è¾‘è€ŒéåŸºç¡€è®¾æ–½ã€‚é€šè¿‡Motiaï¼Œå¼€å‘è€…å¯ä»¥å®ç°å¿«é€Ÿå¼€å‘ã€çµæ´»æ‰©å±•å’Œç®€åŒ–éƒ¨ç½²ï¼Œé€‚åº”ç°ä»£è½¯ä»¶å¼€å‘çš„éœ€æ±‚ã€‚æ€»ä¹‹ï¼ŒMotiaä¸ºåç«¯å¼€å‘æä¾›äº†ä¸€ç§å…¨æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œæ—¨åœ¨æå‡å¼€å‘æ•ˆç‡å’Œç³»ç»Ÿçš„å¯ç»´æŠ¤æ€§ã€‚",
        "https://github.com/OpenBB-finance/OpenBB\n\nOpenBBå¹³å°æ˜¯ä¸€ä¸ªå¼€æºçš„é‡‘èæ•°æ®èšåˆå·¥å…·ï¼Œæ—¨åœ¨ä¸ºç”¨æˆ·å’Œäººå·¥æ™ºèƒ½ä»£ç†æä¾›ä¸°å¯Œçš„é‡‘èæ•°æ®è®¿é—®ï¼ŒåŒ…æ‹¬è‚¡ç¥¨ã€æœŸæƒã€åŠ å¯†è´§å¸ã€å¤–æ±‡ã€å®è§‚ç»æµå’Œå›ºå®šæ”¶ç›Šç­‰ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡ç®€å•çš„Pythonå‘½ä»¤å®‰è£…å’Œä½¿ç”¨è¯¥å¹³å°ï¼Œè·å–æ‰€éœ€çš„é‡‘èæ•°æ®ã€‚OpenBBè¿˜æä¾›äº†å¤šç§æ‰©å±•åŠŸèƒ½ï¼Œä»¥æ»¡è¶³ä¸åŒç”¨æˆ·çš„éœ€æ±‚ã€‚\n\nè¯¥å¹³å°çš„æ¥å£æ”¯æŒPythonå’Œå‘½ä»¤è¡Œç•Œé¢ï¼ˆCLIï¼‰ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡OpenBBå·¥ä½œåŒºå®ç°æ•°æ®å¯è§†åŒ–å’ŒAIä»£ç†çš„é›†æˆã€‚ç”¨æˆ·åªéœ€æŒ‰ç…§ç®€å•çš„æ­¥éª¤å°†OpenBBå¹³å°ä¸å·¥ä½œåŒºè¿æ¥ï¼Œå³å¯å¼€å§‹ä½¿ç”¨ã€‚OpenBBå·¥ä½œåŒºå…è®¸ç”¨æˆ·åœ¨ä¸€ä¸ªé›†ä¸­çš„ç¯å¢ƒä¸­ç®¡ç†å’Œåˆ†ææ•°æ®ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚\n\nå®‰è£…OpenBBå¹³å°éå¸¸ç®€å•ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡PyPIåŒ…æˆ–ç›´æ¥å…‹éš†ä»£ç åº“æ¥å®Œæˆå®‰è£…ã€‚æ­¤å¤–ï¼ŒOpenBBè¿˜é¼“åŠ±ç”¨æˆ·å‚ä¸è´¡çŒ®ï¼Œæä¾›åé¦ˆæˆ–æŠ¥å‘Šé—®é¢˜ï¼Œä»¥å¸®åŠ©é¡¹ç›®ä¸æ–­æ”¹è¿›ã€‚å¹³å°çš„ä½¿ç”¨æ¶‰åŠä¸€å®šçš„é£é™©ï¼Œç”¨æˆ·åœ¨è¿›è¡Œé‡‘èäº¤æ˜“å‰åº”å……åˆ†äº†è§£ç›¸å…³é£é™©å’Œæˆæœ¬ï¼Œå¹¶æ ¹æ®è‡ªèº«çš„æŠ•èµ„ç›®æ ‡å’Œé£é™©æ‰¿å—èƒ½åŠ›åšå‡ºæ˜æ™ºå†³ç­–ã€‚\n\nOpenBBå¹³å°åœ¨ä¸æ–­å‘å±•å£®å¤§ï¼Œæ¬¢è¿æ›´å¤šç”¨æˆ·åŠ å…¥è¿™ä¸ªå¼€æºç¤¾åŒºã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡ç¤¾äº¤åª’ä½“æˆ–ç”µå­é‚®ä»¶ä¸å›¢é˜Ÿè”ç³»ï¼Œè·å–æ›´å¤šä¿¡æ¯æˆ–å¯»æ±‚æ”¯æŒã€‚æ€»ä¹‹ï¼ŒOpenBBè‡´åŠ›äºé€šè¿‡å¼€æ”¾çš„é‡‘èæ•°æ®å¹³å°ï¼Œæ¨åŠ¨é‡‘èè¡Œä¸šçš„åˆ›æ–°ä¸å˜é©ã€‚"
    ],
    "L1 Summary": "- We-Math 2.0: è¯¥ç³»ç»Ÿæ—¨åœ¨æå‡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦æ¨ç†æ–¹é¢çš„èƒ½åŠ›ï¼Œé›†æˆäº†ç»“æ„åŒ–çŸ¥è¯†ä½“ç³»å’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¡†æ¶ã€‚é€šè¿‡æ„å»ºMathBookçŸ¥è¯†ç³»ç»Ÿå’ŒMathBook-RLå¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå®éªŒç»“æœæ˜¾ç¤ºå…¶åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚\n\n- NextStep-1: è¿™æ˜¯ä¸€ä¸ª140äº¿å‚æ•°çš„è‡ªå›å½’æ¨¡å‹ï¼Œä¸“æ³¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆï¼Œé‡‡ç”¨ç¦»æ•£æ–‡æœ¬å’Œè¿ç»­å›¾åƒæ ‡è®°è¿›è¡Œè®­ç»ƒã€‚è¯¥æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆå’Œç¼–è¾‘ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œå¹¶è®¡åˆ’å‘ç¤¾åŒºå‘å¸ƒä»£ç å’Œæ¨¡å‹ä»¥ä¿ƒè¿›ç ”ç©¶ã€‚\n\n- ToonComposer: è¯¥ç”Ÿæˆæ¨¡å‹å°†å¡é€šåˆ¶ä½œä¸­çš„è¡¥é—´å’Œä¸Šè‰²è¿‡ç¨‹ç»Ÿä¸€ä¸ºåå…³é”®å¸§é˜¶æ®µï¼Œå‡å°‘äº†äººå·¥å·¥ä½œé‡ã€‚é€šè¿‡ç¨€ç–è‰å›¾æ³¨å…¥æœºåˆ¶å’Œç©ºé—´ä½ç§©é€‚é…å™¨ï¼ŒToonComposeråœ¨è§†è§‰è´¨é‡å’Œç”Ÿäº§æ•ˆç‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚\n\n- PRELUDE: è¿™æ˜¯ä¸€ä¸ªè¯„ä¼°é•¿æ–‡æœ¬ç†è§£èƒ½åŠ›çš„åŸºå‡†ï¼Œè¦æ±‚åˆ¤æ–­è§’è‰²å‰ä¼ æ•…äº‹ä¸åŸè‘—å™è¿°çš„ä¸€è‡´æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œå½“å‰æ¨¡å‹åœ¨è¿™ä¸€ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œå¼ºè°ƒäº†é•¿æ–‡æœ¬ç†è§£å’Œæ¨ç†çš„æ”¹è¿›ç©ºé—´ã€‚\n\n- UI-Venus Technical Report: è¯¥ç”¨æˆ·ç•Œé¢ä»£ç†é€šè¿‡æˆªå›¾ä½œä¸ºè¾“å…¥ï¼Œåœ¨å®šä½å’Œå¯¼èˆªä»»åŠ¡ä¸Šå®ç°äº†æœ€ä½³æ€§èƒ½ã€‚å¼•å…¥äº†å¼ºåŒ–å¾®è°ƒå’Œè‡ªæˆ‘æ¼”å˜æ–¹æ³•ï¼Œæå‡äº†å¯¼èˆªèƒ½åŠ›ï¼Œå¹¶å‘å¸ƒäº†å¼€æºä»£ç ä¾›ç¤¾åŒºä½¿ç”¨ã€‚\n\n- Puppeteer: è¿™æ˜¯ä¸€ä¸ªè‡ªåŠ¨ç»‘å®šå’ŒåŠ¨ç”»åˆ¶ä½œçš„æ¡†æ¶ï¼Œæ—¨åœ¨ç®€åŒ–3Då†…å®¹åˆ›ä½œè¿‡ç¨‹ã€‚é€šè¿‡è‡ªå›å½’å˜æ¢å™¨å’ŒåŸºäºæ³¨æ„åŠ›çš„æ¶æ„ï¼ŒPuppeteeråœ¨éª¨éª¼é¢„æµ‹å’ŒåŠ¨ç”»è´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚\n\n- STream3R: è¯¥æ–¹æ³•å°†3Dé‡å»ºé—®é¢˜é‡æ–°å®šä¹‰ä¸ºä»…ä½¿ç”¨è§£ç å™¨çš„Transformeré—®é¢˜ï¼Œåˆ©ç”¨å› æœæ³¨æ„åŠ›é«˜æ•ˆå¤„ç†å›¾åƒåºåˆ—ã€‚å®éªŒç»“æœæ˜¾ç¤ºå…¶åœ¨åŠ¨æ€åœºæ™¯ä¸­çš„è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå¹¶å…¼å®¹å¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒåŸºç¡€è®¾æ–½ã€‚\n\n- A Survey on Diffusion Language Models: æœ¬è°ƒæŸ¥æä¾›äº†æ‰©æ•£è¯­è¨€æ¨¡å‹çš„å…¨é¢æ¦‚è¿°ï¼Œåˆ†æäº†å…¶ä¸è‡ªå›å½’æ¨¡å‹çš„å…³ç³»åŠåº”ç”¨ã€‚å¼ºè°ƒäº†DLMåœ¨å¤šæ¨¡æ€æ‰©å±•å’Œå®é™…åœºæ™¯ä¸­çš„æ½œåŠ›ï¼ŒåŒæ—¶è®¨è®ºäº†å…¶å±€é™æ€§å’Œæœªæ¥ç ”ç©¶æ–¹å‘ã€‚\n\n- Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models: è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ä½¿ç”¨Pass@kä½œä¸ºå¥–åŠ±çš„ä¼˜åŠ¿ï¼Œå¼ºè°ƒæ¢ç´¢ä¸åˆ©ç”¨çš„ç›¸äº’ä¿ƒè¿›ã€‚é€šè¿‡è§£ææ¨å¯¼ï¼Œæå‡ºäº†ä¼˜åŒ–ç­–ç•¥è®¾è®¡çš„æ–°è§†è§’ã€‚\n\n- HumanSense: è¿™æ˜¯ä¸€ä¸ªè¯„ä¼°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹äººæœ¬æ„ŸçŸ¥å’Œäº’åŠ¨èƒ½åŠ›çš„åŸºå‡†ï¼Œå¼ºè°ƒå¯¹å¤æ‚äººç±»æ„å›¾çš„ç†è§£ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç»“åˆè§†è§‰å’ŒéŸ³é¢‘è¾“å…¥å¯ä»¥æ˜¾è‘—æå‡æ¨¡å‹è¡¨ç°ï¼Œå¹¶æå‡ºäº†å¢å¼ºæ¨ç†èƒ½åŠ›çš„æ–¹æ³•ã€‚\n\n- Processing and acquisition traces in visual encoders: è¯¥ç ”ç©¶åˆ†æäº†å›¾åƒè·å–è¿‡ç¨‹ä¸­çš„å‚æ•°å¦‚ä½•å½±å“è§†è§‰ç¼–ç å™¨çš„æ€§èƒ½ã€‚å‘ç°è¿™äº›å‚æ•°åœ¨å­¦ä¹ çš„è§†è§‰è¡¨å¾ä¸­è¢«ç¼–ç ï¼Œå¹¶å¯¹è¯­ä¹‰é¢„æµ‹æœ‰æ·±è¿œå½±å“ã€‚\n\n- From Black Box to Transparency: è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å¤šç»´å»ºæ¨¡æ¡†æ¶ï¼Œç»“åˆå¯è§£é‡Šçš„æœºå™¨å­¦ä¹ å’Œç‰¹å¾å·¥ç¨‹ï¼Œæå‡è‡ªåŠ¨åŒ–å£è¯‘è´¨é‡è¯„ä¼°çš„é€æ˜æ€§ã€‚ç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨è¯„ä¼°å¿ å®åº¦å’Œæµç•…åº¦æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚\n\n- When Explainability Meets Privacy: è¯¥ç ”ç©¶æ¢è®¨äº†è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„éšç§ä¸å¯è§£é‡Šæ€§ä¹‹é—´çš„æƒè¡¡ï¼Œæ­ç¤ºäº†ä¸¤è€…ä¹‹é—´å¤æ‚çš„å…³ç³»ã€‚æ€»ç»“äº†ä¸€ç³»åˆ—å®ç”¨å»ºè®®ï¼Œä»¥æŒ‡å¯¼æœªæ¥åœ¨è¿™ä¸€äº¤å‰é¢†åŸŸçš„ç ”ç©¶ã€‚\n\n- Archon: è¿™æ˜¯ä¸€ä¸ªä¸ºAIç¼–ç åŠ©æ‰‹æä¾›çŸ¥è¯†å’Œä»»åŠ¡ç®¡ç†çš„æ ¸å¿ƒæ”¯æŒå¹³å°ï¼Œæ—¨åœ¨æå‡å¼€å‘æ•ˆç‡ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡ç®€å•çš„è®¾ç½®è¿æ¥å¤šä¸ªAIå·¥å…·ï¼Œåˆ©ç”¨æ™ºèƒ½æœç´¢å’Œä»»åŠ¡ç®¡ç†åŠŸèƒ½ã€‚\n\n- Parlant: è¯¥æ¡†æ¶é€šè¿‡è‡ªç„¶è¯­è¨€å®šä¹‰è§„åˆ™ï¼Œè§£å†³AIä»£ç†å¼€å‘ä¸­çš„ä¸€è‡´æ€§é—®é¢˜ã€‚å¼€å‘è€…å¯ä»¥å¿«é€Ÿå¯åŠ¨ä»£ç†ï¼Œå¹¶ç¡®ä¿å…¶åœ¨å®é™…åº”ç”¨ä¸­æ»¡è¶³ç”¨æˆ·éœ€æ±‚ï¼Œé€‚ç”¨äºå¤šä¸ªè¡Œä¸šã€‚\n\n- Data Engineer Handbook: è¿™æ˜¯ä¸€ä¸ªæ•°æ®å·¥ç¨‹å­¦ä¹ èµ„æºçš„æ±‡æ€»åº“ï¼Œæä¾›äº†å…¥é—¨è·¯çº¿å›¾ã€å®è·µæ¡ˆä¾‹å’Œç¤¾åŒºæ”¯æŒã€‚é¡¹ç›®æ—¨åœ¨å¸®åŠ©ç”¨æˆ·æå‡æ•°æ®å·¥ç¨‹æŠ€èƒ½ï¼Œäº†è§£è¡Œä¸šåŠ¨æ€ã€‚\n\n- LLMs from Scratch: è¯¥é¡¹ç›®æä¾›äº†ä»é›¶å¼€å§‹ä½¿ç”¨PyTorchå®ç°å¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç å’Œæ•™ç¨‹ï¼Œé€‚åˆå¸Œæœ›æ·±å…¥äº†è§£LLMçš„å­¦ä¹ è€…ã€‚ä¹¦ä¸­è¯¦ç»†è®²è§£äº†æ¨¡å‹æ„å»ºè¿‡ç¨‹ï¼Œå¹¶æä¾›äº†ç»ƒä¹ å’Œé¢å¤–ææ–™ã€‚\n\n- Awesome n8n Templates: è¯¥é¡¹ç›®æä¾›äº†ä¸€ç³»åˆ—n8nè‡ªåŠ¨åŒ–æ¨¡æ¿ï¼Œæ—¨åœ¨æå‡å·¥ä½œæµç¨‹çš„è‡ªåŠ¨åŒ–æ•ˆç‡ã€‚ç”¨æˆ·å¯ä»¥å¿«é€Ÿè¿æ¥å¸¸ç”¨åº”ç”¨ç¨‹åºï¼Œåˆ©ç”¨ç°æˆçš„è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆã€‚\n\n- PixiEditor: è¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„2Dç¼–è¾‘å™¨ï¼Œæ”¯æŒç”¨æˆ·åˆ›å»ºæ¸¸æˆç²¾çµã€åŠ¨ç”»å’Œå›¾åƒè®¾è®¡ã€‚è½¯ä»¶æä¾›å¤šç§å·¥å…·é›†ï¼Œç”¨æˆ·å¯ä»¥åœ¨åŒä¸€ç”»å¸ƒä¸Šçµæ´»ä½¿ç”¨ï¼Œæ”¯æŒå¤šç§æ ¼å¼å¯¼å‡ºã€‚\n\n- Immich: è¯¥é¡¹ç›®æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„è‡ªæ‰˜ç®¡ç…§ç‰‡å’Œè§†é¢‘ç®¡ç†è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒå¤šç§åŠŸèƒ½å¦‚è‡ªåŠ¨å¤‡ä»½å’Œå…ƒæ•°æ®æœç´¢ã€‚ç”¨æˆ·éœ€éµå¾ªæ•°æ®å®‰å…¨ç­–ç•¥ï¼Œå¹¶å¯å‚ä¸é¡¹ç›®çš„è¿›ä¸€æ­¥å‘å±•ã€‚\n\n- Awesome LLM Apps: è¯¥é¡¹ç›®æ±‡é›†äº†ä¼—å¤šå¤§å‹è¯­è¨€æ¨¡å‹åº”ç”¨ï¼Œå±•ç¤ºäº†LLMåœ¨å„ä¸ªé¢†åŸŸçš„å®é™…åº”ç”¨ã€‚é¼“åŠ±ç”¨æˆ·æ¢ç´¢å’Œè´¡çŒ®æ–°æƒ³æ³•ï¼Œæ¨åŠ¨å¼€æºç”Ÿæ€ç³»ç»Ÿçš„å‘å±•ã€‚\n\n- Motia: è¿™æ˜¯ä¸€ä¸ªç°ä»£åŒ–çš„åç«¯æ¡†æ¶ï¼Œæ—¨åœ¨ç®€åŒ–åç«¯å¼€å‘è¿‡ç¨‹ã€‚é€šè¿‡ç»Ÿä¸€çš„ç³»ç»Ÿï¼Œå¼€å‘è€…å¯ä»¥çµæ´»ä½¿ç”¨å¤šç§è¯­è¨€ï¼Œæå‡å¼€å‘æ•ˆç‡å’Œç³»ç»Ÿå¯ç»´æŠ¤æ€§ã€‚\n\n- OpenBB: è¯¥å¹³å°æ˜¯ä¸€ä¸ªå¼€æºé‡‘èæ•°æ®èšåˆå·¥å…·ï¼Œæä¾›ä¸°å¯Œçš„é‡‘èæ•°æ®è®¿é—®ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡ç®€å•çš„å‘½ä»¤è·å–æ•°æ®ï¼Œå¹¶å‚ä¸é¡¹ç›®çš„æ”¹è¿›å’Œå‘å±•ã€‚"
}